{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674d68be-dee1-4910-a28e-f08a102316c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk pengolahan data dan visualisasi\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Library untuk evaluasi dan model machine learning\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import sklearn.ensemble as ek\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Library untuk Explainable AI (XAI)\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import shap\n",
    "\n",
    "# Library untuk Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103abc4c-1b2e-4ca0-82e5-0b66b34b6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dataset \n",
    "\n",
    "DM = pd.read_csv(\"C:\\\\Data Raihan\\\\Penelitian Threshold\\\\Dataset\\\\Obfuscated-MalMem2022\\\\Obfuscated-MalMem2022.csv\") #DM--> Dataset Malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b14026-c76d-4c99-8f2a-723225d2df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58596 entries, 0 to 58595\n",
      "Data columns (total 57 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Category                                58596 non-null  object \n",
      " 1   pslist.nproc                            58596 non-null  int64  \n",
      " 2   pslist.nppid                            58596 non-null  int64  \n",
      " 3   pslist.avg_threads                      58596 non-null  float64\n",
      " 4   pslist.nprocs64bit                      58596 non-null  int64  \n",
      " 5   pslist.avg_handlers                     58596 non-null  float64\n",
      " 6   dlllist.ndlls                           58596 non-null  int64  \n",
      " 7   dlllist.avg_dlls_per_proc               58596 non-null  float64\n",
      " 8   handles.nhandles                        58596 non-null  int64  \n",
      " 9   handles.avg_handles_per_proc            58596 non-null  float64\n",
      " 10  handles.nport                           58596 non-null  int64  \n",
      " 11  handles.nfile                           58596 non-null  int64  \n",
      " 12  handles.nevent                          58596 non-null  int64  \n",
      " 13  handles.ndesktop                        58596 non-null  int64  \n",
      " 14  handles.nkey                            58596 non-null  int64  \n",
      " 15  handles.nthread                         58596 non-null  int64  \n",
      " 16  handles.ndirectory                      58596 non-null  int64  \n",
      " 17  handles.nsemaphore                      58596 non-null  int64  \n",
      " 18  handles.ntimer                          58596 non-null  int64  \n",
      " 19  handles.nsection                        58596 non-null  int64  \n",
      " 20  handles.nmutant                         58596 non-null  int64  \n",
      " 21  ldrmodules.not_in_load                  58596 non-null  int64  \n",
      " 22  ldrmodules.not_in_init                  58596 non-null  int64  \n",
      " 23  ldrmodules.not_in_mem                   58596 non-null  int64  \n",
      " 24  ldrmodules.not_in_load_avg              58596 non-null  float64\n",
      " 25  ldrmodules.not_in_init_avg              58596 non-null  float64\n",
      " 26  ldrmodules.not_in_mem_avg               58596 non-null  float64\n",
      " 27  malfind.ninjections                     58596 non-null  int64  \n",
      " 28  malfind.commitCharge                    58596 non-null  int64  \n",
      " 29  malfind.protection                      58596 non-null  int64  \n",
      " 30  malfind.uniqueInjections                58596 non-null  float64\n",
      " 31  psxview.not_in_pslist                   58596 non-null  int64  \n",
      " 32  psxview.not_in_eprocess_pool            58596 non-null  int64  \n",
      " 33  psxview.not_in_ethread_pool             58596 non-null  int64  \n",
      " 34  psxview.not_in_pspcid_list              58596 non-null  int64  \n",
      " 35  psxview.not_in_csrss_handles            58596 non-null  int64  \n",
      " 36  psxview.not_in_session                  58596 non-null  int64  \n",
      " 37  psxview.not_in_deskthrd                 58596 non-null  int64  \n",
      " 38  psxview.not_in_pslist_false_avg         58596 non-null  float64\n",
      " 39  psxview.not_in_eprocess_pool_false_avg  58596 non-null  float64\n",
      " 40  psxview.not_in_ethread_pool_false_avg   58596 non-null  float64\n",
      " 41  psxview.not_in_pspcid_list_false_avg    58596 non-null  float64\n",
      " 42  psxview.not_in_csrss_handles_false_avg  58596 non-null  float64\n",
      " 43  psxview.not_in_session_false_avg        58596 non-null  float64\n",
      " 44  psxview.not_in_deskthrd_false_avg       58596 non-null  float64\n",
      " 45  modules.nmodules                        58596 non-null  int64  \n",
      " 46  svcscan.nservices                       58596 non-null  int64  \n",
      " 47  svcscan.kernel_drivers                  58596 non-null  int64  \n",
      " 48  svcscan.fs_drivers                      58596 non-null  int64  \n",
      " 49  svcscan.process_services                58596 non-null  int64  \n",
      " 50  svcscan.shared_process_services         58596 non-null  int64  \n",
      " 51  svcscan.interactive_process_services    58596 non-null  int64  \n",
      " 52  svcscan.nactive                         58596 non-null  int64  \n",
      " 53  callbacks.ncallbacks                    58596 non-null  int64  \n",
      " 54  callbacks.nanonymous                    58596 non-null  int64  \n",
      " 55  callbacks.ngeneric                      58596 non-null  int64  \n",
      " 56  Class                                   58596 non-null  object \n",
      "dtypes: float64(15), int64(40), object(2)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "DM.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dcbc54b-758f-4b1f-999c-71e61b807d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "features_to_drop = ['Category', 'Class']\n",
    "\n",
    "# Droping specified columns and target variable\n",
    "X = DM.drop(features_to_drop, axis=1).values    \n",
    "y = DM['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41bd6d6c-c0ef-470b-9c61-cf4044411438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Nan\n",
    "X = pd.DataFrame(X).dropna()\n",
    "y = y[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8f7589-ddf7-41a4-aaa7-436e367e5f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Min-Max scaling to make X non-negative\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c355a696-fe69-43fd-8957-c3fd27306a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable (if still contains string values)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba75d9b8-e9cf-428b-bee5-0f0eb118955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic Algorithm evaluation function\n",
    "def evaluate(individual):\n",
    "    \"\"\" Evaluation function for genetic algorithm \"\"\"\n",
    "    selected_features = [i for i, value in enumerate(individual) if value > 0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 1000,  # Penalty for selecting no features\n",
    "    estimator = RandomForestClassifier()\n",
    "    X_selected = X_scaled[:, selected_features]\n",
    "    estimator.fit(X_selected, y)\n",
    "    return 1 - estimator.score(X_selected, y),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e597769-8696-45a1-b4d3-d2112634f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic Algorithm setup\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", np.random.randint, 0, 2)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=X.shape[1])\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "852b0e31-271d-49bb-9ee5-49adcffd2e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0]],\n",
       " [{'gen': 0, 'nevals': 50},\n",
       "  {'gen': 1, 'nevals': 28},\n",
       "  {'gen': 2, 'nevals': 29},\n",
       "  {'gen': 3, 'nevals': 33},\n",
       "  {'gen': 4, 'nevals': 34},\n",
       "  {'gen': 5, 'nevals': 24},\n",
       "  {'gen': 6, 'nevals': 25},\n",
       "  {'gen': 7, 'nevals': 35},\n",
       "  {'gen': 8, 'nevals': 26},\n",
       "  {'gen': 9, 'nevals': 35},\n",
       "  {'gen': 10, 'nevals': 28},\n",
       "  {'gen': 11, 'nevals': 37},\n",
       "  {'gen': 12, 'nevals': 31},\n",
       "  {'gen': 13, 'nevals': 28},\n",
       "  {'gen': 14, 'nevals': 32},\n",
       "  {'gen': 15, 'nevals': 25},\n",
       "  {'gen': 16, 'nevals': 24},\n",
       "  {'gen': 17, 'nevals': 33},\n",
       "  {'gen': 18, 'nevals': 36},\n",
       "  {'gen': 19, 'nevals': 28},\n",
       "  {'gen': 20, 'nevals': 34}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Genetic Algorithm\n",
    "population = toolbox.population(n=50)\n",
    "algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=20, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa8ad04-c8ca-43d2-95fc-f272b05e0a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using Genetic Algorithm:\n",
      "pslist.nproc\n",
      "pslist.nppid\n",
      "pslist.avg_threads\n",
      "pslist.nprocs64bit\n",
      "pslist.avg_handlers\n",
      "dlllist.ndlls\n",
      "handles.nhandles\n",
      "handles.avg_handles_per_proc\n",
      "handles.nport\n",
      "handles.ndesktop\n",
      "handles.nkey\n",
      "ldrmodules.not_in_load\n",
      "ldrmodules.not_in_init\n",
      "ldrmodules.not_in_load_avg\n",
      "ldrmodules.not_in_mem_avg\n",
      "malfind.ninjections\n",
      "malfind.protection\n",
      "psxview.not_in_ethread_pool\n",
      "psxview.not_in_pspcid_list\n",
      "psxview.not_in_deskthrd\n",
      "psxview.not_in_pslist_false_avg\n",
      "psxview.not_in_eprocess_pool_false_avg\n",
      "psxview.not_in_ethread_pool_false_avg\n",
      "psxview.not_in_session_false_avg\n",
      "modules.nmodules\n",
      "svcscan.nservices\n",
      "svcscan.kernel_drivers\n",
      "svcscan.fs_drivers\n",
      "callbacks.ncallbacks\n",
      "callbacks.ngeneric\n"
     ]
    }
   ],
   "source": [
    "# Select the best individual\n",
    "best_individual = tools.selBest(population, k=1)[0]\n",
    "genetic_selected_features = [i for i, value in enumerate(best_individual) if value > 0]\n",
    "\n",
    "# Display selected features\n",
    "features = []\n",
    "filtered_columns = DM.drop(features_to_drop, axis=1).columns\n",
    "print(\"Selected features using Genetic Algorithm:\")\n",
    "for idx in genetic_selected_features:\n",
    "    print(filtered_columns[idx])\n",
    "    features.append(filtered_columns[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbdd0877-c2ba-4c27-a531-0e69ba6823e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Temp\\ipykernel_14576\\1069642451.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_data = DM.groupby('Class').apply(lambda x: x.sample(frac=1)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Memilih 100% data secara acak dari setiap fitur/column\n",
    "sampled_data = DM.groupby('Class').apply(lambda x: x.sample(frac=1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c19c643a-4213-435e-ab40-0d4f86031267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6242107-ff43-4017-a39c-3bded4309660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels ke bentuk numerik jika diperlukan\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "455baa36-aed5-457f-8b85-e9db2d0de2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20469, number of negative: 20548\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7597\n",
      "[LightGBM] [Info] Number of data points in the train set: 41017, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499037 -> initscore=-0.003852\n",
      "[LightGBM] [Info] Start training from score -0.003852\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0:\tlearn: 0.4139860\ttotal: 174ms\tremaining: 17.2s\n",
      "1:\tlearn: 0.2530356\ttotal: 197ms\tremaining: 9.65s\n",
      "2:\tlearn: 0.1431572\ttotal: 222ms\tremaining: 7.18s\n",
      "3:\tlearn: 0.0828220\ttotal: 243ms\tremaining: 5.84s\n",
      "4:\tlearn: 0.0490886\ttotal: 266ms\tremaining: 5.05s\n",
      "5:\tlearn: 0.0278122\ttotal: 294ms\tremaining: 4.61s\n",
      "6:\tlearn: 0.0173225\ttotal: 315ms\tremaining: 4.19s\n",
      "7:\tlearn: 0.0121741\ttotal: 339ms\tremaining: 3.89s\n",
      "8:\tlearn: 0.0084377\ttotal: 360ms\tremaining: 3.64s\n",
      "9:\tlearn: 0.0060383\ttotal: 387ms\tremaining: 3.48s\n",
      "10:\tlearn: 0.0047036\ttotal: 411ms\tremaining: 3.33s\n",
      "11:\tlearn: 0.0039345\ttotal: 440ms\tremaining: 3.23s\n",
      "12:\tlearn: 0.0033389\ttotal: 458ms\tremaining: 3.06s\n",
      "13:\tlearn: 0.0026314\ttotal: 478ms\tremaining: 2.94s\n",
      "14:\tlearn: 0.0022482\ttotal: 498ms\tremaining: 2.82s\n",
      "15:\tlearn: 0.0019083\ttotal: 520ms\tremaining: 2.73s\n",
      "16:\tlearn: 0.0017279\ttotal: 594ms\tremaining: 2.9s\n",
      "17:\tlearn: 0.0014875\ttotal: 617ms\tremaining: 2.81s\n",
      "18:\tlearn: 0.0013509\ttotal: 637ms\tremaining: 2.71s\n",
      "19:\tlearn: 0.0011706\ttotal: 658ms\tremaining: 2.63s\n",
      "20:\tlearn: 0.0011165\ttotal: 675ms\tremaining: 2.54s\n",
      "21:\tlearn: 0.0010226\ttotal: 698ms\tremaining: 2.48s\n",
      "22:\tlearn: 0.0009747\ttotal: 722ms\tremaining: 2.42s\n",
      "23:\tlearn: 0.0009421\ttotal: 747ms\tremaining: 2.37s\n",
      "24:\tlearn: 0.0008743\ttotal: 771ms\tremaining: 2.31s\n",
      "25:\tlearn: 0.0008384\ttotal: 791ms\tremaining: 2.25s\n",
      "26:\tlearn: 0.0007707\ttotal: 820ms\tremaining: 2.22s\n",
      "27:\tlearn: 0.0007305\ttotal: 900ms\tremaining: 2.31s\n",
      "28:\tlearn: 0.0006866\ttotal: 984ms\tremaining: 2.41s\n",
      "29:\tlearn: 0.0006407\ttotal: 1.07s\tremaining: 2.5s\n",
      "30:\tlearn: 0.0006114\ttotal: 1.17s\tremaining: 2.61s\n",
      "31:\tlearn: 0.0006068\ttotal: 1.26s\tremaining: 2.67s\n",
      "32:\tlearn: 0.0005815\ttotal: 1.34s\tremaining: 2.72s\n",
      "33:\tlearn: 0.0005394\ttotal: 1.45s\tremaining: 2.82s\n",
      "34:\tlearn: 0.0005012\ttotal: 1.57s\tremaining: 2.92s\n",
      "35:\tlearn: 0.0005012\ttotal: 1.63s\tremaining: 2.89s\n",
      "36:\tlearn: 0.0004781\ttotal: 1.71s\tremaining: 2.92s\n",
      "37:\tlearn: 0.0004538\ttotal: 1.74s\tremaining: 2.84s\n",
      "38:\tlearn: 0.0004538\ttotal: 1.76s\tremaining: 2.75s\n",
      "39:\tlearn: 0.0004388\ttotal: 1.79s\tremaining: 2.69s\n",
      "40:\tlearn: 0.0004388\ttotal: 1.81s\tremaining: 2.6s\n",
      "41:\tlearn: 0.0004388\ttotal: 1.83s\tremaining: 2.53s\n",
      "42:\tlearn: 0.0004388\ttotal: 1.85s\tremaining: 2.45s\n",
      "43:\tlearn: 0.0004270\ttotal: 1.88s\tremaining: 2.4s\n",
      "44:\tlearn: 0.0004115\ttotal: 1.9s\tremaining: 2.32s\n",
      "45:\tlearn: 0.0003897\ttotal: 1.99s\tremaining: 2.34s\n",
      "46:\tlearn: 0.0003897\ttotal: 2.1s\tremaining: 2.37s\n",
      "47:\tlearn: 0.0003831\ttotal: 2.18s\tremaining: 2.37s\n",
      "48:\tlearn: 0.0003798\ttotal: 2.23s\tremaining: 2.32s\n",
      "49:\tlearn: 0.0003676\ttotal: 2.25s\tremaining: 2.25s\n",
      "50:\tlearn: 0.0003521\ttotal: 2.29s\tremaining: 2.2s\n",
      "51:\tlearn: 0.0003521\ttotal: 2.39s\tremaining: 2.21s\n",
      "52:\tlearn: 0.0003521\ttotal: 2.42s\tremaining: 2.15s\n",
      "53:\tlearn: 0.0003521\ttotal: 2.45s\tremaining: 2.08s\n",
      "54:\tlearn: 0.0003345\ttotal: 2.47s\tremaining: 2.02s\n",
      "55:\tlearn: 0.0003053\ttotal: 2.54s\tremaining: 2s\n",
      "56:\tlearn: 0.0003002\ttotal: 2.56s\tremaining: 1.93s\n",
      "57:\tlearn: 0.0003002\ttotal: 2.58s\tremaining: 1.87s\n",
      "58:\tlearn: 0.0003002\ttotal: 2.6s\tremaining: 1.81s\n",
      "59:\tlearn: 0.0003002\ttotal: 2.62s\tremaining: 1.74s\n",
      "60:\tlearn: 0.0002761\ttotal: 2.64s\tremaining: 1.69s\n",
      "61:\tlearn: 0.0002726\ttotal: 2.66s\tremaining: 1.63s\n",
      "62:\tlearn: 0.0002726\ttotal: 2.68s\tremaining: 1.57s\n",
      "63:\tlearn: 0.0002726\ttotal: 2.7s\tremaining: 1.52s\n",
      "64:\tlearn: 0.0002726\ttotal: 2.72s\tremaining: 1.47s\n",
      "65:\tlearn: 0.0002726\ttotal: 2.74s\tremaining: 1.41s\n",
      "66:\tlearn: 0.0002549\ttotal: 2.76s\tremaining: 1.36s\n",
      "67:\tlearn: 0.0002549\ttotal: 2.79s\tremaining: 1.31s\n",
      "68:\tlearn: 0.0002549\ttotal: 2.8s\tremaining: 1.26s\n",
      "69:\tlearn: 0.0002549\ttotal: 2.82s\tremaining: 1.21s\n",
      "70:\tlearn: 0.0002549\ttotal: 2.85s\tremaining: 1.17s\n",
      "71:\tlearn: 0.0002549\ttotal: 2.87s\tremaining: 1.12s\n",
      "72:\tlearn: 0.0002549\ttotal: 2.9s\tremaining: 1.07s\n",
      "73:\tlearn: 0.0002549\ttotal: 2.91s\tremaining: 1.02s\n",
      "74:\tlearn: 0.0002548\ttotal: 2.93s\tremaining: 978ms\n",
      "75:\tlearn: 0.0002548\ttotal: 2.95s\tremaining: 932ms\n",
      "76:\tlearn: 0.0002548\ttotal: 2.97s\tremaining: 888ms\n",
      "77:\tlearn: 0.0002548\ttotal: 2.99s\tremaining: 843ms\n",
      "78:\tlearn: 0.0002548\ttotal: 3.02s\tremaining: 801ms\n",
      "79:\tlearn: 0.0002548\ttotal: 3.04s\tremaining: 759ms\n",
      "80:\tlearn: 0.0002548\ttotal: 3.05s\tremaining: 716ms\n",
      "81:\tlearn: 0.0002548\ttotal: 3.07s\tremaining: 675ms\n",
      "82:\tlearn: 0.0002548\ttotal: 3.09s\tremaining: 633ms\n",
      "83:\tlearn: 0.0002548\ttotal: 3.11s\tremaining: 593ms\n",
      "84:\tlearn: 0.0002548\ttotal: 3.13s\tremaining: 553ms\n",
      "85:\tlearn: 0.0002548\ttotal: 3.15s\tremaining: 513ms\n",
      "86:\tlearn: 0.0002531\ttotal: 3.18s\tremaining: 475ms\n",
      "87:\tlearn: 0.0002531\ttotal: 3.2s\tremaining: 436ms\n",
      "88:\tlearn: 0.0002531\ttotal: 3.21s\tremaining: 397ms\n",
      "89:\tlearn: 0.0002531\ttotal: 3.23s\tremaining: 359ms\n",
      "90:\tlearn: 0.0002531\ttotal: 3.25s\tremaining: 321ms\n",
      "91:\tlearn: 0.0002531\ttotal: 3.27s\tremaining: 284ms\n",
      "92:\tlearn: 0.0002530\ttotal: 3.29s\tremaining: 248ms\n",
      "93:\tlearn: 0.0002530\ttotal: 3.32s\tremaining: 212ms\n",
      "94:\tlearn: 0.0002530\ttotal: 3.34s\tremaining: 176ms\n",
      "95:\tlearn: 0.0002530\ttotal: 3.36s\tremaining: 140ms\n",
      "96:\tlearn: 0.0002530\ttotal: 3.46s\tremaining: 107ms\n",
      "97:\tlearn: 0.0002530\ttotal: 3.54s\tremaining: 72.3ms\n",
      "98:\tlearn: 0.0002530\ttotal: 3.57s\tremaining: 36.1ms\n",
      "99:\tlearn: 0.0002530\ttotal: 3.6s\tremaining: 0us\n",
      "550/550 [==============================] - 1s 941us/step\n",
      "550/550 [==============================] - 1s 1ms/step\n",
      "550/550 [==============================] - 6s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 17580it [19:01, 15.41it/s]                                                             \n",
      "PermutationExplainer explainer: 17580it [1:05:30,  4.46it/s]                                                           \n",
      "PermutationExplainer explainer: 17580it [11:23, 25.39it/s]                                                             \n",
      "PermutationExplainer explainer: 17580it [29:48,  9.77it/s]                                                             \n",
      "PermutationExplainer explainer: 17580it [10:40, 27.00it/s]                                                             \n",
      "PermutationExplainer explainer: 17580it [08:53, 32.29it/s]                                                             \n",
      "PermutationExplainer explainer: 17580it [10:37:49,  2.18s/it]                                                          \n",
      "PermutationExplainer explainer: 17580it [31:11,  9.33it/s]                                                             \n",
      "PermutationExplainer explainer: 17580it [42:15,  6.92it/s]                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20469, number of negative: 20548\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7597\n",
      "[LightGBM] [Info] Number of data points in the train set: 41017, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499037 -> initscore=-0.003852\n",
      "[LightGBM] [Info] Start training from score -0.003852\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 17580it [24:20, 11.95it/s]                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4139860\ttotal: 15.9ms\tremaining: 1.57s\n",
      "1:\tlearn: 0.2530356\ttotal: 32.6ms\tremaining: 1.6s\n",
      "2:\tlearn: 0.1431572\ttotal: 47.2ms\tremaining: 1.53s\n",
      "3:\tlearn: 0.0828220\ttotal: 62.2ms\tremaining: 1.49s\n",
      "4:\tlearn: 0.0490886\ttotal: 77.6ms\tremaining: 1.48s\n",
      "5:\tlearn: 0.0278122\ttotal: 94.6ms\tremaining: 1.48s\n",
      "6:\tlearn: 0.0173225\ttotal: 110ms\tremaining: 1.46s\n",
      "7:\tlearn: 0.0121741\ttotal: 127ms\tremaining: 1.46s\n",
      "8:\tlearn: 0.0084377\ttotal: 143ms\tremaining: 1.45s\n",
      "9:\tlearn: 0.0060383\ttotal: 160ms\tremaining: 1.44s\n",
      "10:\tlearn: 0.0047036\ttotal: 176ms\tremaining: 1.42s\n",
      "11:\tlearn: 0.0039345\ttotal: 194ms\tremaining: 1.42s\n",
      "12:\tlearn: 0.0033389\ttotal: 209ms\tremaining: 1.4s\n",
      "13:\tlearn: 0.0026314\ttotal: 227ms\tremaining: 1.4s\n",
      "14:\tlearn: 0.0022482\ttotal: 245ms\tremaining: 1.39s\n",
      "15:\tlearn: 0.0019083\ttotal: 262ms\tremaining: 1.38s\n",
      "16:\tlearn: 0.0017279\ttotal: 279ms\tremaining: 1.36s\n",
      "17:\tlearn: 0.0014875\ttotal: 294ms\tremaining: 1.34s\n",
      "18:\tlearn: 0.0013509\ttotal: 308ms\tremaining: 1.31s\n",
      "19:\tlearn: 0.0011706\ttotal: 323ms\tremaining: 1.29s\n",
      "20:\tlearn: 0.0011165\ttotal: 335ms\tremaining: 1.26s\n",
      "21:\tlearn: 0.0010226\ttotal: 352ms\tremaining: 1.25s\n",
      "22:\tlearn: 0.0009747\ttotal: 366ms\tremaining: 1.23s\n",
      "23:\tlearn: 0.0009421\ttotal: 382ms\tremaining: 1.21s\n",
      "24:\tlearn: 0.0008743\ttotal: 397ms\tremaining: 1.19s\n",
      "25:\tlearn: 0.0008384\ttotal: 413ms\tremaining: 1.18s\n",
      "26:\tlearn: 0.0007707\ttotal: 429ms\tremaining: 1.16s\n",
      "27:\tlearn: 0.0007305\ttotal: 446ms\tremaining: 1.15s\n",
      "28:\tlearn: 0.0006866\ttotal: 461ms\tremaining: 1.13s\n",
      "29:\tlearn: 0.0006407\ttotal: 477ms\tremaining: 1.11s\n",
      "30:\tlearn: 0.0006114\ttotal: 492ms\tremaining: 1.09s\n",
      "31:\tlearn: 0.0006068\ttotal: 506ms\tremaining: 1.07s\n",
      "32:\tlearn: 0.0005815\ttotal: 520ms\tremaining: 1.05s\n",
      "33:\tlearn: 0.0005394\ttotal: 535ms\tremaining: 1.04s\n",
      "34:\tlearn: 0.0005012\ttotal: 551ms\tremaining: 1.02s\n",
      "35:\tlearn: 0.0005012\ttotal: 563ms\tremaining: 1s\n",
      "36:\tlearn: 0.0004781\ttotal: 577ms\tremaining: 983ms\n",
      "37:\tlearn: 0.0004538\ttotal: 593ms\tremaining: 967ms\n",
      "38:\tlearn: 0.0004538\ttotal: 605ms\tremaining: 946ms\n",
      "39:\tlearn: 0.0004388\ttotal: 624ms\tremaining: 936ms\n",
      "40:\tlearn: 0.0004388\ttotal: 642ms\tremaining: 924ms\n",
      "41:\tlearn: 0.0004388\ttotal: 661ms\tremaining: 913ms\n",
      "42:\tlearn: 0.0004388\ttotal: 677ms\tremaining: 897ms\n",
      "43:\tlearn: 0.0004270\ttotal: 692ms\tremaining: 881ms\n",
      "44:\tlearn: 0.0004115\ttotal: 706ms\tremaining: 863ms\n",
      "45:\tlearn: 0.0003897\ttotal: 721ms\tremaining: 847ms\n",
      "46:\tlearn: 0.0003897\ttotal: 737ms\tremaining: 831ms\n",
      "47:\tlearn: 0.0003831\ttotal: 753ms\tremaining: 815ms\n",
      "48:\tlearn: 0.0003798\ttotal: 767ms\tremaining: 798ms\n",
      "49:\tlearn: 0.0003676\ttotal: 781ms\tremaining: 781ms\n",
      "50:\tlearn: 0.0003521\ttotal: 796ms\tremaining: 764ms\n",
      "51:\tlearn: 0.0003521\ttotal: 807ms\tremaining: 745ms\n",
      "52:\tlearn: 0.0003521\ttotal: 821ms\tremaining: 728ms\n",
      "53:\tlearn: 0.0003521\ttotal: 834ms\tremaining: 711ms\n",
      "54:\tlearn: 0.0003345\ttotal: 849ms\tremaining: 695ms\n",
      "55:\tlearn: 0.0003053\ttotal: 866ms\tremaining: 681ms\n",
      "56:\tlearn: 0.0003002\ttotal: 882ms\tremaining: 665ms\n",
      "57:\tlearn: 0.0003002\ttotal: 895ms\tremaining: 648ms\n",
      "58:\tlearn: 0.0003002\ttotal: 906ms\tremaining: 630ms\n",
      "59:\tlearn: 0.0003002\ttotal: 920ms\tremaining: 613ms\n",
      "60:\tlearn: 0.0002761\ttotal: 935ms\tremaining: 598ms\n",
      "61:\tlearn: 0.0002726\ttotal: 951ms\tremaining: 583ms\n",
      "62:\tlearn: 0.0002726\ttotal: 964ms\tremaining: 566ms\n",
      "63:\tlearn: 0.0002726\ttotal: 978ms\tremaining: 550ms\n",
      "64:\tlearn: 0.0002726\ttotal: 991ms\tremaining: 534ms\n",
      "65:\tlearn: 0.0002726\ttotal: 1s\tremaining: 517ms\n",
      "66:\tlearn: 0.0002549\ttotal: 1.02s\tremaining: 501ms\n",
      "67:\tlearn: 0.0002549\ttotal: 1.03s\tremaining: 485ms\n",
      "68:\tlearn: 0.0002549\ttotal: 1.04s\tremaining: 469ms\n",
      "69:\tlearn: 0.0002549\ttotal: 1.06s\tremaining: 453ms\n",
      "70:\tlearn: 0.0002549\ttotal: 1.07s\tremaining: 439ms\n",
      "71:\tlearn: 0.0002549\ttotal: 1.09s\tremaining: 424ms\n",
      "72:\tlearn: 0.0002549\ttotal: 1.1s\tremaining: 409ms\n",
      "73:\tlearn: 0.0002549\ttotal: 1.12s\tremaining: 392ms\n",
      "74:\tlearn: 0.0002548\ttotal: 1.13s\tremaining: 377ms\n",
      "75:\tlearn: 0.0002548\ttotal: 1.15s\tremaining: 362ms\n",
      "76:\tlearn: 0.0002548\ttotal: 1.16s\tremaining: 347ms\n",
      "77:\tlearn: 0.0002548\ttotal: 1.17s\tremaining: 331ms\n",
      "78:\tlearn: 0.0002548\ttotal: 1.19s\tremaining: 315ms\n",
      "79:\tlearn: 0.0002548\ttotal: 1.2s\tremaining: 300ms\n",
      "80:\tlearn: 0.0002548\ttotal: 1.21s\tremaining: 284ms\n",
      "81:\tlearn: 0.0002548\ttotal: 1.22s\tremaining: 269ms\n",
      "82:\tlearn: 0.0002548\ttotal: 1.24s\tremaining: 254ms\n",
      "83:\tlearn: 0.0002548\ttotal: 1.25s\tremaining: 239ms\n",
      "84:\tlearn: 0.0002548\ttotal: 1.26s\tremaining: 223ms\n",
      "85:\tlearn: 0.0002548\ttotal: 1.28s\tremaining: 208ms\n",
      "86:\tlearn: 0.0002531\ttotal: 1.29s\tremaining: 193ms\n",
      "87:\tlearn: 0.0002531\ttotal: 1.3s\tremaining: 178ms\n",
      "88:\tlearn: 0.0002531\ttotal: 1.32s\tremaining: 163ms\n",
      "89:\tlearn: 0.0002531\ttotal: 1.33s\tremaining: 148ms\n",
      "90:\tlearn: 0.0002531\ttotal: 1.35s\tremaining: 133ms\n",
      "91:\tlearn: 0.0002531\ttotal: 1.36s\tremaining: 118ms\n",
      "92:\tlearn: 0.0002530\ttotal: 1.37s\tremaining: 103ms\n",
      "93:\tlearn: 0.0002530\ttotal: 1.39s\tremaining: 88.7ms\n",
      "94:\tlearn: 0.0002530\ttotal: 1.41s\tremaining: 74ms\n",
      "95:\tlearn: 0.0002530\ttotal: 1.42s\tremaining: 59.1ms\n",
      "96:\tlearn: 0.0002530\ttotal: 1.43s\tremaining: 44.3ms\n",
      "97:\tlearn: 0.0002530\ttotal: 1.45s\tremaining: 29.5ms\n",
      "98:\tlearn: 0.0002530\ttotal: 1.46s\tremaining: 14.7ms\n",
      "99:\tlearn: 0.0002530\ttotal: 1.47s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 17580it [4:19:58,  1.13it/s]                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550/550 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550/550 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using SHAP with CNN: operands could not be broadcast together with shapes (41017,55,1) (41017,55) \n",
      "550/550 [==============================] - 5s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using SHAP with RNN: in user code:\n",
      "\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 244, in grad_graph  *\n",
      "        out = self.model(shap_rAnD)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 371, in custom_grad\n",
      "        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefix before the lookup\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 663, in handler\n",
      "        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 670, in linearity_with_excluded_handler\n",
      "        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 222, in _variable_inputs\n",
      "        out[i] = t.name in self.between_tensors\n",
      "\n",
      "    AttributeError: Exception encountered when calling layer 'lstm' (type LSTM).\n",
      "    \n",
      "    'TFDeep' object has no attribute 'between_tensors'\n",
      "    \n",
      "    Call arguments received by layer 'lstm' (type LSTM):\n",
      "       inputs=tf.Tensor(shape=(82034, 55, 1), dtype=float32)\n",
      "       mask=None\n",
      "       training=False\n",
      "       initial_state=None\n",
      "\n",
      "\n",
      "Hasil Evaluasi ML/DL tanpa XAI:\n",
      "[['DecisionTree', 1.0, 0.999886736889795, 0.9999433652375829, 0.9999431139427726, 0.9012298583984375], ['RandomForest', 0.999886736889795, 0.999886736889795, 0.999886736889795, 0.9998862278855453, 4.538815498352051], ['Logistic Regression', 0.994912379875636, 0.9967153698040548, 0.9958130587303384, 0.9957904317651743, 0.76228928565979], ['Naive Bayes', 0.9897534061479563, 0.9955827387020048, 0.9926595143986447, 0.9926048125604414, 0.12760472297668457], ['MLP', 0.9981879954699887, 0.9983010533469249, 0.9982445212073163, 0.9982365322259514, 8.944763898849487], ['Stochastic Gradient Descent', 0.9906521004617637, 0.9962623173632348, 0.9934492884571945, 0.9934012173616247, 0.24507379531860352], ['ADA Boost', 1.0, 1.0, 1.0, 1.0, 23.554849863052368], ['Gradient Boosting', 1.0, 0.9996602106693849, 0.9998300764655904, 0.9998293418283178, 46.45119547843933], ['XGBoost', 1.0, 0.999886736889795, 0.9999433652375829, 0.9999431139427726, 35.61520767211914], ['LightGBM', 0.9998867497168743, 1.0, 0.9999433716518489, 0.9999431139427726, 60.4275918006897], ['CatBoost', 1.0, 1.0, 1.0, 1.0, 5.004649639129639], ['DNN', 0.9984150345296049, 0.9988673688979499, 0.9986411504925831, 0.9986347346265431, 9.728044271469116], ['CNN', 0.9981892258940697, 0.9989806320081549, 0.9985847721483159, 0.9985778485693156, 20.57917618751526], ['RNN', 0.9953430258973194, 0.9925246347264696, 0.9939318323597799, 0.993913191876671, 158.88436937332153]]\n",
      "\n",
      "Hasil Evaluasi ML/DL dengan XAI:\n",
      "[['DecisionTree', 1.0, 0.999886736889795, 0.9999433652375829, 0.9999431139427726, 0.9386115074157715, {'SHAP': array([[ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 5.60498322e-04, -5.60498322e-04],\n",
      "       [-6.70521645e-03,  6.70521645e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 2.31287331e-03, -2.31287331e-03],\n",
      "       [-1.06923033e-03,  1.06923033e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.63547415e-04, -1.63547415e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-5.64082143e-04,  5.64082143e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 2.20547244e-03, -2.20547244e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-2.93532055e-05,  2.93532055e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 5.00927243e-03, -5.00927243e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.71341942e-02,  1.71341942e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 3.06029922e-03, -3.06029922e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]])}], ['RandomForest', 1.0, 0.999886736889795, 0.9999433652375829, 0.9999431139427726, 4.949376106262207, {'SHAP': array([[-8.91176973e-05,  8.91176973e-05],\n",
      "       [-7.38954434e-04,  7.38954434e-04],\n",
      "       [-7.34007623e-04,  7.34007623e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.51412708e-03,  1.51412708e-03],\n",
      "       [-4.25795552e-04,  4.25795552e-04],\n",
      "       [-1.32124694e-03,  1.32124694e-03],\n",
      "       [-8.48011832e-05,  8.48011832e-05],\n",
      "       [ 6.65769384e-04, -6.65769384e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-3.81194607e-04,  3.81194607e-04],\n",
      "       [-6.96867854e-04,  6.96867854e-04],\n",
      "       [ 6.68866261e-06, -6.68866261e-06],\n",
      "       [-6.33801695e-04,  6.33801695e-04],\n",
      "       [-8.16081688e-04,  8.16081688e-04],\n",
      "       [ 6.24404119e-05, -6.24404119e-05],\n",
      "       [ 5.32612777e-04, -5.32612777e-04],\n",
      "       [-1.17506115e-04,  1.17506115e-04],\n",
      "       [ 2.54821093e-04, -2.54821093e-04],\n",
      "       [ 6.29064224e-04, -6.29064224e-04],\n",
      "       [ 3.95900791e-04, -3.95900791e-04],\n",
      "       [ 3.95262529e-04, -3.95262529e-04],\n",
      "       [ 1.63087775e-04, -1.63087775e-04],\n",
      "       [ 1.05232380e-04, -1.05232380e-04],\n",
      "       [-3.55037260e-05,  3.55037260e-05],\n",
      "       [ 3.42962626e-04, -3.42962626e-04],\n",
      "       [-3.01529097e-04,  3.01529097e-04],\n",
      "       [-2.37121566e-04,  2.37121566e-04],\n",
      "       [-2.56182946e-04,  2.56182946e-04],\n",
      "       [ 3.42415382e-04, -3.42415382e-04],\n",
      "       [ 3.41669037e-05, -3.41669037e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 4.71300984e-05, -4.71300984e-05],\n",
      "       [ 1.01211673e-05, -1.01211673e-05],\n",
      "       [-1.37163661e-05,  1.37163661e-05],\n",
      "       [ 2.06541897e-05, -2.06541897e-05],\n",
      "       [-7.19740600e-04,  7.19740600e-04],\n",
      "       [ 3.49143865e-05, -3.49143865e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.01332271e-04, -1.01332271e-04],\n",
      "       [ 1.30749189e-04, -1.30749189e-04],\n",
      "       [ 6.02923943e-05, -6.02923943e-05],\n",
      "       [-2.10168952e-04,  2.10168952e-04],\n",
      "       [-2.00227544e-05,  2.00227544e-05],\n",
      "       [-1.50168952e-04,  1.50168952e-04],\n",
      "       [-2.47901473e-04,  2.47901473e-04],\n",
      "       [ 7.94561693e-05, -7.94561693e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-6.62545196e-03,  6.62545196e-03],\n",
      "       [-3.42406280e-04,  3.42406280e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 2.77362762e-04, -2.77362762e-04],\n",
      "       [-3.08834405e-04,  3.08834405e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]])}], ['Logistic Regression', 0.994912379875636, 0.9967153698040548, 0.9958130587303384, 0.9957904317651743, 0.6337947845458984, {'SHAP': array([[-6.16954577e-05,  6.16954577e-05],\n",
      "       [-6.86382445e-04,  6.86382445e-04],\n",
      "       [-5.85483077e-03,  5.85483077e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-4.77986896e-07,  4.77986896e-07],\n",
      "       [ 6.66273675e-05, -6.66273675e-05],\n",
      "       [-2.88140592e-03,  2.88140592e-03],\n",
      "       [ 1.22441890e-07, -1.22441890e-07],\n",
      "       [-3.16152334e-07,  3.16152334e-07],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-6.22639542e-09,  6.22639542e-09],\n",
      "       [-4.48462474e-04,  4.48462474e-04],\n",
      "       [-3.46281845e-05,  3.46281845e-05],\n",
      "       [ 2.91563037e-04, -2.91563037e-04],\n",
      "       [-8.16222398e-05,  8.16222398e-05],\n",
      "       [-5.46607607e-05,  5.46607607e-05],\n",
      "       [-1.70246470e-05,  1.70246470e-05],\n",
      "       [ 4.55399092e-07, -4.55399092e-07],\n",
      "       [-3.91708697e-06,  3.91708697e-06],\n",
      "       [ 4.35364007e-03, -4.35364007e-03],\n",
      "       [ 2.21163827e-03, -2.21163827e-03],\n",
      "       [ 1.14133313e-03, -1.14133313e-03],\n",
      "       [ 2.25118559e-03, -2.25118559e-03],\n",
      "       [ 6.09269744e-05, -6.09269744e-05],\n",
      "       [ 1.05494064e-05, -1.05494064e-05],\n",
      "       [ 6.10906592e-05, -6.10906592e-05],\n",
      "       [ 1.05805423e-04, -1.05805423e-04],\n",
      "       [-4.65584749e-05,  4.65584749e-05],\n",
      "       [ 1.06764339e-04, -1.06764339e-04],\n",
      "       [ 2.61966886e-05, -2.61966886e-05],\n",
      "       [ 1.24511913e-05, -1.24511913e-05],\n",
      "       [-3.61100074e-05,  3.61100074e-05],\n",
      "       [ 1.02012249e-05, -1.02012249e-05],\n",
      "       [ 9.70470048e-06, -9.70470048e-06],\n",
      "       [ 9.86553265e-06, -9.86553265e-06],\n",
      "       [ 1.10827764e-05, -1.10827764e-05],\n",
      "       [-1.63773828e-05,  1.63773828e-05],\n",
      "       [ 5.21955542e-05, -5.21955542e-05],\n",
      "       [-1.45967831e-05,  1.45967831e-05],\n",
      "       [ 2.63130637e-04, -2.63130637e-04],\n",
      "       [ 1.58546084e-05, -1.58546084e-05],\n",
      "       [ 2.74691884e-04, -2.74691884e-04],\n",
      "       [ 1.81328206e-04, -1.81328206e-04],\n",
      "       [-1.09711717e-04,  1.09711717e-04],\n",
      "       [-1.58232388e-04,  1.58232388e-04],\n",
      "       [-6.14824695e-05,  6.14824695e-05],\n",
      "       [-2.86377592e-06,  2.86377592e-06],\n",
      "       [ 1.52770028e-09, -1.52770028e-09],\n",
      "       [-5.30057766e-03,  5.30057766e-03],\n",
      "       [-3.05960063e-06,  3.05960063e-06],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 6.87656189e-05, -6.87656189e-05],\n",
      "       [-1.01750970e-03,  1.01750970e-03],\n",
      "       [-6.73071130e-06,  6.73071130e-06],\n",
      "       [-2.16657310e-09,  2.16657310e-09]])}], ['Naive Bayes', 0.9897534061479563, 0.9955827387020048, 0.9926595143986447, 0.9926048125604414, 0.09102296829223633, {'SHAP': array([[ 2.68018511e-04, -2.68018511e-04],\n",
      "       [-8.92350995e-05,  8.92350995e-05],\n",
      "       [-3.72368991e-04,  3.72368991e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-4.09075049e-04,  4.09075049e-04],\n",
      "       [ 1.11025192e-04, -1.11025192e-04],\n",
      "       [-5.62665145e-04,  5.62665145e-04],\n",
      "       [-1.95140632e-04,  1.95140632e-04],\n",
      "       [-4.26568617e-04,  4.26568617e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-5.90281910e-04,  5.90281910e-04],\n",
      "       [-7.02444361e-04,  7.02444361e-04],\n",
      "       [-5.69784781e-05,  5.69784781e-05],\n",
      "       [ 4.39857074e-04, -4.39857074e-04],\n",
      "       [-7.02528219e-04,  7.02528219e-04],\n",
      "       [ 7.73818448e-05, -7.73818448e-05],\n",
      "       [ 5.35672556e-05, -5.35672556e-05],\n",
      "       [-1.39173847e-04,  1.39173847e-04],\n",
      "       [-6.48378547e-04,  6.48378547e-04],\n",
      "       [ 7.87068510e-04, -7.87068510e-04],\n",
      "       [ 1.59294001e-03, -1.59294001e-03],\n",
      "       [ 8.04772105e-04, -8.04772105e-04],\n",
      "       [ 1.55026544e-03, -1.55026544e-03],\n",
      "       [ 1.18970829e-05, -1.18970829e-05],\n",
      "       [ 3.76855823e-04, -3.76855823e-04],\n",
      "       [ 4.64349693e-05, -4.64349693e-05],\n",
      "       [ 4.34851507e-04, -4.34851507e-04],\n",
      "       [-2.16733882e-03,  2.16733882e-03],\n",
      "       [ 6.11349149e-04, -6.11349149e-04],\n",
      "       [ 1.31194448e-03, -1.31194448e-03],\n",
      "       [-7.86801642e-06,  7.86801642e-06],\n",
      "       [-4.83688743e-04,  4.83688743e-04],\n",
      "       [-5.93808762e-05,  5.93808762e-05],\n",
      "       [-4.46526828e-06,  4.46526828e-06],\n",
      "       [-5.02511349e-05,  5.02511349e-05],\n",
      "       [-6.94866280e-06,  6.94866280e-06],\n",
      "       [-4.05526709e-05,  4.05526709e-05],\n",
      "       [-1.31588977e-05,  1.31588977e-05],\n",
      "       [-2.23323674e-04,  2.23323674e-04],\n",
      "       [-1.50319469e-05,  1.50319469e-05],\n",
      "       [-1.47760423e-05,  1.47760423e-05],\n",
      "       [-1.50094423e-05,  1.50094423e-05],\n",
      "       [-2.09475321e-05,  2.09475321e-05],\n",
      "       [-2.08995353e-05,  2.08995353e-05],\n",
      "       [ 1.44881213e-04, -1.44881213e-04],\n",
      "       [-4.29318267e-04,  4.29318267e-04],\n",
      "       [-5.11802096e-04,  5.11802096e-04],\n",
      "       [-5.52361592e-05,  5.52361592e-05],\n",
      "       [-1.34702902e-03,  1.34702902e-03],\n",
      "       [-5.57850818e-04,  5.57850818e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-2.76105605e-05,  2.76105605e-05],\n",
      "       [-2.64184262e-03,  2.64184262e-03],\n",
      "       [-1.80351160e-04,  1.80351160e-04],\n",
      "       [-9.16561922e-06,  9.16561922e-06]])}], ['MLP', 0.9981879954699887, 0.9983010533469249, 0.9982445212073163, 0.9982365322259514, 6.634045124053955, {'SHAP': array([[-6.28267590e-04,  6.28267590e-04],\n",
      "       [-1.72958459e-03,  1.72958459e-03],\n",
      "       [-4.73854505e-03,  4.73854505e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.52179365e-05,  1.52179365e-05],\n",
      "       [ 6.67760456e-04, -6.67760456e-04],\n",
      "       [-1.99853371e-03,  1.99853371e-03],\n",
      "       [ 2.03755949e-05, -2.03755949e-05],\n",
      "       [-1.18324692e-05,  1.18324692e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 6.51042132e-06, -6.51042132e-06],\n",
      "       [-3.78613096e-04,  3.78613096e-04],\n",
      "       [-4.09391889e-04,  4.09391889e-04],\n",
      "       [-4.67219210e-04,  4.67219210e-04],\n",
      "       [-3.77243436e-04,  3.77243436e-04],\n",
      "       [-5.04347584e-04,  5.04347584e-04],\n",
      "       [-2.25449381e-04,  2.25449381e-04],\n",
      "       [ 3.08814938e-05, -3.08814938e-05],\n",
      "       [-5.72148990e-05,  5.72148990e-05],\n",
      "       [ 3.98654061e-03, -3.98654061e-03],\n",
      "       [ 2.90424817e-03, -2.90424817e-03],\n",
      "       [ 8.44675494e-04, -8.44675494e-04],\n",
      "       [ 3.39620225e-03, -3.39620225e-03],\n",
      "       [-2.44456396e-04,  2.44456396e-04],\n",
      "       [-3.28465305e-04,  3.28465305e-04],\n",
      "       [-1.13142796e-04,  1.13142796e-04],\n",
      "       [ 8.90210215e-05, -8.90210215e-05],\n",
      "       [-6.11186711e-04,  6.11186711e-04],\n",
      "       [ 3.18191707e-04, -3.18191707e-04],\n",
      "       [-1.08401907e-04,  1.08401907e-04],\n",
      "       [ 2.36509178e-04, -2.36509178e-04],\n",
      "       [-1.29608383e-04,  1.29608383e-04],\n",
      "       [ 1.22008868e-04, -1.22008868e-04],\n",
      "       [ 1.41489909e-04, -1.41489909e-04],\n",
      "       [ 1.29196075e-04, -1.29196075e-04],\n",
      "       [ 1.44814626e-04, -1.44814626e-04],\n",
      "       [-3.01283635e-04,  3.01283635e-04],\n",
      "       [-1.42037080e-04,  1.42037080e-04],\n",
      "       [-5.03229227e-06,  5.03229227e-06],\n",
      "       [ 6.40211124e-04, -6.40211124e-04],\n",
      "       [-1.13345971e-04,  1.13345971e-04],\n",
      "       [ 1.83337357e-04, -1.83337357e-04],\n",
      "       [ 8.84551186e-05, -8.84551186e-05],\n",
      "       [-9.74010076e-04,  9.74010076e-04],\n",
      "       [-3.92889030e-04,  3.92889030e-04],\n",
      "       [ 9.49348330e-05, -9.49348330e-05],\n",
      "       [ 1.39390364e-05, -1.39390364e-05],\n",
      "       [ 1.18322093e-05, -1.18322093e-05],\n",
      "       [-4.84380337e-03,  4.84380337e-03],\n",
      "       [ 1.16974841e-05, -1.16974841e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-3.11693971e-04,  3.11693971e-04],\n",
      "       [ 4.90294413e-05, -4.90294413e-05],\n",
      "       [-7.24293188e-05,  7.24293188e-05],\n",
      "       [ 2.44258812e-05, -2.44258812e-05]])}], ['Stochastic Gradient Descent', 0.9906521004617637, 0.9962623173632348, 0.9934492884571945, 0.9934012173616247, 0.13245606422424316, {'SHAP': array([[-1.61609205e-05,  1.61609205e-05],\n",
      "       [-6.21105112e-04,  6.21105112e-04],\n",
      "       [-5.63652087e-03,  5.63652087e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-4.12020417e-07,  4.12020417e-07],\n",
      "       [-4.41540358e-05,  4.41540358e-05],\n",
      "       [-4.03770898e-03,  4.03770898e-03],\n",
      "       [ 2.07785492e-08, -2.07785492e-08],\n",
      "       [-1.85974355e-07,  1.85974355e-07],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-4.63635939e-08,  4.63635940e-08],\n",
      "       [-7.60053457e-04,  7.60053457e-04],\n",
      "       [ 1.25763470e-05, -1.25763470e-05],\n",
      "       [ 3.68507054e-04, -3.68507054e-04],\n",
      "       [-1.52252528e-04,  1.52252528e-04],\n",
      "       [-1.84674526e-05,  1.84674526e-05],\n",
      "       [ 5.43782744e-07, -5.43782744e-07],\n",
      "       [-8.05155579e-06,  8.05155579e-06],\n",
      "       [-7.09107911e-06,  7.09107911e-06],\n",
      "       [ 3.76421137e-03, -3.76421137e-03],\n",
      "       [ 2.18039676e-03, -2.18039676e-03],\n",
      "       [ 1.14733123e-03, -1.14733123e-03],\n",
      "       [ 2.20441021e-03, -2.20441021e-03],\n",
      "       [ 7.63459257e-05, -7.63459257e-05],\n",
      "       [ 1.21983173e-05, -1.21983173e-05],\n",
      "       [ 7.31562653e-05, -7.31562653e-05],\n",
      "       [ 8.50717104e-05, -8.50717104e-05],\n",
      "       [-3.44064725e-05,  3.44064725e-05],\n",
      "       [ 8.19917404e-05, -8.19917404e-05],\n",
      "       [ 1.52443970e-05, -1.52443970e-05],\n",
      "       [ 5.40609850e-06, -5.40609850e-06],\n",
      "       [-2.97927736e-05,  2.97927736e-05],\n",
      "       [ 5.59522449e-06, -5.59522449e-06],\n",
      "       [ 4.30077060e-06, -4.30077060e-06],\n",
      "       [ 5.41342795e-06, -5.41342795e-06],\n",
      "       [ 5.62060894e-06, -5.62060894e-06],\n",
      "       [-9.74000667e-06,  9.74000667e-06],\n",
      "       [ 1.10938908e-04, -1.10938908e-04],\n",
      "       [-9.46518622e-06,  9.46518622e-06],\n",
      "       [ 2.10905700e-04, -2.10905700e-04],\n",
      "       [ 3.04254081e-05, -3.04254081e-05],\n",
      "       [ 2.43930001e-04, -2.43930001e-04],\n",
      "       [ 1.97151433e-04, -1.97151433e-04],\n",
      "       [ 6.96439251e-05, -6.96439251e-05],\n",
      "       [-9.21895545e-05,  9.21895545e-05],\n",
      "       [-2.72265303e-05,  2.72265303e-05],\n",
      "       [ 1.68002228e-06, -1.68002228e-06],\n",
      "       [ 3.22174261e-06, -3.22174261e-06],\n",
      "       [-3.75361883e-03,  3.75361883e-03],\n",
      "       [-1.40838422e-05,  1.40838422e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.77019714e-05, -1.77019714e-05],\n",
      "       [-8.26878178e-04,  8.26878178e-04],\n",
      "       [-4.45963776e-06,  4.45963776e-06],\n",
      "       [ 3.03530214e-06, -3.03530214e-06]])}], ['ADA Boost', 1.0, 1.0, 1.0, 1.0, 18.9148006439209, {'SHAP': array([[ 2.86007251e-04, -2.86007251e-04],\n",
      "       [-1.48467937e-04,  1.48467937e-04],\n",
      "       [ 4.18780183e-04, -4.18780183e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 6.13699071e-05, -6.13699071e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 9.81740873e-05, -9.81740873e-05],\n",
      "       [-2.95096439e-05,  2.95096439e-05],\n",
      "       [-2.88649014e-04,  2.88649014e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-8.20013050e-05,  8.20013050e-05],\n",
      "       [-1.22996034e-04,  1.22996034e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-3.30656245e-06,  3.30656245e-06],\n",
      "       [-2.75243594e-04,  2.75243594e-04],\n",
      "       [ 1.33973318e-04, -1.33973318e-04],\n",
      "       [-9.03375595e-06,  9.03375595e-06],\n",
      "       [ 2.40303089e-04, -2.40303089e-04],\n",
      "       [ 5.50286729e-05, -5.50286729e-05],\n",
      "       [ 1.20616025e-03, -1.20616025e-03],\n",
      "       [ 9.23990604e-04, -9.23990604e-04],\n",
      "       [-7.56298203e-05,  7.56298203e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 2.75629024e-03, -2.75629024e-03],\n",
      "       [ 3.33626998e-04, -3.33626998e-04],\n",
      "       [ 2.27635682e-03, -2.27635682e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-3.12579171e-05,  3.12579171e-05],\n",
      "       [ 1.05339144e-04, -1.05339144e-04],\n",
      "       [ 1.37850755e-05, -1.37850755e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 6.77958802e-05, -6.77958802e-05],\n",
      "       [-5.72703064e-06,  5.72703064e-06],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 3.59356002e-04, -3.59356002e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-3.82493483e-05,  3.82493483e-05],\n",
      "       [-1.35422572e-04,  1.35422572e-04],\n",
      "       [ 1.42209520e-04, -1.42209520e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.18361610e-04,  1.18361610e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.46645973e-02,  1.46645973e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 5.71257172e-04, -5.71257172e-04],\n",
      "       [ 9.64698652e-04, -9.64698652e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]])}], ['Gradient Boosting', 1.0, 0.9996602106693849, 0.9998300764655904, 0.9998293418283178, 44.45885467529297, {'SHAP': array([[ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-7.60092415e-05,  7.60092415e-05],\n",
      "       [ 6.62337464e-07, -6.62337464e-07],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.33890023e-03, -1.33890023e-03],\n",
      "       [-2.55177355e-06,  2.55177355e-06],\n",
      "       [ 5.74869156e-07, -5.74869156e-07],\n",
      "       [ 1.24315850e-04, -1.24315850e-04],\n",
      "       [-4.96999416e-03,  4.96999416e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 3.13349816e-05, -3.13349816e-05],\n",
      "       [ 1.44464821e-03, -1.44464821e-03],\n",
      "       [-1.57611545e-03,  1.57611545e-03],\n",
      "       [-2.97903950e-04,  2.97903950e-04],\n",
      "       [-6.99075781e-04,  6.99075781e-04],\n",
      "       [-1.60788237e-05,  1.60788237e-05],\n",
      "       [-1.47096703e-05,  1.47096703e-05],\n",
      "       [-6.48469916e-05,  6.48469916e-05],\n",
      "       [ 2.17604211e-05, -2.17604211e-05],\n",
      "       [ 4.44002720e-04, -4.44002720e-04],\n",
      "       [ 5.50804184e-05, -5.50804184e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.01557406e-04, -1.01557406e-04],\n",
      "       [ 9.32463096e-04, -9.32463096e-04],\n",
      "       [-1.73320835e-04,  1.73320835e-04],\n",
      "       [ 5.09629476e-04, -5.09629476e-04],\n",
      "       [ 7.52942407e-06, -7.52942407e-06],\n",
      "       [-5.64738544e-05,  5.64738544e-05],\n",
      "       [ 1.64635061e-04, -1.64635061e-04],\n",
      "       [ 8.38329838e-05, -8.38329838e-05],\n",
      "       [-1.08692958e-05,  1.08692958e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.80089484e-06,  1.80089484e-06],\n",
      "       [-8.32094030e-06,  8.32094030e-06],\n",
      "       [-4.71835920e-06,  4.71835920e-06],\n",
      "       [-2.81260862e-06,  2.81260862e-06],\n",
      "       [-1.17544729e-04,  1.17544729e-04],\n",
      "       [-5.18303982e-06,  5.18303982e-06],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 2.56912072e-05, -2.56912072e-05],\n",
      "       [ 1.39032190e-05, -1.39032190e-05],\n",
      "       [-4.83866625e-05,  4.83866625e-05],\n",
      "       [ 2.82428037e-06, -2.82428037e-06],\n",
      "       [ 1.78617478e-05, -1.78617478e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 4.00505200e-03, -4.00505200e-03],\n",
      "       [ 5.44298182e-05, -5.44298182e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.42337616e-02,  1.42337616e-02],\n",
      "       [ 5.15822683e-04, -5.15822683e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-8.53582017e-05,  8.53582017e-05],\n",
      "       [ 5.65952937e-04, -5.65952937e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]])}], ['XGBoost', 1.0, 0.999886736889795, 0.9999433652375829, 0.9999431139427726, 22.88760733604431, {'SHAP': array([[-9.70662905e-07,  9.70662853e-07],\n",
      "       [-3.26014070e-04,  3.26014028e-04],\n",
      "       [-1.74745826e-03,  1.74745825e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-2.15075087e-04,  2.15075135e-04],\n",
      "       [-2.52164029e-05,  2.52164038e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-3.41159710e-05,  3.41159716e-05],\n",
      "       [-9.75879099e-03,  9.75879105e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 7.52015363e-06, -7.52012053e-06],\n",
      "       [ 1.05901306e-05, -1.05901194e-05],\n",
      "       [-2.44018843e-04,  2.44018843e-04],\n",
      "       [-2.94873469e-04,  2.94873520e-04],\n",
      "       [-1.04187192e-03,  1.04187186e-03],\n",
      "       [-1.75322734e-04,  1.75322705e-04],\n",
      "       [ 4.84196880e-05, -4.84196734e-05],\n",
      "       [ 4.30104454e-05, -4.30104494e-05],\n",
      "       [-7.10664135e-05,  7.10663975e-05],\n",
      "       [ 4.79359784e-04, -4.79359813e-04],\n",
      "       [ 2.12083798e-04, -2.12083833e-04],\n",
      "       [-4.65358423e-05,  4.65358431e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 3.59973729e-03, -3.59973700e-03],\n",
      "       [ 1.15017609e-03, -1.15017636e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.09438850e-04, -1.09438843e-04],\n",
      "       [-2.65365845e-04,  2.65365808e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.04416403e-04, -1.04416509e-04],\n",
      "       [-2.88288111e-06,  2.88288292e-06],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.31235212e-06, -1.31235014e-06],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.26626559e-04,  1.26626473e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-5.83683009e-05,  5.83683160e-05],\n",
      "       [ 6.66800953e-05, -6.66800627e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.69792612e-04, -1.69792663e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.93267888e-05,  1.93267887e-05],\n",
      "       [-1.30043118e-04,  1.30043196e-04],\n",
      "       [-1.18482411e-05,  1.18482625e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 6.46859258e-03, -6.46859254e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.26909188e-02,  1.26909188e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.95333904e-05, -1.95333785e-05],\n",
      "       [ 2.68028912e-03, -2.68028912e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]])}], ['LightGBM', 0.9998867497168743, 1.0, 0.9999433716518489, 0.9999431139427726, 0.7945973873138428, {'SHAP': array([[-7.91461311e-05,  7.91461311e-05],\n",
      "       [ 5.51105679e-06, -5.51105679e-06],\n",
      "       [-2.32565509e-04,  2.32565509e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.57545922e-04,  1.57545922e-04],\n",
      "       [-1.06576915e-04,  1.06576915e-04],\n",
      "       [ 2.83138584e-04, -2.83138584e-04],\n",
      "       [-1.14713751e-04,  1.14713751e-04],\n",
      "       [-4.74831094e-03,  4.74831094e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-3.55741454e-05,  3.55741454e-05],\n",
      "       [-5.08585522e-04,  5.08585522e-04],\n",
      "       [-1.16946857e-04,  1.16946857e-04],\n",
      "       [-1.03165510e-04,  1.03165510e-04],\n",
      "       [-1.12979185e-03,  1.12979185e-03],\n",
      "       [-2.33767957e-04,  2.33767957e-04],\n",
      "       [-2.27203615e-05,  2.27203615e-05],\n",
      "       [ 2.37898301e-04, -2.37898301e-04],\n",
      "       [-5.72480841e-07,  5.72480841e-07],\n",
      "       [ 1.31515618e-04, -1.31515618e-04],\n",
      "       [-2.19572754e-05,  2.19572754e-05],\n",
      "       [-5.72212279e-04,  5.72212279e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 2.39261970e-04, -2.39261970e-04],\n",
      "       [-6.53691381e-04,  6.53691381e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.47971623e-04, -1.47971623e-04],\n",
      "       [-3.38378512e-04,  3.38378512e-04],\n",
      "       [ 1.88840608e-05, -1.88840608e-05],\n",
      "       [-1.99817120e-04,  1.99817120e-04],\n",
      "       [ 1.86213630e-07, -1.86213630e-07],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.00368737e-04, -1.00368737e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.50283662e-05, -1.50283662e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 4.44890571e-04, -4.44890571e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.26202790e-04, -1.26202790e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 8.29161903e-05, -8.29161903e-05],\n",
      "       [ 8.51178693e-05, -8.51178693e-05],\n",
      "       [ 5.17972440e-05, -5.17972440e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 6.93923390e-03, -6.93923390e-03],\n",
      "       [-4.59881475e-07,  4.59881475e-07],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.62257244e-02,  1.62257244e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-7.58533193e-05,  7.58533193e-05],\n",
      "       [ 4.46922488e-03, -4.46922488e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]])}], ['CatBoost', 1.0, 1.0, 1.0, 1.0, 2.570887565612793, {'SHAP': array([[-1.01171823e-05,  1.01171823e-05],\n",
      "       [ 4.09042763e-05, -4.09042763e-05],\n",
      "       [ 1.38933270e-04, -1.38933270e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 9.92426552e-05, -9.92426552e-05],\n",
      "       [-1.56656780e-04,  1.56656780e-04],\n",
      "       [-4.50794282e-04,  4.50794282e-04],\n",
      "       [ 1.17207840e-04, -1.17207840e-04],\n",
      "       [-1.19272768e-04,  1.19272768e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-9.20814057e-05,  9.20814057e-05],\n",
      "       [-6.98964046e-04,  6.98964046e-04],\n",
      "       [ 8.11137085e-09, -8.11137086e-09],\n",
      "       [ 2.08745380e-07, -2.08745380e-07],\n",
      "       [ 1.07702099e-04, -1.07702099e-04],\n",
      "       [-6.36987818e-05,  6.36987818e-05],\n",
      "       [ 2.36158436e-04, -2.36158436e-04],\n",
      "       [ 7.30355562e-05, -7.30355562e-05],\n",
      "       [ 5.52650332e-05, -5.52650332e-05],\n",
      "       [-3.31192413e-04,  3.31192413e-04],\n",
      "       [ 6.20841530e-05, -6.20841530e-05],\n",
      "       [ 2.85354629e-05, -2.85354629e-05],\n",
      "       [ 1.38178258e-03, -1.38178258e-03],\n",
      "       [ 2.38648740e-03, -2.38648740e-03],\n",
      "       [ 1.17387051e-04, -1.17387051e-04],\n",
      "       [ 1.61256705e-04, -1.61256705e-04],\n",
      "       [-1.31014786e-05,  1.31014786e-05],\n",
      "       [-5.26654770e-04,  5.26654770e-04],\n",
      "       [ 1.15453305e-05, -1.15453305e-05],\n",
      "       [ 6.86584115e-06, -6.86584115e-06],\n",
      "       [-3.58119075e-06,  3.58119075e-06],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.09677815e-05,  1.09677815e-05],\n",
      "       [-3.09529455e-05,  3.09529455e-05],\n",
      "       [-3.83623046e-09,  3.83623046e-09],\n",
      "       [ 8.07534267e-11, -8.07534267e-11],\n",
      "       [-8.39994225e-04,  8.39994225e-04],\n",
      "       [ 2.33156158e-04, -2.33156158e-04],\n",
      "       [-1.89496754e-09,  1.89496754e-09],\n",
      "       [-7.11836930e-05,  7.11836930e-05],\n",
      "       [-9.13216218e-05,  9.13216218e-05],\n",
      "       [ 3.67305608e-04, -3.67305608e-04],\n",
      "       [ 1.67167701e-05, -1.67167701e-05],\n",
      "       [ 3.36572360e-05, -3.36572360e-05],\n",
      "       [-1.29869579e-05,  1.29869579e-05],\n",
      "       [ 1.71448034e-03, -1.71448034e-03],\n",
      "       [-1.68446255e-04,  1.68446255e-04],\n",
      "       [ 3.95111289e-11, -3.95111289e-11],\n",
      "       [-2.13867178e-02,  2.13867178e-02],\n",
      "       [ 7.47113334e-04, -7.47113334e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 5.48914894e-06, -5.48914894e-06],\n",
      "       [ 4.72768914e-03, -4.72768914e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]])}], ['DNN', 0.998755374519122, 0.99977347377959, 0.9992641648270787, 0.9992604812560442, 22.898216485977173, {'SHAP': array([0.00906633])}], ['CNN', 0.9981869688385269, 0.9977347377958998, 0.9979608020845134, 0.9979521019398145, 16.793054342269897, {'SHAP': None}], ['RNN', 1.0, 0.026050515347151432, 0.05077823159289104, 0.5108367939018147, 126.38613486289978, {'SHAP': None}]]\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi variabel untuk menyimpan hasil evaluasi\n",
    "hasil_ml_dl = []\n",
    "hasil_ml_dl_xai = []\n",
    "\n",
    "# Encode labels ke bentuk numerik jika diperlukan\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Fungsi untuk mengevaluasi model ML/DL\n",
    "def EvaluateModel(model_name, model, X_train, y_train, X_test, y_test, use_xai=False, is_dl_model=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Melatih model\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0) if is_dl_model else model.fit(X_train, y_train)\n",
    "    \n",
    "    if is_dl_model:\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    elif hasattr(model, 'predict_proba'):\n",
    "        # Model dengan metode predict_proba\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        if y_pred_proba.shape[1] > 1:  # Model klasifikasi multi-kelas\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        else:  # Model klasifikasi biner\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    else:\n",
    "        # Model tanpa metode predict_proba\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "\n",
    "    # Menghitung confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Menghitung metrik\n",
    "    Precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    Recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    F1Score = 2 * ((Precision * Recall) / (Precision + Recall)) if (Precision + Recall) != 0 else 0\n",
    "    Accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) != 0 else 0\n",
    "\n",
    "    # Menghitung waktu running\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "    # Jika XAI diperlukan, tambahkan analisis dengan SHAP\n",
    "    if use_xai:\n",
    "        # Periksa apakah X_train adalah DataFrame\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            feature_names = X_train.columns\n",
    "        else:\n",
    "            feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "        \n",
    "        # Perbaiki format X_train untuk SHAP\n",
    "        if is_dl_model:\n",
    "            X_train_for_xai = X_train.reshape((X_train.shape[0], X_train.shape[1]))\n",
    "            X_test_for_xai = X_test.reshape((X_test.shape[0], X_test.shape[1]))\n",
    "        else:\n",
    "            X_train_for_xai = X_train\n",
    "            X_test_for_xai = X_test\n",
    "\n",
    "        # Gunakan SHAP\n",
    "        try:\n",
    "            if is_dl_model:\n",
    "                explainer = shap.DeepExplainer(model, X_train_for_xai)\n",
    "                shap_values = explainer.shap_values(X_test_for_xai)\n",
    "                shap_summary = np.mean(shap_values[0], axis=0)\n",
    "            else:\n",
    "                explainer = shap.Explainer(model.predict_proba, X_train_for_xai)\n",
    "                shap_values = explainer(X_test_for_xai)\n",
    "                shap_summary = shap_values.values.mean(axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error using SHAP with {model_name}: {e}\")\n",
    "            shap_summary = None\n",
    "\n",
    "        # Simpan hasil evaluasi dengan XAI\n",
    "        hasil_ml_dl_xai.append([model_name, Precision, Recall, F1Score, Accuracy, run_time, {'SHAP': shap_summary}])\n",
    "    else:\n",
    "        # Simpan hasil evaluasi tanpa XAI\n",
    "        hasil_ml_dl.append([model_name, Precision, Recall, F1Score, Accuracy, run_time])\n",
    "\n",
    "# Model ML dan DL yang akan dievaluasi\n",
    "model_ml_dl = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=10),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=50),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0, max_iter=10000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000),\n",
    "    \"Stochastic Gradient Descent\": SGDClassifier(loss='log_loss', random_state=42),\n",
    "    \"ADA Boost\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='Logloss')\n",
    "}\n",
    "\n",
    "model_dl = {\n",
    "    \"DNN\": Sequential([\n",
    "        Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"CNN\": Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"RNN\": Sequential([\n",
    "        LSTM(100, input_shape=(X_train.shape[1], 1)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Pastikan X_train dan X_test memiliki bentuk yang sesuai untuk DL\n",
    "X_train_dl = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_dl = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Mengevaluasi model ML tanpa XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=False)\n",
    "\n",
    "# Mengevaluasi model DL tanpa XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=False, is_dl_model=True)\n",
    "\n",
    "# Mengevaluasi model ML dengan XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=True)\n",
    "\n",
    "# Mengevaluasi model DL dengan XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=True, is_dl_model=True)\n",
    "\n",
    "# Print hasil evaluasi tanpa XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL tanpa XAI:\")\n",
    "print(hasil_ml_dl)\n",
    "\n",
    "# Print hasil evaluasi dengan XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL dengan XAI:\")\n",
    "print(hasil_ml_dl_xai)\n",
    "\n",
    "# Convert results to DataFrame and save to CSV\n",
    "df_ml_dl = pd.DataFrame(hasil_ml_dl, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\"])\n",
    "df_ml_dl_xai = pd.DataFrame(hasil_ml_dl_xai, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\", \"XAI\"])\n",
    "\n",
    "df_ml_dl.to_csv(\"hasil_evaluasi_ml_dl_GAFC.csv\", index=False)\n",
    "df_ml_dl_xai.to_csv(\"hasil_evaluasi_ml_dl_xai_GAFC.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
