{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674d68be-dee1-4910-a28e-f08a102316c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk pengolahan data dan visualisasi\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Library untuk evaluasi dan model machine learning\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import sklearn.ensemble as ek\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Library untuk Explainable AI (XAI)\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import shap\n",
    "\n",
    "# Library untuk Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103abc4c-1b2e-4ca0-82e5-0b66b34b6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dataset \n",
    "\n",
    "DM = pd.read_csv(\"C:\\\\Data Raihan\\\\Penelitian Threshold\\\\Dataset\\\\Obfuscated-MalMem2022\\\\Obfuscated-MalMem2022.csv\") #DM--> Dataset Malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b14026-c76d-4c99-8f2a-723225d2df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58596 entries, 0 to 58595\n",
      "Data columns (total 57 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Category                                58596 non-null  object \n",
      " 1   pslist.nproc                            58596 non-null  int64  \n",
      " 2   pslist.nppid                            58596 non-null  int64  \n",
      " 3   pslist.avg_threads                      58596 non-null  float64\n",
      " 4   pslist.nprocs64bit                      58596 non-null  int64  \n",
      " 5   pslist.avg_handlers                     58596 non-null  float64\n",
      " 6   dlllist.ndlls                           58596 non-null  int64  \n",
      " 7   dlllist.avg_dlls_per_proc               58596 non-null  float64\n",
      " 8   handles.nhandles                        58596 non-null  int64  \n",
      " 9   handles.avg_handles_per_proc            58596 non-null  float64\n",
      " 10  handles.nport                           58596 non-null  int64  \n",
      " 11  handles.nfile                           58596 non-null  int64  \n",
      " 12  handles.nevent                          58596 non-null  int64  \n",
      " 13  handles.ndesktop                        58596 non-null  int64  \n",
      " 14  handles.nkey                            58596 non-null  int64  \n",
      " 15  handles.nthread                         58596 non-null  int64  \n",
      " 16  handles.ndirectory                      58596 non-null  int64  \n",
      " 17  handles.nsemaphore                      58596 non-null  int64  \n",
      " 18  handles.ntimer                          58596 non-null  int64  \n",
      " 19  handles.nsection                        58596 non-null  int64  \n",
      " 20  handles.nmutant                         58596 non-null  int64  \n",
      " 21  ldrmodules.not_in_load                  58596 non-null  int64  \n",
      " 22  ldrmodules.not_in_init                  58596 non-null  int64  \n",
      " 23  ldrmodules.not_in_mem                   58596 non-null  int64  \n",
      " 24  ldrmodules.not_in_load_avg              58596 non-null  float64\n",
      " 25  ldrmodules.not_in_init_avg              58596 non-null  float64\n",
      " 26  ldrmodules.not_in_mem_avg               58596 non-null  float64\n",
      " 27  malfind.ninjections                     58596 non-null  int64  \n",
      " 28  malfind.commitCharge                    58596 non-null  int64  \n",
      " 29  malfind.protection                      58596 non-null  int64  \n",
      " 30  malfind.uniqueInjections                58596 non-null  float64\n",
      " 31  psxview.not_in_pslist                   58596 non-null  int64  \n",
      " 32  psxview.not_in_eprocess_pool            58596 non-null  int64  \n",
      " 33  psxview.not_in_ethread_pool             58596 non-null  int64  \n",
      " 34  psxview.not_in_pspcid_list              58596 non-null  int64  \n",
      " 35  psxview.not_in_csrss_handles            58596 non-null  int64  \n",
      " 36  psxview.not_in_session                  58596 non-null  int64  \n",
      " 37  psxview.not_in_deskthrd                 58596 non-null  int64  \n",
      " 38  psxview.not_in_pslist_false_avg         58596 non-null  float64\n",
      " 39  psxview.not_in_eprocess_pool_false_avg  58596 non-null  float64\n",
      " 40  psxview.not_in_ethread_pool_false_avg   58596 non-null  float64\n",
      " 41  psxview.not_in_pspcid_list_false_avg    58596 non-null  float64\n",
      " 42  psxview.not_in_csrss_handles_false_avg  58596 non-null  float64\n",
      " 43  psxview.not_in_session_false_avg        58596 non-null  float64\n",
      " 44  psxview.not_in_deskthrd_false_avg       58596 non-null  float64\n",
      " 45  modules.nmodules                        58596 non-null  int64  \n",
      " 46  svcscan.nservices                       58596 non-null  int64  \n",
      " 47  svcscan.kernel_drivers                  58596 non-null  int64  \n",
      " 48  svcscan.fs_drivers                      58596 non-null  int64  \n",
      " 49  svcscan.process_services                58596 non-null  int64  \n",
      " 50  svcscan.shared_process_services         58596 non-null  int64  \n",
      " 51  svcscan.interactive_process_services    58596 non-null  int64  \n",
      " 52  svcscan.nactive                         58596 non-null  int64  \n",
      " 53  callbacks.ncallbacks                    58596 non-null  int64  \n",
      " 54  callbacks.nanonymous                    58596 non-null  int64  \n",
      " 55  callbacks.ngeneric                      58596 non-null  int64  \n",
      " 56  Class                                   58596 non-null  object \n",
      "dtypes: float64(15), int64(40), object(2)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "DM.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dcbc54b-758f-4b1f-999c-71e61b807d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "features_to_drop = ['Category', 'Class']\n",
    "\n",
    "# Droping specified columns and target variable\n",
    "X = DM.drop(features_to_drop, axis=1).values    \n",
    "y = DM['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41bd6d6c-c0ef-470b-9c61-cf4044411438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Nan\n",
    "X = pd.DataFrame(X).dropna()\n",
    "y = y[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8f7589-ddf7-41a4-aaa7-436e367e5f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Min-Max scaling to make X non-negative\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c355a696-fe69-43fd-8957-c3fd27306a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable (if still contains string values)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba75d9b8-e9cf-428b-bee5-0f0eb118955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Feature Selector\n",
    "sfs_selector = SequentialFeatureSelector(estimator=SVR(kernel=\"linear\"), n_features_to_select=5)\n",
    "X_sfs = sfs_selector.fit_transform(X_scaled, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aa8ad04-c8ca-43d2-95fc-f272b05e0a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using Sequential Feature Selector:\n",
      "dlllist.avg_dlls_per_proc\n",
      "handles.nkey\n",
      "handles.nsection\n",
      "psxview.not_in_csrss_handles_false_avg\n",
      "modules.nmodules\n"
     ]
    }
   ],
   "source": [
    "# Get top features selected by SFS\n",
    "sfs_top_features = np.where(sfs_selector.get_support())[0]\n",
    "\n",
    "# Get names of selected features\n",
    "filtered_columns = DM.drop(features_to_drop, axis=1).columns\n",
    "features = filtered_columns[sfs_top_features]\n",
    "\n",
    "print(\"Selected features using Sequential Feature Selector:\")\n",
    "for feature in features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbdd0877-c2ba-4c27-a531-0e69ba6823e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Temp\\ipykernel_21252\\1069642451.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_data = DM.groupby('Class').apply(lambda x: x.sample(frac=1)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Memilih 100% data secara acak dari setiap fitur/column\n",
    "sampled_data = DM.groupby('Class').apply(lambda x: x.sample(frac=1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c19c643a-4213-435e-ab40-0d4f86031267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sfs, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f7e5e01-61e4-45c2-9159-460c11755fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels ke bentuk numerik jika diperlukan\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15ba3878-16bf-44e3-9c8a-9fdfe6d3078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20469, number of negative: 20548\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 41017, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499037 -> initscore=-0.003852\n",
      "[LightGBM] [Info] Start training from score -0.003852\n",
      "0:\tlearn: 0.6004829\ttotal: 197ms\tremaining: 19.5s\n",
      "1:\tlearn: 0.5242195\ttotal: 238ms\tremaining: 11.7s\n",
      "2:\tlearn: 0.4607783\ttotal: 300ms\tremaining: 9.69s\n",
      "3:\tlearn: 0.4071149\ttotal: 351ms\tremaining: 8.42s\n",
      "4:\tlearn: 0.3615188\ttotal: 390ms\tremaining: 7.42s\n",
      "5:\tlearn: 0.3218081\ttotal: 433ms\tremaining: 6.79s\n",
      "6:\tlearn: 0.2873742\ttotal: 502ms\tremaining: 6.67s\n",
      "7:\tlearn: 0.2571925\ttotal: 580ms\tremaining: 6.67s\n",
      "8:\tlearn: 0.2308176\ttotal: 611ms\tremaining: 6.17s\n",
      "9:\tlearn: 0.2078706\ttotal: 675ms\tremaining: 6.08s\n",
      "10:\tlearn: 0.1874760\ttotal: 720ms\tremaining: 5.83s\n",
      "11:\tlearn: 0.1692875\ttotal: 761ms\tremaining: 5.58s\n",
      "12:\tlearn: 0.1532321\ttotal: 800ms\tremaining: 5.35s\n",
      "13:\tlearn: 0.1389749\ttotal: 853ms\tremaining: 5.24s\n",
      "14:\tlearn: 0.1258843\ttotal: 905ms\tremaining: 5.13s\n",
      "15:\tlearn: 0.1144162\ttotal: 966ms\tremaining: 5.07s\n",
      "16:\tlearn: 0.1040321\ttotal: 1.01s\tremaining: 4.93s\n",
      "17:\tlearn: 0.0949652\ttotal: 1.06s\tremaining: 4.81s\n",
      "18:\tlearn: 0.0864393\ttotal: 1.1s\tremaining: 4.7s\n",
      "19:\tlearn: 0.0788545\ttotal: 1.15s\tremaining: 4.6s\n",
      "20:\tlearn: 0.0720226\ttotal: 1.19s\tremaining: 4.48s\n",
      "21:\tlearn: 0.0659930\ttotal: 1.25s\tremaining: 4.41s\n",
      "22:\tlearn: 0.0606072\ttotal: 1.27s\tremaining: 4.25s\n",
      "23:\tlearn: 0.0556292\ttotal: 1.32s\tremaining: 4.18s\n",
      "24:\tlearn: 0.0512564\ttotal: 1.39s\tremaining: 4.17s\n",
      "25:\tlearn: 0.0473098\ttotal: 1.46s\tremaining: 4.15s\n",
      "26:\tlearn: 0.0436240\ttotal: 1.54s\tremaining: 4.16s\n",
      "27:\tlearn: 0.0405222\ttotal: 1.59s\tremaining: 4.1s\n",
      "28:\tlearn: 0.0375907\ttotal: 1.63s\tremaining: 4s\n",
      "29:\tlearn: 0.0349997\ttotal: 1.67s\tremaining: 3.9s\n",
      "30:\tlearn: 0.0325449\ttotal: 1.72s\tremaining: 3.84s\n",
      "31:\tlearn: 0.0303687\ttotal: 1.77s\tremaining: 3.76s\n",
      "32:\tlearn: 0.0284215\ttotal: 1.81s\tremaining: 3.67s\n",
      "33:\tlearn: 0.0264279\ttotal: 1.84s\tremaining: 3.58s\n",
      "34:\tlearn: 0.0248356\ttotal: 1.89s\tremaining: 3.51s\n",
      "35:\tlearn: 0.0233835\ttotal: 1.95s\tremaining: 3.46s\n",
      "36:\tlearn: 0.0221457\ttotal: 1.98s\tremaining: 3.38s\n",
      "37:\tlearn: 0.0210333\ttotal: 2.01s\tremaining: 3.28s\n",
      "38:\tlearn: 0.0197525\ttotal: 2.08s\tremaining: 3.26s\n",
      "39:\tlearn: 0.0187235\ttotal: 2.13s\tremaining: 3.19s\n",
      "40:\tlearn: 0.0178210\ttotal: 2.17s\tremaining: 3.12s\n",
      "41:\tlearn: 0.0167603\ttotal: 2.22s\tremaining: 3.06s\n",
      "42:\tlearn: 0.0159769\ttotal: 2.26s\tremaining: 3s\n",
      "43:\tlearn: 0.0153203\ttotal: 2.31s\tremaining: 2.94s\n",
      "44:\tlearn: 0.0147488\ttotal: 2.35s\tremaining: 2.87s\n",
      "45:\tlearn: 0.0141754\ttotal: 2.39s\tremaining: 2.8s\n",
      "46:\tlearn: 0.0135262\ttotal: 2.46s\tremaining: 2.77s\n",
      "47:\tlearn: 0.0129995\ttotal: 2.48s\tremaining: 2.69s\n",
      "48:\tlearn: 0.0124953\ttotal: 2.55s\tremaining: 2.65s\n",
      "49:\tlearn: 0.0120635\ttotal: 2.6s\tremaining: 2.6s\n",
      "50:\tlearn: 0.0116171\ttotal: 2.65s\tremaining: 2.55s\n",
      "51:\tlearn: 0.0113026\ttotal: 2.71s\tremaining: 2.5s\n",
      "52:\tlearn: 0.0110337\ttotal: 2.76s\tremaining: 2.44s\n",
      "53:\tlearn: 0.0106803\ttotal: 2.81s\tremaining: 2.39s\n",
      "54:\tlearn: 0.0104201\ttotal: 2.86s\tremaining: 2.34s\n",
      "55:\tlearn: 0.0102165\ttotal: 2.91s\tremaining: 2.29s\n",
      "56:\tlearn: 0.0099950\ttotal: 2.98s\tremaining: 2.25s\n",
      "57:\tlearn: 0.0097587\ttotal: 3.04s\tremaining: 2.2s\n",
      "58:\tlearn: 0.0095661\ttotal: 3.09s\tremaining: 2.15s\n",
      "59:\tlearn: 0.0093895\ttotal: 3.13s\tremaining: 2.08s\n",
      "60:\tlearn: 0.0090869\ttotal: 3.17s\tremaining: 2.02s\n",
      "61:\tlearn: 0.0088871\ttotal: 3.23s\tremaining: 1.98s\n",
      "62:\tlearn: 0.0086721\ttotal: 3.25s\tremaining: 1.91s\n",
      "63:\tlearn: 0.0084459\ttotal: 3.31s\tremaining: 1.86s\n",
      "64:\tlearn: 0.0083188\ttotal: 3.36s\tremaining: 1.81s\n",
      "65:\tlearn: 0.0082351\ttotal: 3.4s\tremaining: 1.75s\n",
      "66:\tlearn: 0.0081321\ttotal: 3.44s\tremaining: 1.7s\n",
      "67:\tlearn: 0.0080423\ttotal: 3.5s\tremaining: 1.65s\n",
      "68:\tlearn: 0.0079198\ttotal: 3.57s\tremaining: 1.6s\n",
      "69:\tlearn: 0.0078167\ttotal: 3.63s\tremaining: 1.56s\n",
      "70:\tlearn: 0.0077376\ttotal: 3.69s\tremaining: 1.5s\n",
      "71:\tlearn: 0.0076130\ttotal: 3.73s\tremaining: 1.45s\n",
      "72:\tlearn: 0.0075371\ttotal: 3.78s\tremaining: 1.4s\n",
      "73:\tlearn: 0.0074469\ttotal: 3.83s\tremaining: 1.35s\n",
      "74:\tlearn: 0.0073516\ttotal: 3.91s\tremaining: 1.3s\n",
      "75:\tlearn: 0.0072596\ttotal: 3.96s\tremaining: 1.25s\n",
      "76:\tlearn: 0.0072411\ttotal: 4s\tremaining: 1.19s\n",
      "77:\tlearn: 0.0071282\ttotal: 4.05s\tremaining: 1.14s\n",
      "78:\tlearn: 0.0070897\ttotal: 4.12s\tremaining: 1.09s\n",
      "79:\tlearn: 0.0070005\ttotal: 4.15s\tremaining: 1.04s\n",
      "80:\tlearn: 0.0069531\ttotal: 4.19s\tremaining: 983ms\n",
      "81:\tlearn: 0.0068968\ttotal: 4.23s\tremaining: 928ms\n",
      "82:\tlearn: 0.0068758\ttotal: 4.27s\tremaining: 875ms\n",
      "83:\tlearn: 0.0068110\ttotal: 4.31s\tremaining: 821ms\n",
      "84:\tlearn: 0.0067645\ttotal: 4.34s\tremaining: 766ms\n",
      "85:\tlearn: 0.0067141\ttotal: 4.4s\tremaining: 716ms\n",
      "86:\tlearn: 0.0066743\ttotal: 4.44s\tremaining: 663ms\n",
      "87:\tlearn: 0.0066216\ttotal: 4.48s\tremaining: 611ms\n",
      "88:\tlearn: 0.0065220\ttotal: 4.56s\tremaining: 564ms\n",
      "89:\tlearn: 0.0064751\ttotal: 4.59s\tremaining: 510ms\n",
      "90:\tlearn: 0.0064156\ttotal: 4.64s\tremaining: 459ms\n",
      "91:\tlearn: 0.0063538\ttotal: 4.75s\tremaining: 413ms\n",
      "92:\tlearn: 0.0062735\ttotal: 4.8s\tremaining: 362ms\n",
      "93:\tlearn: 0.0062352\ttotal: 4.87s\tremaining: 311ms\n",
      "94:\tlearn: 0.0062123\ttotal: 4.93s\tremaining: 259ms\n",
      "95:\tlearn: 0.0061608\ttotal: 4.96s\tremaining: 207ms\n",
      "96:\tlearn: 0.0060777\ttotal: 5.01s\tremaining: 155ms\n",
      "97:\tlearn: 0.0060482\ttotal: 5.07s\tremaining: 103ms\n",
      "98:\tlearn: 0.0060365\ttotal: 5.11s\tremaining: 51.6ms\n",
      "99:\tlearn: 0.0060146\ttotal: 5.16s\tremaining: 0us\n",
      "550/550 [==============================] - 1s 849us/step\n",
      "550/550 [==============================] - 1s 896us/step\n",
      "550/550 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 17580it [01:12, 243.95it/s]                                                                  \n",
      "ExactExplainer explainer: 17580it [05:19, 53.31it/s]                                                                   \n",
      "ExactExplainer explainer: 17580it [00:25, 539.22it/s]                                                                  \n",
      "ExactExplainer explainer: 17580it [00:28, 396.44it/s]                                                                  \n",
      "ExactExplainer explainer: 17580it [00:22, 429.04it/s]                                                                  \n",
      "ExactExplainer explainer: 17580it [00:19, 437.71it/s]                                                                  \n",
      "ExactExplainer explainer: 17580it [20:53, 13.90it/s]                                                                   \n",
      "ExactExplainer explainer: 17580it [00:50, 276.24it/s]                                                                  \n",
      "ExactExplainer explainer: 17580it [01:05, 229.84it/s]                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20469, number of negative: 20548\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 41017, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499037 -> initscore=-0.003852\n",
      "[LightGBM] [Info] Start training from score -0.003852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 17580it [01:20, 183.12it/s]                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6004829\ttotal: 9.49ms\tremaining: 940ms\n",
      "1:\tlearn: 0.5242195\ttotal: 29.2ms\tremaining: 1.43s\n",
      "2:\tlearn: 0.4607783\ttotal: 53.3ms\tremaining: 1.72s\n",
      "3:\tlearn: 0.4071149\ttotal: 71.4ms\tremaining: 1.71s\n",
      "4:\tlearn: 0.3615188\ttotal: 82.6ms\tremaining: 1.57s\n",
      "5:\tlearn: 0.3218081\ttotal: 106ms\tremaining: 1.66s\n",
      "6:\tlearn: 0.2873742\ttotal: 126ms\tremaining: 1.67s\n",
      "7:\tlearn: 0.2571925\ttotal: 136ms\tremaining: 1.56s\n",
      "8:\tlearn: 0.2308176\ttotal: 153ms\tremaining: 1.55s\n",
      "9:\tlearn: 0.2078706\ttotal: 178ms\tremaining: 1.6s\n",
      "10:\tlearn: 0.1874760\ttotal: 201ms\tremaining: 1.63s\n",
      "11:\tlearn: 0.1692875\ttotal: 220ms\tremaining: 1.61s\n",
      "12:\tlearn: 0.1532321\ttotal: 230ms\tremaining: 1.54s\n",
      "13:\tlearn: 0.1389749\ttotal: 253ms\tremaining: 1.55s\n",
      "14:\tlearn: 0.1258843\ttotal: 272ms\tremaining: 1.54s\n",
      "15:\tlearn: 0.1144162\ttotal: 281ms\tremaining: 1.48s\n",
      "16:\tlearn: 0.1040321\ttotal: 306ms\tremaining: 1.5s\n",
      "17:\tlearn: 0.0949652\ttotal: 331ms\tremaining: 1.51s\n",
      "18:\tlearn: 0.0864393\ttotal: 357ms\tremaining: 1.52s\n",
      "19:\tlearn: 0.0788545\ttotal: 374ms\tremaining: 1.49s\n",
      "20:\tlearn: 0.0720226\ttotal: 385ms\tremaining: 1.45s\n",
      "21:\tlearn: 0.0659930\ttotal: 410ms\tremaining: 1.45s\n",
      "22:\tlearn: 0.0606072\ttotal: 430ms\tremaining: 1.44s\n",
      "23:\tlearn: 0.0556292\ttotal: 436ms\tremaining: 1.38s\n",
      "24:\tlearn: 0.0512564\ttotal: 459ms\tremaining: 1.38s\n",
      "25:\tlearn: 0.0473098\ttotal: 482ms\tremaining: 1.37s\n",
      "26:\tlearn: 0.0436240\ttotal: 499ms\tremaining: 1.35s\n",
      "27:\tlearn: 0.0405222\ttotal: 511ms\tremaining: 1.31s\n",
      "28:\tlearn: 0.0375907\ttotal: 536ms\tremaining: 1.31s\n",
      "29:\tlearn: 0.0349997\ttotal: 567ms\tremaining: 1.32s\n",
      "30:\tlearn: 0.0325449\ttotal: 592ms\tremaining: 1.32s\n",
      "31:\tlearn: 0.0303687\ttotal: 617ms\tremaining: 1.31s\n",
      "32:\tlearn: 0.0284215\ttotal: 634ms\tremaining: 1.29s\n",
      "33:\tlearn: 0.0264279\ttotal: 646ms\tremaining: 1.25s\n",
      "34:\tlearn: 0.0248356\ttotal: 669ms\tremaining: 1.24s\n",
      "35:\tlearn: 0.0233835\ttotal: 688ms\tremaining: 1.22s\n",
      "36:\tlearn: 0.0221457\ttotal: 697ms\tremaining: 1.19s\n",
      "37:\tlearn: 0.0210333\ttotal: 723ms\tremaining: 1.18s\n",
      "38:\tlearn: 0.0197525\ttotal: 749ms\tremaining: 1.17s\n",
      "39:\tlearn: 0.0187235\ttotal: 772ms\tremaining: 1.16s\n",
      "40:\tlearn: 0.0178210\ttotal: 782ms\tremaining: 1.13s\n",
      "41:\tlearn: 0.0167603\ttotal: 812ms\tremaining: 1.12s\n",
      "42:\tlearn: 0.0159769\ttotal: 825ms\tremaining: 1.09s\n",
      "43:\tlearn: 0.0153203\ttotal: 852ms\tremaining: 1.08s\n",
      "44:\tlearn: 0.0147488\ttotal: 877ms\tremaining: 1.07s\n",
      "45:\tlearn: 0.0141754\ttotal: 894ms\tremaining: 1.05s\n",
      "46:\tlearn: 0.0135262\ttotal: 906ms\tremaining: 1.02s\n",
      "47:\tlearn: 0.0129995\ttotal: 929ms\tremaining: 1.01s\n",
      "48:\tlearn: 0.0124953\ttotal: 950ms\tremaining: 989ms\n",
      "49:\tlearn: 0.0120635\ttotal: 967ms\tremaining: 967ms\n",
      "50:\tlearn: 0.0116171\ttotal: 979ms\tremaining: 940ms\n",
      "51:\tlearn: 0.0113026\ttotal: 1s\tremaining: 924ms\n",
      "52:\tlearn: 0.0110337\ttotal: 1.02s\tremaining: 906ms\n",
      "53:\tlearn: 0.0106803\ttotal: 1.04s\tremaining: 883ms\n",
      "54:\tlearn: 0.0104201\ttotal: 1.05s\tremaining: 858ms\n",
      "55:\tlearn: 0.0102165\ttotal: 1.07s\tremaining: 843ms\n",
      "56:\tlearn: 0.0099950\ttotal: 1.09s\tremaining: 827ms\n",
      "57:\tlearn: 0.0097587\ttotal: 1.11s\tremaining: 808ms\n",
      "58:\tlearn: 0.0095661\ttotal: 1.13s\tremaining: 786ms\n",
      "59:\tlearn: 0.0093895\ttotal: 1.15s\tremaining: 767ms\n",
      "60:\tlearn: 0.0090869\ttotal: 1.18s\tremaining: 752ms\n",
      "61:\tlearn: 0.0088871\ttotal: 1.2s\tremaining: 734ms\n",
      "62:\tlearn: 0.0086721\ttotal: 1.21s\tremaining: 708ms\n",
      "63:\tlearn: 0.0084459\ttotal: 1.22s\tremaining: 689ms\n",
      "64:\tlearn: 0.0083188\ttotal: 1.24s\tremaining: 668ms\n",
      "65:\tlearn: 0.0082351\ttotal: 1.25s\tremaining: 645ms\n",
      "66:\tlearn: 0.0081321\ttotal: 1.27s\tremaining: 628ms\n",
      "67:\tlearn: 0.0080423\ttotal: 1.3s\tremaining: 611ms\n",
      "68:\tlearn: 0.0079198\ttotal: 1.32s\tremaining: 592ms\n",
      "69:\tlearn: 0.0078167\ttotal: 1.33s\tremaining: 569ms\n",
      "70:\tlearn: 0.0077376\ttotal: 1.35s\tremaining: 553ms\n",
      "71:\tlearn: 0.0076130\ttotal: 1.37s\tremaining: 534ms\n",
      "72:\tlearn: 0.0075371\ttotal: 1.38s\tremaining: 510ms\n",
      "73:\tlearn: 0.0074469\ttotal: 1.4s\tremaining: 493ms\n",
      "74:\tlearn: 0.0073516\ttotal: 1.43s\tremaining: 476ms\n",
      "75:\tlearn: 0.0072596\ttotal: 1.45s\tremaining: 457ms\n",
      "76:\tlearn: 0.0072411\ttotal: 1.46s\tremaining: 435ms\n",
      "77:\tlearn: 0.0071282\ttotal: 1.48s\tremaining: 417ms\n",
      "78:\tlearn: 0.0070897\ttotal: 1.5s\tremaining: 400ms\n",
      "79:\tlearn: 0.0070005\ttotal: 1.52s\tremaining: 381ms\n",
      "80:\tlearn: 0.0069531\ttotal: 1.53s\tremaining: 359ms\n",
      "81:\tlearn: 0.0068968\ttotal: 1.55s\tremaining: 341ms\n",
      "82:\tlearn: 0.0068758\ttotal: 1.58s\tremaining: 324ms\n",
      "83:\tlearn: 0.0068110\ttotal: 1.6s\tremaining: 306ms\n",
      "84:\tlearn: 0.0067645\ttotal: 1.62s\tremaining: 287ms\n",
      "85:\tlearn: 0.0067141\ttotal: 1.63s\tremaining: 266ms\n",
      "86:\tlearn: 0.0066743\ttotal: 1.66s\tremaining: 248ms\n",
      "87:\tlearn: 0.0066216\ttotal: 1.68s\tremaining: 229ms\n",
      "88:\tlearn: 0.0065220\ttotal: 1.7s\tremaining: 210ms\n",
      "89:\tlearn: 0.0064751\ttotal: 1.71s\tremaining: 190ms\n",
      "90:\tlearn: 0.0064156\ttotal: 1.74s\tremaining: 172ms\n",
      "91:\tlearn: 0.0063538\ttotal: 1.75s\tremaining: 152ms\n",
      "92:\tlearn: 0.0062735\ttotal: 1.77s\tremaining: 134ms\n",
      "93:\tlearn: 0.0062352\ttotal: 1.8s\tremaining: 115ms\n",
      "94:\tlearn: 0.0062123\ttotal: 1.82s\tremaining: 95.8ms\n",
      "95:\tlearn: 0.0061608\ttotal: 1.83s\tremaining: 76.2ms\n",
      "96:\tlearn: 0.0060777\ttotal: 1.85s\tremaining: 57.2ms\n",
      "97:\tlearn: 0.0060482\ttotal: 1.87s\tremaining: 38.2ms\n",
      "98:\tlearn: 0.0060365\ttotal: 1.89s\tremaining: 19.1ms\n",
      "99:\tlearn: 0.0060146\ttotal: 1.9s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 17580it [03:06, 91.18it/s]                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550/550 [==============================] - 0s 660us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550/550 [==============================] - 1s 792us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using SHAP with CNN: operands could not be broadcast together with shapes (41017,5,1) (41017,5) \n",
      "550/550 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using SHAP with RNN: in user code:\n",
      "\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 244, in grad_graph  *\n",
      "        out = self.model(shap_rAnD)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 371, in custom_grad\n",
      "        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefix before the lookup\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 663, in handler\n",
      "        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 670, in linearity_with_excluded_handler\n",
      "        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 222, in _variable_inputs\n",
      "        out[i] = t.name in self.between_tensors\n",
      "\n",
      "    AttributeError: Exception encountered when calling layer 'lstm' (type LSTM).\n",
      "    \n",
      "    'TFDeep' object has no attribute 'between_tensors'\n",
      "    \n",
      "    Call arguments received by layer 'lstm' (type LSTM):\n",
      "      • inputs=tf.Tensor(shape=(82034, 5, 1), dtype=float32)\n",
      "      • mask=None\n",
      "      • training=False\n",
      "      • initial_state=None\n",
      "\n",
      "\n",
      "Hasil Evaluasi ML/DL tanpa XAI:\n",
      "[['DecisionTree', 0.9993197278911564, 0.9983010533469249, 0.9988101308856026, 0.9988053927982251, 0.1420438289642334], ['RandomForest', 0.9989801699716714, 0.998527579567335, 0.9987538234960915, 0.9987485067409978, 2.116088628768921], ['Logistic Regression', 0.9925782142041562, 0.9845962170121192, 0.9885711036561097, 0.9885659024972979, 0.10052943229675293], ['Naive Bayes', 0.9824876515491693, 0.9912787405142145, 0.9868636184247618, 0.9867455486660219, 0.02300572395324707], ['MLP', 0.9951064071924434, 0.9903726356325745, 0.9927338782924614, 0.9927185846748962, 9.7477285861969], ['Stochastic Gradient Descent', 0.9903507776138041, 0.9881073734284743, 0.9892278036058509, 0.989191649126799, 0.04951643943786621], ['ADA Boost', 0.9986386840612592, 0.9970551591346698, 0.9978462933575153, 0.9978383298253598, 3.4389302730560303], ['Gradient Boosting', 0.9984130582634323, 0.9976214746856948, 0.9980171095122089, 0.998008987997042, 9.801441669464111], ['XGBoost', 0.9992066190638105, 0.998527579567335, 0.9988669839111716, 0.9988622788554525, 11.466551780700684], ['LightGBM', 0.9995465366738465, 0.9986408426775399, 0.9990934844192635, 0.999089823084362, 46.72764325141907], ['CatBoost', 0.9972823009851659, 0.9975082115754899, 0.9973952434881087, 0.9973832413675409, 5.43679666519165], ['DNN', 0.9956690221107819, 0.9894665307509344, 0.9925580866897689, 0.9925479265032141, 8.6316659450531], ['CNN', 0.9905234657039711, 0.9944501075999547, 0.9924829028429323, 0.9924341543887593, 9.580212116241455], ['RNN', 0.9920018281535649, 0.9833503227998641, 0.9876571298560947, 0.9876557255816599, 24.90317964553833]]\n",
      "\n",
      "Hasil Evaluasi ML/DL dengan XAI:\n",
      "[['DecisionTree', 0.9994330422950448, 0.9983010533469249, 0.9988667271078875, 0.9988622788554525, 0.15854144096374512, {'SHAP': array([[-0.00504912,  0.00504912],\n",
      "       [-0.00118334,  0.00118334],\n",
      "       [-0.00535984,  0.00535984],\n",
      "       [ 0.00378532, -0.00378532],\n",
      "       [-0.00377676,  0.00377676]])}], ['RandomForest', 0.9989801699716714, 0.998527579567335, 0.9987538234960915, 0.9987485067409978, 2.450727701187134, {'SHAP': array([[-0.0100656 ,  0.0100656 ],\n",
      "       [-0.00103187,  0.00103187],\n",
      "       [-0.00099701,  0.00099701],\n",
      "       [ 0.0016104 , -0.0016104 ],\n",
      "       [-0.00130795,  0.00130795]])}], ['Logistic Regression', 0.9925782142041562, 0.9845962170121192, 0.9885711036561097, 0.9885659024972979, 0.07352352142333984, {'SHAP': array([[-1.34740249e-02,  1.34740249e-02],\n",
      "       [ 4.05866348e-03, -4.05866348e-03],\n",
      "       [ 3.38715338e-05, -3.38715338e-05],\n",
      "       [ 9.50469312e-05, -9.50469312e-05],\n",
      "       [-4.46988579e-04,  4.46988579e-04]])}], ['Naive Bayes', 0.9824876515491693, 0.9912787405142145, 0.9868636184247618, 0.9867455486660219, 0.018004179000854492, {'SHAP': array([[-3.23288192e-03,  3.23288192e-03],\n",
      "       [ 1.83449350e-03, -1.83449350e-03],\n",
      "       [-9.60268741e-04,  9.60268741e-04],\n",
      "       [-4.66843232e-05,  4.66843232e-05],\n",
      "       [ 5.12041719e-03, -5.12041719e-03]])}], ['MLP', 0.9951064071924434, 0.9903726356325745, 0.9927338782924614, 0.9927185846748962, 9.84696888923645, {'SHAP': array([[-0.01114586,  0.01114586],\n",
      "       [ 0.00377983, -0.00377983],\n",
      "       [ 0.00029841, -0.00029841],\n",
      "       [ 0.00015098, -0.00015098],\n",
      "       [-0.00044179,  0.00044179]])}], ['Stochastic Gradient Descent', 0.9903507776138041, 0.9881073734284743, 0.9892278036058509, 0.989191649126799, 0.055013418197631836, {'SHAP': array([[-1.24395929e-02,  1.24395929e-02],\n",
      "       [ 4.10684711e-03, -4.10684711e-03],\n",
      "       [ 9.97054205e-06, -9.97054205e-06],\n",
      "       [ 7.73021293e-05, -7.73021293e-05],\n",
      "       [-2.06103703e-04,  2.06103703e-04]])}], ['ADA Boost', 0.9986386840612592, 0.9970551591346698, 0.9978462933575153, 0.9978383298253598, 3.4750499725341797, {'SHAP': array([[-0.00100657,  0.00100657],\n",
      "       [-0.00058898,  0.00058898],\n",
      "       [ 0.00017413, -0.00017413],\n",
      "       [ 0.00031751, -0.00031751],\n",
      "       [-0.00042756,  0.00042756]])}], ['Gradient Boosting', 0.9984130582634323, 0.9976214746856948, 0.9980171095122089, 0.998008987997042, 4.505514621734619, {'SHAP': array([[-0.01230715,  0.01230715],\n",
      "       [-0.00137914,  0.00137914],\n",
      "       [ 0.00230431, -0.00230431],\n",
      "       [ 0.00102549, -0.00102549],\n",
      "       [-0.00152681,  0.00152681]])}], ['XGBoost', 0.9992066190638105, 0.998527579567335, 0.9988669839111716, 0.9988622788554525, 0.1515519618988037, {'SHAP': array([[-0.00539686,  0.00539686],\n",
      "       [-0.00403922,  0.00403922],\n",
      "       [ 0.00161602, -0.00161602],\n",
      "       [-0.00099641,  0.00099641],\n",
      "       [-0.00260523,  0.00260523]])}], ['LightGBM', 0.9995465366738465, 0.9986408426775399, 0.9990934844192635, 0.999089823084362, 0.13634109497070312, {'SHAP': array([[-0.01774093,  0.01774093],\n",
      "       [-0.00188234,  0.00188234],\n",
      "       [ 0.00890631, -0.00890631],\n",
      "       [ 0.00022771, -0.00022771],\n",
      "       [-0.001237  ,  0.001237  ]])}], ['CatBoost', 0.9972823009851659, 0.9975082115754899, 0.9973952434881087, 0.9973832413675409, 2.374157667160034, {'SHAP': array([[-0.00863392,  0.00863392],\n",
      "       [-0.00205896,  0.00205896],\n",
      "       [ 0.00288742, -0.00288742],\n",
      "       [ 0.00046674, -0.00046674],\n",
      "       [-0.0019177 ,  0.0019177 ]])}], ['DNN', 0.9959049027414401, 0.9916185298448296, 0.9937570942111237, 0.9937425337049889, 7.148904800415039, {'SHAP': array([0.10114204])}], ['CNN', 0.9949988633780404, 0.9915052667346246, 0.9932489930220684, 0.9932305591899425, 26.676481008529663, {'SHAP': None}], ['RNN', 0.988527724665392, 0.9954694755917998, 0.9919864559819414, 0.991922179873713, 24.501221895217896, {'SHAP': None}]]\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi variabel untuk menyimpan hasil evaluasi\n",
    "hasil_ml_dl = []\n",
    "hasil_ml_dl_xai = []\n",
    "\n",
    "# Encode labels ke bentuk numerik jika diperlukan\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Fungsi untuk mengevaluasi model ML/DL\n",
    "def EvaluateModel(model_name, model, X_train, y_train, X_test, y_test, use_xai=False, is_dl_model=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Melatih model\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0) if is_dl_model else model.fit(X_train, y_train)\n",
    "    \n",
    "    if is_dl_model:\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    elif hasattr(model, 'predict_proba'):\n",
    "        # Model dengan metode predict_proba\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        if y_pred_proba.shape[1] > 1:  # Model klasifikasi multi-kelas\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        else:  # Model klasifikasi biner\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    else:\n",
    "        # Model tanpa metode predict_proba\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "\n",
    "    # Menghitung confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Menghitung metrik\n",
    "    Precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    Recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    F1Score = 2 * ((Precision * Recall) / (Precision + Recall)) if (Precision + Recall) != 0 else 0\n",
    "    Accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) != 0 else 0\n",
    "\n",
    "    # Menghitung waktu running\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "    # Jika XAI diperlukan, tambahkan analisis dengan SHAP\n",
    "    if use_xai:\n",
    "        # Periksa apakah X_train adalah DataFrame\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            feature_names = X_train.columns\n",
    "        else:\n",
    "            feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "        \n",
    "        # Perbaiki format X_train untuk SHAP\n",
    "        if is_dl_model:\n",
    "            X_train_for_xai = X_train.reshape((X_train.shape[0], X_train.shape[1]))\n",
    "            X_test_for_xai = X_test.reshape((X_test.shape[0], X_test.shape[1]))\n",
    "        else:\n",
    "            X_train_for_xai = X_train\n",
    "            X_test_for_xai = X_test\n",
    "\n",
    "        # Gunakan SHAP\n",
    "        try:\n",
    "            if is_dl_model:\n",
    "                explainer = shap.DeepExplainer(model, X_train_for_xai)\n",
    "                shap_values = explainer.shap_values(X_test_for_xai)\n",
    "                shap_summary = np.mean(shap_values[0], axis=0)\n",
    "            else:\n",
    "                explainer = shap.Explainer(model.predict_proba, X_train_for_xai)\n",
    "                shap_values = explainer(X_test_for_xai)\n",
    "                shap_summary = shap_values.values.mean(axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error using SHAP with {model_name}: {e}\")\n",
    "            shap_summary = None\n",
    "\n",
    "        # Simpan hasil evaluasi dengan XAI\n",
    "        hasil_ml_dl_xai.append([model_name, Precision, Recall, F1Score, Accuracy, run_time, {'SHAP': shap_summary}])\n",
    "    else:\n",
    "        # Simpan hasil evaluasi tanpa XAI\n",
    "        hasil_ml_dl.append([model_name, Precision, Recall, F1Score, Accuracy, run_time])\n",
    "\n",
    "# Model ML dan DL yang akan dievaluasi\n",
    "model_ml_dl = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=10),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=50),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0, max_iter=10000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000),\n",
    "    \"Stochastic Gradient Descent\": SGDClassifier(loss='log_loss', random_state=42),\n",
    "    \"ADA Boost\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='Logloss')\n",
    "}\n",
    "\n",
    "model_dl = {\n",
    "    \"DNN\": Sequential([\n",
    "        Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"CNN\": Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"RNN\": Sequential([\n",
    "        LSTM(100, input_shape=(X_train.shape[1], 1)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Pastikan X_train dan X_test memiliki bentuk yang sesuai untuk DL\n",
    "X_train_dl = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_dl = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Mengevaluasi model ML tanpa XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=False)\n",
    "\n",
    "# Mengevaluasi model DL tanpa XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=False, is_dl_model=True)\n",
    "\n",
    "# Mengevaluasi model ML dengan XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=True)\n",
    "\n",
    "# Mengevaluasi model DL dengan XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=True, is_dl_model=True)\n",
    "\n",
    "# Print hasil evaluasi tanpa XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL tanpa XAI:\")\n",
    "print(hasil_ml_dl)\n",
    "\n",
    "# Print hasil evaluasi dengan XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL dengan XAI:\")\n",
    "print(hasil_ml_dl_xai)\n",
    "\n",
    "# Convert results to DataFrame and save to CSV\n",
    "df_ml_dl = pd.DataFrame(hasil_ml_dl, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\"])\n",
    "df_ml_dl_xai = pd.DataFrame(hasil_ml_dl_xai, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\", \"XAI\"])\n",
    "\n",
    "df_ml_dl.to_csv(\"hasil_evaluasi_ml_dl_SFSFC.csv\", index=False)\n",
    "df_ml_dl_xai.to_csv(\"hasil_evaluasi_ml_dl_xai_SFSFC.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
