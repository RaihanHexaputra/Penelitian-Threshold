{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ed2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk pengolahan data dan visualisasi\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Library untuk evaluasi dan model machine learning\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import sklearn.ensemble as ek\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Library untuk Explainable AI (XAI)\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import shap\n",
    "\n",
    "# Library untuk Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58528644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dataset \n",
    "\n",
    "# Define the directory where the parquet files are stored\n",
    "parquet_directory = \"C:\\Data Raihan\\Penelitian Threshold\\Dataset\\CTU-13\"\n",
    "\n",
    "# List all parquet files in the directory\n",
    "parquet_files = [f for f in os.listdir(parquet_directory) if f.endswith('.parquet')]\n",
    "\n",
    "# Read each parquet file and append it to a list of DataFrames\n",
    "dataframes = [pd.read_parquet(os.path.join(parquet_directory, file)) for file in parquet_files]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "DM = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637e2bbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10598771 entries, 0 to 10598770\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   dur        float32\n",
      " 1   proto      object \n",
      " 2   dir        object \n",
      " 3   state      object \n",
      " 4   stos       float32\n",
      " 5   dtos       float32\n",
      " 6   tot_pkts   int32  \n",
      " 7   tot_bytes  int64  \n",
      " 8   src_bytes  int64  \n",
      " 9   label      object \n",
      " 10  Family     object \n",
      "dtypes: float32(3), int32(1), int64(2), object(5)\n",
      "memory usage: 727.8+ MB\n"
     ]
    }
   ],
   "source": [
    "DM.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f75c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "features_to_drop = ['proto', 'dir', 'state', 'dtos', 'stos', 'tot_pkts', 'tot_bytes', 'src_bytes', 'label','Family']\n",
    "\n",
    "# Droping specified columns and target variable\n",
    "X = DM.drop(features_to_drop, axis=1).values    \n",
    "y = DM['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12df0cd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    label  binary_label\n",
      "0  flow=Background-Established-cmpgw-CVUT             0\n",
      "1  flow=Background-Established-cmpgw-CVUT             0\n",
      "2             flow=Background-TCP-Attempt             0\n",
      "3             flow=Background-TCP-Attempt             0\n",
      "4             flow=Background-TCP-Attempt             0\n",
      "Counts of binary labels:\n",
      "binary_label\n",
      "0    10573337\n",
      "1       25434\n",
      "Name: count, dtype: int64\n",
      "Sample attack labels:\n",
      "                dur proto    dir     state  stos  dtos  tot_pkts  tot_bytes  \\\n",
      "418186     0.000278   udp    <->       CON   0.0   0.0         2        203   \n",
      "418403     0.020525   udp    <->       CON   0.0   0.0         2        590   \n",
      "418408     0.045125   tcp     ->  SRPA_SPA   0.0   0.0         7        882   \n",
      "426914     0.336250   udp    <->       CON   0.0   0.0         2        215   \n",
      "426933  3514.083496   tcp     ->   SPA_SPA   0.0   0.0       120       7767   \n",
      "428002     0.459301   udp    <->       CON   0.0   0.0         2        212   \n",
      "428142     1.371909   udp    <->       CON   0.0   0.0         3        295   \n",
      "428340     0.313117   udp    <->       CON   0.0   0.0         2        202   \n",
      "428526     0.547071   udp    <->       CON   0.0   0.0         2        223   \n",
      "428659     0.559377   udp    <->       CON   0.0   0.0         2        218   \n",
      "\n",
      "        src_bytes                                              label  \\\n",
      "418186         64                       flow=From-Botnet-V42-UDP-DNS   \n",
      "418403         87                       flow=From-Botnet-V42-UDP-DNS   \n",
      "418408        629  flow=From-Botnet-V42-TCP-HTTP-Google-Net-Estab...   \n",
      "426914         71                       flow=From-Botnet-V42-UDP-DNS   \n",
      "426933       2690               flow=From-Botnet-V42-TCP-Established   \n",
      "428002         77                       flow=From-Botnet-V42-UDP-DNS   \n",
      "428142        156                       flow=From-Botnet-V42-UDP-DNS   \n",
      "428340         72                       flow=From-Botnet-V42-UDP-DNS   \n",
      "428526         81                       flow=From-Botnet-V42-UDP-DNS   \n",
      "428659         77                       flow=From-Botnet-V42-UDP-DNS   \n",
      "\n",
      "                        Family  binary_label  \n",
      "418186  20110810.binetflow.csv             1  \n",
      "418403  20110810.binetflow.csv             1  \n",
      "418408  20110810.binetflow.csv             1  \n",
      "426914  20110810.binetflow.csv             1  \n",
      "426933  20110810.binetflow.csv             1  \n",
      "428002  20110810.binetflow.csv             1  \n",
      "428142  20110810.binetflow.csv             1  \n",
      "428340  20110810.binetflow.csv             1  \n",
      "428526  20110810.binetflow.csv             1  \n",
      "428659  20110810.binetflow.csv             1  \n",
      "Sample benign labels:\n",
      "        dur proto    dir  state  stos  dtos  tot_pkts  tot_bytes  src_bytes  \\\n",
      "0  1.026539   tcp     ->   S_RA   0.0   0.0         4        276        156   \n",
      "1  1.009595   tcp     ->   S_RA   0.0   0.0         4        276        156   \n",
      "2  3.056586   tcp     ->   SR_A   0.0   0.0         3        182        122   \n",
      "3  3.111769   tcp     ->   SR_A   0.0   0.0         3        182        122   \n",
      "4  3.083411   tcp     ->   SR_A   0.0   0.0         3        182        122   \n",
      "5  3.097288   tcp     ->   SR_A   0.0   0.0         3        182        122   \n",
      "6  1.048908   tcp     ->   S_RA   0.0   0.0         4        244        124   \n",
      "7  4.373526   tcp     ->   S_RA   0.0   0.0         4        252        132   \n",
      "8  4.827912   tcp     ->   S_RA   0.0   0.0         4        252        132   \n",
      "9  0.049697   tcp     ->  SR_SA   0.0   0.0         5        352        208   \n",
      "\n",
      "                                    label                  Family  \\\n",
      "0  flow=Background-Established-cmpgw-CVUT  20110810.binetflow.csv   \n",
      "1  flow=Background-Established-cmpgw-CVUT  20110810.binetflow.csv   \n",
      "2             flow=Background-TCP-Attempt  20110810.binetflow.csv   \n",
      "3             flow=Background-TCP-Attempt  20110810.binetflow.csv   \n",
      "4             flow=Background-TCP-Attempt  20110810.binetflow.csv   \n",
      "5             flow=Background-TCP-Attempt  20110810.binetflow.csv   \n",
      "6  flow=Background-Established-cmpgw-CVUT  20110810.binetflow.csv   \n",
      "7  flow=Background-Established-cmpgw-CVUT  20110810.binetflow.csv   \n",
      "8  flow=Background-Established-cmpgw-CVUT  20110810.binetflow.csv   \n",
      "9         flow=Background-TCP-Established  20110810.binetflow.csv   \n",
      "\n",
      "   binary_label  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "5             0  \n",
      "6             0  \n",
      "7             0  \n",
      "8             0  \n",
      "9             0  \n"
     ]
    }
   ],
   "source": [
    "# Membuat data yang multiclass menjadi binary class\n",
    "attack_classes = [\n",
    "    'flow=From-Botnet-V50-1-TCP-Established-SSL-To-Microsoft-1', \n",
    "    'flow=From-Botnet-V50-4-TCP-HTTP-Not-Encrypted-Down-2',\n",
    "    'flow=From-Botnet-V42-UDP-DNS',\n",
    "    'flow=From-Botnet-V42-TCP-HTTP-Google-Net-Established-6',\n",
    "    'flow=From-Botnet-V42-TCP-Established',\n",
    "    'flow=From-Botnet-V50-6-TCP-HTTP-Google-Net-Established-2'\n",
    "]\n",
    "\n",
    "# Mmebuat Label Binary\n",
    "DM['binary_label'] = DM['label'].apply(lambda x: 1 if x in attack_classes else 0)\n",
    "\n",
    "# Menampilkan rows 1 untuk mengkonformasi label baru\n",
    "print(DM[['label', 'binary_label']].head())\n",
    "\n",
    "# Menghitung label Binary\n",
    "binary_counts = DM['binary_label'].value_counts()\n",
    "print(\"Counts of binary labels:\")\n",
    "print(binary_counts)\n",
    "\n",
    "# Menampilkan sample\n",
    "print(\"Sample attack labels:\")\n",
    "print(DM[DM['binary_label'] == 1].head(10))  # Print 10 samples of attack labels\n",
    "print(\"Sample benign labels:\")\n",
    "print(DM[DM['binary_label'] == 0].head(10))  # Print 10 samples of benign labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aaa24f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Nan\n",
    "X = pd.DataFrame(X).dropna()\n",
    "y = y[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d332649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menerapkan Min-Max scaling untuk membuat X tidak negatif\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb8a5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Threshold (Filter)\n",
    "vt_selector = VarianceThreshold(threshold=0.00000001)  # Anda bisa menyesuaikan ambang batas\n",
    "X_vt = vt_selector.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32e8519d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dur terpilih dengan varians di atas threshold\n"
     ]
    }
   ],
   "source": [
    "# Mendapatkan indeks fitur yang terpilih\n",
    "vt_top_features = np.where(vt_selector.get_support())[0]\n",
    "\n",
    "# Mengambil nama kolom dari X yang sudah difilter\n",
    "filtered_columns = DM.drop(features_to_drop, axis=1).columns\n",
    "\n",
    "# Mengambil nama fitur terpilih\n",
    "features = []\n",
    "for idx in vt_top_features:\n",
    "    print(f\"Feature {filtered_columns[idx]} terpilih dengan varians di atas threshold\")\n",
    "    features.append(filtered_columns[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f54cba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_label\n",
      "0    5299\n",
      "1    5299\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Temp\\ipykernel_19368\\2278220086.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_data = DM.groupby('binary_label').apply(lambda x: x.sample(n=int(total_samples / 2), random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Tentukan 0.1% dari total dataset\n",
    "total_samples = int(len(DM) * 0.001)\n",
    "\n",
    "# Ambil jumlah minimal sampel dari kelas yang lebih sedikit\n",
    "min_class_samples = DM['binary_label'].value_counts().min()\n",
    "\n",
    "# Pastikan tidak mengambil lebih dari jumlah minimum kelas yang ada\n",
    "if total_samples / 2 > min_class_samples:\n",
    "    total_samples = min_class_samples * 2  # Sesuaikan total sampel agar tidak lebih dari yang tersedia\n",
    "\n",
    "# Ambil sampel secara acak dari kedua kelas dengan jumlah yang seimbang\n",
    "sampled_data = DM.groupby('binary_label').apply(lambda x: x.sample(n=int(total_samples / 2), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# Cek distribusi kelas setelah sampling\n",
    "print(sampled_data['binary_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e971c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan data menjadi fitur (X) dan target (y)\n",
    "X = sampled_data[features]\n",
    "y = sampled_data['binary_label']\n",
    "\n",
    "# Pisahkan data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9b293cf-5db8-4e67-953b-7392dc634109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels ke bentuk numerik jika diperlukan\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c779a7f-9a9e-4537-ab36-9480aec19f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3733, number of negative: 3685\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 7418, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503235 -> initscore=0.012942\n",
      "[LightGBM] [Info] Start training from score 0.012942\n",
      "0:\tlearn: 0.6562775\ttotal: 133ms\tremaining: 13.2s\n",
      "1:\tlearn: 0.6254255\ttotal: 135ms\tremaining: 6.6s\n",
      "2:\tlearn: 0.5998611\ttotal: 136ms\tremaining: 4.41s\n",
      "3:\tlearn: 0.5790303\ttotal: 138ms\tremaining: 3.31s\n",
      "4:\tlearn: 0.5621130\ttotal: 140ms\tremaining: 2.66s\n",
      "5:\tlearn: 0.5451802\ttotal: 142ms\tremaining: 2.22s\n",
      "6:\tlearn: 0.5320178\ttotal: 143ms\tremaining: 1.91s\n",
      "7:\tlearn: 0.5202495\ttotal: 145ms\tremaining: 1.67s\n",
      "8:\tlearn: 0.5109044\ttotal: 147ms\tremaining: 1.49s\n",
      "9:\tlearn: 0.5007965\ttotal: 149ms\tremaining: 1.34s\n",
      "10:\tlearn: 0.4940030\ttotal: 151ms\tremaining: 1.22s\n",
      "11:\tlearn: 0.4868630\ttotal: 153ms\tremaining: 1.12s\n",
      "12:\tlearn: 0.4820939\ttotal: 154ms\tremaining: 1.03s\n",
      "13:\tlearn: 0.4761226\ttotal: 156ms\tremaining: 956ms\n",
      "14:\tlearn: 0.4708079\ttotal: 157ms\tremaining: 891ms\n",
      "15:\tlearn: 0.4663055\ttotal: 159ms\tremaining: 834ms\n",
      "16:\tlearn: 0.4631563\ttotal: 161ms\tremaining: 784ms\n",
      "17:\tlearn: 0.4597340\ttotal: 162ms\tremaining: 739ms\n",
      "18:\tlearn: 0.4551618\ttotal: 164ms\tremaining: 700ms\n",
      "19:\tlearn: 0.4526475\ttotal: 166ms\tremaining: 664ms\n",
      "20:\tlearn: 0.4497229\ttotal: 168ms\tremaining: 630ms\n",
      "21:\tlearn: 0.4470095\ttotal: 169ms\tremaining: 600ms\n",
      "22:\tlearn: 0.4447476\ttotal: 171ms\tremaining: 573ms\n",
      "23:\tlearn: 0.4427049\ttotal: 173ms\tremaining: 548ms\n",
      "24:\tlearn: 0.4409008\ttotal: 175ms\tremaining: 524ms\n",
      "25:\tlearn: 0.4388414\ttotal: 176ms\tremaining: 502ms\n",
      "26:\tlearn: 0.4373755\ttotal: 178ms\tremaining: 482ms\n",
      "27:\tlearn: 0.4358445\ttotal: 180ms\tremaining: 463ms\n",
      "28:\tlearn: 0.4344214\ttotal: 182ms\tremaining: 445ms\n",
      "29:\tlearn: 0.4326746\ttotal: 183ms\tremaining: 428ms\n",
      "30:\tlearn: 0.4311640\ttotal: 185ms\tremaining: 412ms\n",
      "31:\tlearn: 0.4300062\ttotal: 187ms\tremaining: 397ms\n",
      "32:\tlearn: 0.4289891\ttotal: 189ms\tremaining: 383ms\n",
      "33:\tlearn: 0.4278406\ttotal: 190ms\tremaining: 370ms\n",
      "34:\tlearn: 0.4272389\ttotal: 192ms\tremaining: 357ms\n",
      "35:\tlearn: 0.4263767\ttotal: 194ms\tremaining: 344ms\n",
      "36:\tlearn: 0.4251900\ttotal: 195ms\tremaining: 332ms\n",
      "37:\tlearn: 0.4245057\ttotal: 197ms\tremaining: 321ms\n",
      "38:\tlearn: 0.4241345\ttotal: 199ms\tremaining: 311ms\n",
      "39:\tlearn: 0.4235640\ttotal: 200ms\tremaining: 300ms\n",
      "40:\tlearn: 0.4229555\ttotal: 202ms\tremaining: 291ms\n",
      "41:\tlearn: 0.4224378\ttotal: 204ms\tremaining: 281ms\n",
      "42:\tlearn: 0.4219596\ttotal: 205ms\tremaining: 272ms\n",
      "43:\tlearn: 0.4212877\ttotal: 207ms\tremaining: 264ms\n",
      "44:\tlearn: 0.4209664\ttotal: 209ms\tremaining: 255ms\n",
      "45:\tlearn: 0.4205817\ttotal: 210ms\tremaining: 247ms\n",
      "46:\tlearn: 0.4199151\ttotal: 212ms\tremaining: 239ms\n",
      "47:\tlearn: 0.4196108\ttotal: 214ms\tremaining: 231ms\n",
      "48:\tlearn: 0.4192181\ttotal: 216ms\tremaining: 224ms\n",
      "49:\tlearn: 0.4183895\ttotal: 217ms\tremaining: 217ms\n",
      "50:\tlearn: 0.4181165\ttotal: 219ms\tremaining: 211ms\n",
      "51:\tlearn: 0.4176998\ttotal: 221ms\tremaining: 204ms\n",
      "52:\tlearn: 0.4174829\ttotal: 223ms\tremaining: 197ms\n",
      "53:\tlearn: 0.4169022\ttotal: 224ms\tremaining: 191ms\n",
      "54:\tlearn: 0.4166820\ttotal: 226ms\tremaining: 185ms\n",
      "55:\tlearn: 0.4162275\ttotal: 228ms\tremaining: 179ms\n",
      "56:\tlearn: 0.4159016\ttotal: 230ms\tremaining: 173ms\n",
      "57:\tlearn: 0.4155052\ttotal: 232ms\tremaining: 168ms\n",
      "58:\tlearn: 0.4152488\ttotal: 234ms\tremaining: 162ms\n",
      "59:\tlearn: 0.4147073\ttotal: 235ms\tremaining: 157ms\n",
      "60:\tlearn: 0.4143561\ttotal: 237ms\tremaining: 151ms\n",
      "61:\tlearn: 0.4142058\ttotal: 239ms\tremaining: 146ms\n",
      "62:\tlearn: 0.4138214\ttotal: 240ms\tremaining: 141ms\n",
      "63:\tlearn: 0.4136236\ttotal: 242ms\tremaining: 136ms\n",
      "64:\tlearn: 0.4133681\ttotal: 243ms\tremaining: 131ms\n",
      "65:\tlearn: 0.4132407\ttotal: 245ms\tremaining: 126ms\n",
      "66:\tlearn: 0.4130741\ttotal: 247ms\tremaining: 122ms\n",
      "67:\tlearn: 0.4126753\ttotal: 249ms\tremaining: 117ms\n",
      "68:\tlearn: 0.4123174\ttotal: 250ms\tremaining: 112ms\n",
      "69:\tlearn: 0.4122396\ttotal: 252ms\tremaining: 108ms\n",
      "70:\tlearn: 0.4119688\ttotal: 254ms\tremaining: 104ms\n",
      "71:\tlearn: 0.4117461\ttotal: 255ms\tremaining: 99.2ms\n",
      "72:\tlearn: 0.4114734\ttotal: 257ms\tremaining: 95ms\n",
      "73:\tlearn: 0.4111074\ttotal: 258ms\tremaining: 90.8ms\n",
      "74:\tlearn: 0.4109737\ttotal: 260ms\tremaining: 86.7ms\n",
      "75:\tlearn: 0.4108037\ttotal: 262ms\tremaining: 82.7ms\n",
      "76:\tlearn: 0.4107057\ttotal: 264ms\tremaining: 78.8ms\n",
      "77:\tlearn: 0.4106101\ttotal: 265ms\tremaining: 74.8ms\n",
      "78:\tlearn: 0.4101328\ttotal: 267ms\tremaining: 71ms\n",
      "79:\tlearn: 0.4097624\ttotal: 269ms\tremaining: 67.2ms\n",
      "80:\tlearn: 0.4095420\ttotal: 271ms\tremaining: 63.5ms\n",
      "81:\tlearn: 0.4092330\ttotal: 272ms\tremaining: 59.8ms\n",
      "82:\tlearn: 0.4087715\ttotal: 274ms\tremaining: 56.2ms\n",
      "83:\tlearn: 0.4085699\ttotal: 276ms\tremaining: 52.6ms\n",
      "84:\tlearn: 0.4084720\ttotal: 278ms\tremaining: 49ms\n",
      "85:\tlearn: 0.4083743\ttotal: 280ms\tremaining: 45.5ms\n",
      "86:\tlearn: 0.4082875\ttotal: 281ms\tremaining: 42.1ms\n",
      "87:\tlearn: 0.4080676\ttotal: 283ms\tremaining: 38.6ms\n",
      "88:\tlearn: 0.4077781\ttotal: 285ms\tremaining: 35.2ms\n",
      "89:\tlearn: 0.4074841\ttotal: 287ms\tremaining: 31.8ms\n",
      "90:\tlearn: 0.4072383\ttotal: 288ms\tremaining: 28.5ms\n",
      "91:\tlearn: 0.4069609\ttotal: 290ms\tremaining: 25.2ms\n",
      "92:\tlearn: 0.4068589\ttotal: 292ms\tremaining: 22ms\n",
      "93:\tlearn: 0.4065635\ttotal: 294ms\tremaining: 18.8ms\n",
      "94:\tlearn: 0.4063680\ttotal: 296ms\tremaining: 15.6ms\n",
      "95:\tlearn: 0.4061793\ttotal: 298ms\tremaining: 12.4ms\n",
      "96:\tlearn: 0.4059738\ttotal: 300ms\tremaining: 9.28ms\n",
      "97:\tlearn: 0.4057501\ttotal: 302ms\tremaining: 6.15ms\n",
      "98:\tlearn: 0.4055549\ttotal: 303ms\tremaining: 3.06ms\n",
      "99:\tlearn: 0.4052646\ttotal: 305ms\tremaining: 0us\n",
      "100/100 [==============================] - 0s 645us/step\n",
      "100/100 [==============================] - 0s 819us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 3181it [00:11, 93.62it/s]                                                                    \n",
      "ExactExplainer explainer: 3181it [00:31, 66.88it/s]                                                                    \n",
      "ExactExplainer explainer: 3181it [03:51, 13.47it/s]                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3733, number of negative: 3685\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 7418, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503235 -> initscore=0.012942\n",
      "[LightGBM] [Info] Start training from score 0.012942\n",
      "0:\tlearn: 0.6562775\ttotal: 1.6ms\tremaining: 158ms\n",
      "1:\tlearn: 0.6254255\ttotal: 3.11ms\tremaining: 152ms\n",
      "2:\tlearn: 0.5998611\ttotal: 4.55ms\tremaining: 147ms\n",
      "3:\tlearn: 0.5790303\ttotal: 6.08ms\tremaining: 146ms\n",
      "4:\tlearn: 0.5621130\ttotal: 7.58ms\tremaining: 144ms\n",
      "5:\tlearn: 0.5451802\ttotal: 9.05ms\tremaining: 142ms\n",
      "6:\tlearn: 0.5320178\ttotal: 10.5ms\tremaining: 140ms\n",
      "7:\tlearn: 0.5202495\ttotal: 12.1ms\tremaining: 140ms\n",
      "8:\tlearn: 0.5109044\ttotal: 13.7ms\tremaining: 138ms\n",
      "9:\tlearn: 0.5007965\ttotal: 15.2ms\tremaining: 137ms\n",
      "10:\tlearn: 0.4940030\ttotal: 16.8ms\tremaining: 136ms\n",
      "11:\tlearn: 0.4868630\ttotal: 18.2ms\tremaining: 134ms\n",
      "12:\tlearn: 0.4820939\ttotal: 19.5ms\tremaining: 130ms\n",
      "13:\tlearn: 0.4761226\ttotal: 20.9ms\tremaining: 129ms\n",
      "14:\tlearn: 0.4708079\ttotal: 22.4ms\tremaining: 127ms\n",
      "15:\tlearn: 0.4663055\ttotal: 23.9ms\tremaining: 126ms\n",
      "16:\tlearn: 0.4631563\ttotal: 25.6ms\tremaining: 125ms\n",
      "17:\tlearn: 0.4597340\ttotal: 27.2ms\tremaining: 124ms\n",
      "18:\tlearn: 0.4551618\ttotal: 28.6ms\tremaining: 122ms\n",
      "19:\tlearn: 0.4526475\ttotal: 30.1ms\tremaining: 120ms\n",
      "20:\tlearn: 0.4497229\ttotal: 31.6ms\tremaining: 119ms\n",
      "21:\tlearn: 0.4470095\ttotal: 33.2ms\tremaining: 118ms\n",
      "22:\tlearn: 0.4447476\ttotal: 34.7ms\tremaining: 116ms\n",
      "23:\tlearn: 0.4427049\ttotal: 36.3ms\tremaining: 115ms\n",
      "24:\tlearn: 0.4409008\ttotal: 37.8ms\tremaining: 113ms\n",
      "25:\tlearn: 0.4388414\ttotal: 39.3ms\tremaining: 112ms\n",
      "26:\tlearn: 0.4373755\ttotal: 40.8ms\tremaining: 110ms\n",
      "27:\tlearn: 0.4358445\ttotal: 42.3ms\tremaining: 109ms\n",
      "28:\tlearn: 0.4344214\ttotal: 43.8ms\tremaining: 107ms\n",
      "29:\tlearn: 0.4326746\ttotal: 45.3ms\tremaining: 106ms\n",
      "30:\tlearn: 0.4311640\ttotal: 46.8ms\tremaining: 104ms\n",
      "31:\tlearn: 0.4300062\ttotal: 48.3ms\tremaining: 103ms\n",
      "32:\tlearn: 0.4289891\ttotal: 49.8ms\tremaining: 101ms\n",
      "33:\tlearn: 0.4278406\ttotal: 51.3ms\tremaining: 99.5ms\n",
      "34:\tlearn: 0.4272389\ttotal: 52.7ms\tremaining: 98ms\n",
      "35:\tlearn: 0.4263767\ttotal: 54.3ms\tremaining: 96.5ms\n",
      "36:\tlearn: 0.4251900\ttotal: 55.9ms\tremaining: 95.2ms\n",
      "37:\tlearn: 0.4245057\ttotal: 57.4ms\tremaining: 93.6ms\n",
      "38:\tlearn: 0.4241345\ttotal: 58.8ms\tremaining: 92ms\n",
      "39:\tlearn: 0.4235640\ttotal: 60.3ms\tremaining: 90.5ms\n",
      "40:\tlearn: 0.4229555\ttotal: 61.8ms\tremaining: 88.9ms\n",
      "41:\tlearn: 0.4224378\ttotal: 63.2ms\tremaining: 87.3ms\n",
      "42:\tlearn: 0.4219596\ttotal: 64.7ms\tremaining: 85.7ms\n",
      "43:\tlearn: 0.4212877\ttotal: 66.2ms\tremaining: 84.3ms\n",
      "44:\tlearn: 0.4209664\ttotal: 67.7ms\tremaining: 82.7ms\n",
      "45:\tlearn: 0.4205817\ttotal: 69.2ms\tremaining: 81.2ms\n",
      "46:\tlearn: 0.4199151\ttotal: 70.8ms\tremaining: 79.8ms\n",
      "47:\tlearn: 0.4196108\ttotal: 72.2ms\tremaining: 78.2ms\n",
      "48:\tlearn: 0.4192181\ttotal: 73.6ms\tremaining: 76.6ms\n",
      "49:\tlearn: 0.4183895\ttotal: 75.1ms\tremaining: 75.1ms\n",
      "50:\tlearn: 0.4181165\ttotal: 76.6ms\tremaining: 73.6ms\n",
      "51:\tlearn: 0.4176998\ttotal: 78.1ms\tremaining: 72.1ms\n",
      "52:\tlearn: 0.4174829\ttotal: 79.6ms\tremaining: 70.6ms\n",
      "53:\tlearn: 0.4169022\ttotal: 81.1ms\tremaining: 69.1ms\n",
      "54:\tlearn: 0.4166820\ttotal: 82.6ms\tremaining: 67.6ms\n",
      "55:\tlearn: 0.4162275\ttotal: 84.1ms\tremaining: 66.1ms\n",
      "56:\tlearn: 0.4159016\ttotal: 85.6ms\tremaining: 64.5ms\n",
      "57:\tlearn: 0.4155052\ttotal: 87.1ms\tremaining: 63ms\n",
      "58:\tlearn: 0.4152488\ttotal: 88.5ms\tremaining: 61.5ms\n",
      "59:\tlearn: 0.4147073\ttotal: 90ms\tremaining: 60ms\n",
      "60:\tlearn: 0.4143561\ttotal: 91.5ms\tremaining: 58.5ms\n",
      "61:\tlearn: 0.4142058\ttotal: 92.9ms\tremaining: 56.9ms\n",
      "62:\tlearn: 0.4138214\ttotal: 94.4ms\tremaining: 55.4ms\n",
      "63:\tlearn: 0.4136236\ttotal: 95.8ms\tremaining: 53.9ms\n",
      "64:\tlearn: 0.4133681\ttotal: 97.5ms\tremaining: 52.5ms\n",
      "65:\tlearn: 0.4132407\ttotal: 99ms\tremaining: 51ms\n",
      "66:\tlearn: 0.4130741\ttotal: 100ms\tremaining: 49.4ms\n",
      "67:\tlearn: 0.4126753\ttotal: 102ms\tremaining: 47.9ms\n",
      "68:\tlearn: 0.4123174\ttotal: 103ms\tremaining: 46.4ms\n",
      "69:\tlearn: 0.4122396\ttotal: 105ms\tremaining: 44.9ms\n",
      "70:\tlearn: 0.4119688\ttotal: 106ms\tremaining: 43.4ms\n",
      "71:\tlearn: 0.4117461\ttotal: 108ms\tremaining: 41.9ms\n",
      "72:\tlearn: 0.4114734\ttotal: 109ms\tremaining: 40.3ms\n",
      "73:\tlearn: 0.4111074\ttotal: 110ms\tremaining: 38.8ms\n",
      "74:\tlearn: 0.4109737\ttotal: 112ms\tremaining: 37.3ms\n",
      "75:\tlearn: 0.4108037\ttotal: 113ms\tremaining: 35.8ms\n",
      "76:\tlearn: 0.4107057\ttotal: 115ms\tremaining: 34.3ms\n",
      "77:\tlearn: 0.4106101\ttotal: 116ms\tremaining: 32.8ms\n",
      "78:\tlearn: 0.4101328\ttotal: 118ms\tremaining: 31.3ms\n",
      "79:\tlearn: 0.4097624\ttotal: 119ms\tremaining: 29.8ms\n",
      "80:\tlearn: 0.4095420\ttotal: 121ms\tremaining: 28.3ms\n",
      "81:\tlearn: 0.4092330\ttotal: 122ms\tremaining: 26.8ms\n",
      "82:\tlearn: 0.4087715\ttotal: 124ms\tremaining: 25.4ms\n",
      "83:\tlearn: 0.4085699\ttotal: 125ms\tremaining: 23.9ms\n",
      "84:\tlearn: 0.4084720\ttotal: 127ms\tremaining: 22.4ms\n",
      "85:\tlearn: 0.4083743\ttotal: 128ms\tremaining: 20.9ms\n",
      "86:\tlearn: 0.4082875\ttotal: 130ms\tremaining: 19.4ms\n",
      "87:\tlearn: 0.4080676\ttotal: 131ms\tremaining: 17.9ms\n",
      "88:\tlearn: 0.4077781\ttotal: 133ms\tremaining: 16.4ms\n",
      "89:\tlearn: 0.4074841\ttotal: 134ms\tremaining: 14.9ms\n",
      "90:\tlearn: 0.4072383\ttotal: 136ms\tremaining: 13.4ms\n",
      "91:\tlearn: 0.4069609\ttotal: 137ms\tremaining: 11.9ms\n",
      "92:\tlearn: 0.4068589\ttotal: 139ms\tremaining: 10.4ms\n",
      "93:\tlearn: 0.4065635\ttotal: 140ms\tremaining: 8.95ms\n",
      "94:\tlearn: 0.4063680\ttotal: 142ms\tremaining: 7.45ms\n",
      "95:\tlearn: 0.4061793\ttotal: 143ms\tremaining: 5.96ms\n",
      "96:\tlearn: 0.4059738\ttotal: 145ms\tremaining: 4.47ms\n",
      "97:\tlearn: 0.4057501\ttotal: 146ms\tremaining: 2.98ms\n",
      "98:\tlearn: 0.4055549\ttotal: 147ms\tremaining: 1.49ms\n",
      "99:\tlearn: 0.4052646\ttotal: 149ms\tremaining: 0us\n",
      "100/100 [==============================] - 0s 585us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using SHAP with RNN: in user code:\n",
      "\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 244, in grad_graph  *\n",
      "        out = self.model(shap_rAnD)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 371, in custom_grad\n",
      "        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefix before the lookup\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 663, in handler\n",
      "        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 670, in linearity_with_excluded_handler\n",
      "        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 222, in _variable_inputs\n",
      "        out[i] = t.name in self.between_tensors\n",
      "\n",
      "    AttributeError: Exception encountered when calling layer 'lstm' (type LSTM).\n",
      "    \n",
      "    'TFDeep' object has no attribute 'between_tensors'\n",
      "    \n",
      "    Call arguments received by layer 'lstm' (type LSTM):\n",
      "      • inputs=tf.Tensor(shape=(14836, 1, 1), dtype=float32)\n",
      "      • mask=None\n",
      "      • training=False\n",
      "      • initial_state=None\n",
      "\n",
      "\n",
      "Hasil Evaluasi ML/DL tanpa XAI:\n",
      "[['DecisionTree', 0.8089887640449438, 0.7816091954022989, 0.7950633322507308, 0.8015723270440251, 0.018052339553833008], ['RandomForest', 0.7594611930724824, 0.756066411238825, 0.75776, 0.7619496855345912, 0.8126010894775391], ['Logistic Regression', 0.580973952434881, 0.9827586206896551, 0.7302491103202846, 0.6424528301886793, 0.015231609344482422], ['Naive Bayes', 0.564935064935065, 1.0, 0.7219917012448133, 0.620754716981132, 0.003018617630004883], ['MLP', 0.5808767951625095, 0.9814814814814815, 0.7298195631528965, 0.6421383647798742, 1.8823156356811523], ['Stochastic Gradient Descent', 0.6897637795275591, 0.8390804597701149, 0.7571305099394987, 0.7349056603773585, 0.03362321853637695], ['ADA Boost', 0.7927527018436109, 0.7962962962962963, 0.7945205479452055, 0.7971698113207547, 0.45903539657592773], ['Gradient Boosting', 0.8014276443867618, 0.7886334610472542, 0.7949790794979079, 0.799685534591195, 0.5902795791625977], ['XGBoost', 0.8, 0.7994891443167306, 0.7997444905780902, 0.8028301886792453, 1.364184856414795], ['LightGBM', 0.7988394584139265, 0.7911877394636015, 0.794995187680462, 0.7990566037735849, 0.21364331245422363], ['CatBoost', 0.80249343832021, 0.780970625798212, 0.7915857605177995, 0.7974842767295598, 0.36622047424316406], ['DNN', 0.6561938958707361, 0.933588761174968, 0.7706905640484976, 0.7264150943396226, 1.9747395515441895], ['RNN', 0.6613780598368088, 0.9316730523627076, 0.7735949098621422, 0.7314465408805031, 4.361464500427246]]\n",
      "\n",
      "Hasil Evaluasi ML/DL dengan XAI:\n",
      "[['DecisionTree', 0.8089887640449438, 0.7816091954022989, 0.7950633322507308, 0.8015723270440251, 0.019724130630493164, {'SHAP': array([[ 0.00521284, -0.00521284]])}], ['RandomForest', 0.7578879587894398, 0.7515964240102171, 0.75472907983328, 0.7594339622641509, 0.7298111915588379, {'SHAP': array([[ 0.025329, -0.025329]])}], ['Logistic Regression', 0.580973952434881, 0.9827586206896551, 0.7302491103202846, 0.6424528301886793, 0.011531591415405273, {'SHAP': array([[ 0.0151463, -0.0151463]])}], ['Naive Bayes', 0.564935064935065, 1.0, 0.7219917012448133, 0.620754716981132, 0.004001140594482422, {'SHAP': array([[ 0.01799454, -0.01799454]])}], ['MLP', 0.5808767951625095, 0.9814814814814815, 0.7298195631528965, 0.6421383647798742, 2.2019572257995605, {'SHAP': array([[ 0.01526238, -0.01526238]])}], ['Stochastic Gradient Descent', 0.6897637795275591, 0.8390804597701149, 0.7571305099394987, 0.7349056603773585, 0.03857684135437012, {'SHAP': array([[ 0.06622142, -0.06622142]])}], ['ADA Boost', 0.7927527018436109, 0.7962962962962963, 0.7945205479452055, 0.7971698113207547, 1.3158531188964844, {'SHAP': array([[ 0.00092579, -0.00092579]])}], ['Gradient Boosting', 0.8014276443867618, 0.7886334610472542, 0.7949790794979079, 0.799685534591195, 0.5470278263092041, {'SHAP': array([[ 0.00574079, -0.00574079]])}], ['XGBoost', 0.8, 0.7994891443167306, 0.7997444905780902, 0.8028301886792453, 0.041567087173461914, {'SHAP': array([[-0.00484365,  0.00484364]])}], ['LightGBM', 0.7988394584139265, 0.7911877394636015, 0.794995187680462, 0.7990566037735849, 0.04117989540100098, {'SHAP': array([[ 0.00608753, -0.00608753]])}], ['CatBoost', 0.80249343832021, 0.780970625798212, 0.7915857605177995, 0.7974842767295598, 0.18930411338806152, {'SHAP': array([[ 0.00567031, -0.00567031]])}], ['DNN', 0.6751652502360718, 0.913154533844189, 0.7763300760043431, 0.740880503144654, 1.4384174346923828, {'SHAP': array([0.3268446])}], ['RNN', 0.6640803286170698, 0.9291187739463601, 0.7745541655576257, 0.7336477987421384, 4.879614591598511, {'SHAP': None}]]\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi variabel untuk menyimpan hasil evaluasi\n",
    "hasil_ml_dl = []\n",
    "hasil_ml_dl_xai = []\n",
    "\n",
    "# Encode labels ke bentuk numerik jika diperlukan\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Fungsi untuk mengevaluasi model ML/DL\n",
    "def EvaluateModel(model_name, model, X_train, y_train, X_test, y_test, use_xai=False, is_dl_model=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Melatih model\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0) if is_dl_model else model.fit(X_train, y_train)\n",
    "    \n",
    "    if is_dl_model:\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    elif hasattr(model, 'predict_proba'):\n",
    "        # Model dengan metode predict_proba\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        if y_pred_proba.shape[1] > 1:  # Model klasifikasi multi-kelas\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        else:  # Model klasifikasi biner\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    else:\n",
    "        # Model tanpa metode predict_proba\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "\n",
    "    # Menghitung confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Menghitung metrik\n",
    "    Precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    Recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    F1Score = 2 * ((Precision * Recall) / (Precision + Recall)) if (Precision + Recall) != 0 else 0\n",
    "    Accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) != 0 else 0\n",
    "\n",
    "    # Menghitung waktu running\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "    # Jika XAI diperlukan, tambahkan analisis dengan SHAP\n",
    "    if use_xai:\n",
    "        # Periksa apakah X_train adalah DataFrame\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            feature_names = X_train.columns\n",
    "        else:\n",
    "            feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "        \n",
    "        # Perbaiki format X_train untuk SHAP\n",
    "        if is_dl_model:\n",
    "            X_train_for_xai = X_train.reshape((X_train.shape[0], X_train.shape[1]))\n",
    "            X_test_for_xai = X_test.reshape((X_test.shape[0], X_test.shape[1]))\n",
    "        else:\n",
    "            X_train_for_xai = X_train\n",
    "            X_test_for_xai = X_test\n",
    "\n",
    "        # Gunakan SHAP\n",
    "        try:\n",
    "            if is_dl_model:\n",
    "                explainer = shap.DeepExplainer(model, X_train_for_xai)\n",
    "                shap_values = explainer.shap_values(X_test_for_xai)\n",
    "                shap_summary = np.mean(shap_values[0], axis=0)\n",
    "            else:\n",
    "                explainer = shap.Explainer(model.predict_proba, X_train_for_xai)\n",
    "                shap_values = explainer(X_test_for_xai)\n",
    "                shap_summary = shap_values.values.mean(axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error using SHAP with {model_name}: {e}\")\n",
    "            shap_summary = None\n",
    "\n",
    "        # Simpan hasil evaluasi dengan XAI\n",
    "        hasil_ml_dl_xai.append([model_name, Precision, Recall, F1Score, Accuracy, run_time, {'SHAP': shap_summary}])\n",
    "    else:\n",
    "        # Simpan hasil evaluasi tanpa XAI\n",
    "        hasil_ml_dl.append([model_name, Precision, Recall, F1Score, Accuracy, run_time])\n",
    "\n",
    "# Model ML dan DL yang akan dievaluasi\n",
    "model_ml_dl = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=10),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=50),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0, max_iter=10000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000),\n",
    "    \"Stochastic Gradient Descent\": SGDClassifier(loss='log_loss', random_state=42),\n",
    "    \"ADA Boost\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='Logloss')\n",
    "}\n",
    "\n",
    "model_dl = {\n",
    "    \"DNN\": Sequential([\n",
    "        Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "   # \"CNN\": Sequential([\n",
    "   #     Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "   #     MaxPooling1D(pool_size=2),\n",
    "   #     Flatten(),\n",
    "   #     Dense(128, activation='relu'),\n",
    "   #     Dense(1, activation='sigmoid')\n",
    "   # ]),\n",
    "    \"RNN\": Sequential([\n",
    "        LSTM(100, input_shape=(X_train.shape[1], 1)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Pastikan X_train dan X_test memiliki bentuk yang sesuai untuk DL\n",
    "X_train_dl = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_dl = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Mengevaluasi model ML tanpa XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=False)\n",
    "\n",
    "# Mengevaluasi model DL tanpa XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=False, is_dl_model=True)\n",
    "\n",
    "# Mengevaluasi model ML dengan XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=True)\n",
    "\n",
    "# Mengevaluasi model DL dengan XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=True, is_dl_model=True)\n",
    "\n",
    "# Print hasil evaluasi tanpa XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL tanpa XAI:\")\n",
    "print(hasil_ml_dl)\n",
    "\n",
    "# Print hasil evaluasi dengan XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL dengan XAI:\")\n",
    "print(hasil_ml_dl_xai)\n",
    "\n",
    "# Convert results to DataFrame and save to CSV\n",
    "df_ml_dl = pd.DataFrame(hasil_ml_dl, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\"])\n",
    "df_ml_dl_xai = pd.DataFrame(hasil_ml_dl_xai, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\", \"XAI\"])\n",
    "\n",
    "df_ml_dl.to_csv(\"hasil_evaluasi_ml_dl_VTFC.csv\", index=False)\n",
    "df_ml_dl_xai.to_csv(\"hasil_evaluasi_ml_dl_xai_VTFC.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
