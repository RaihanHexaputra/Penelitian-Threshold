{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674d68be-dee1-4910-a28e-f08a102316c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk pengolahan data dan visualisasi\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Library untuk evaluasi dan model machine learning\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Library untuk Explainable AI (XAI)\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import shap\n",
    "\n",
    "# Library untuk Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103abc4c-1b2e-4ca0-82e5-0b66b34b6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dataset \n",
    "\n",
    "DM = pd.read_csv(\"C:\\\\Data Raihan\\\\Penelitian Threshold\\\\Dataset\\\\CIC-PDFMal2022\\\\PDFMalware2022.csv\") #DM--> Dataset Malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b14026-c76d-4c99-8f2a-723225d2df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10026 entries, 0 to 10025\n",
      "Data columns (total 33 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Fine name         10026 non-null  object \n",
      " 1   pdfsize           10025 non-null  float64\n",
      " 2   metadata size     10025 non-null  float64\n",
      " 3   pages             10025 non-null  float64\n",
      " 4   xref Length       10025 non-null  float64\n",
      " 5   title characters  10025 non-null  float64\n",
      " 6   isEncrypted       10025 non-null  float64\n",
      " 7   embedded files    10025 non-null  float64\n",
      " 8   images            10025 non-null  object \n",
      " 9   text              10025 non-null  object \n",
      " 10  header            10025 non-null  object \n",
      " 11  obj               10023 non-null  object \n",
      " 12  endobj            10023 non-null  object \n",
      " 13  stream            10023 non-null  float64\n",
      " 14  endstream         10023 non-null  object \n",
      " 15  xref              10023 non-null  object \n",
      " 16  trailer           10023 non-null  float64\n",
      " 17  startxref         10023 non-null  object \n",
      " 18  pageno            10023 non-null  object \n",
      " 19  encrypt           10023 non-null  float64\n",
      " 20  ObjStm            10023 non-null  float64\n",
      " 21  JS                10023 non-null  object \n",
      " 22  Javascript        10023 non-null  object \n",
      " 23  AA                10023 non-null  object \n",
      " 24  OpenAction        10023 non-null  object \n",
      " 25  Acroform          10023 non-null  object \n",
      " 26  JBIG2Decode       10023 non-null  object \n",
      " 27  RichMedia         10023 non-null  object \n",
      " 28  launch            10023 non-null  object \n",
      " 29  EmbeddedFile      10023 non-null  object \n",
      " 30  XFA               10023 non-null  object \n",
      " 31  Colors            10023 non-null  float64\n",
      " 32  Class             10025 non-null  object \n",
      "dtypes: float64(12), object(21)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "DM.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dcbc54b-758f-4b1f-999c-71e61b807d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "X = DM.drop(['Fine name','images','text','header','obj','endobj','endstream','xref','startxref','pageno','JS','Javascript','AA','OpenAction','Acroform','JBIG2Decode','RichMedia','launch','EmbeddedFile','XFA','Class'],axis=1).values    #Droping this because classification model will not accept object type elements (float and int only)\n",
    "# Target variable\n",
    "y = DM['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41bd6d6c-c0ef-470b-9c61-cf4044411438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Nan\n",
    "X = pd.DataFrame(X).dropna()\n",
    "y = y[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba75d9b8-e9cf-428b-bee5-0f0eb118955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Fitting and choosing the important variables\n",
    "extratrees = ExtraTreesClassifier().fit(X, y)\n",
    "model = SelectFromModel(extratrees, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "nbfeatures = X_new.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa8ad04-c8ca-43d2-95fc-f272b05e0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "index = np.argsort(extratrees.feature_importances_)[::-1][:nbfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6b2406f-e52d-412d-8796-a035eea7d0bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. feature text (0.252478)\n",
      "2. feature pages (0.174801)\n",
      "3. feature header (0.164699)\n",
      "4. feature metadata size (0.121250)\n"
     ]
    }
   ],
   "source": [
    "#All the required features\n",
    "for f in range(nbfeatures):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, DM.columns[2+index[f]], extratrees.feature_importances_[index[f]]))\n",
    "    features.append(DM.columns[2+f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbdd0877-c2ba-4c27-a531-0e69ba6823e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memilih 10% data secara acak dari setiap fitur/column\n",
    "sampled_data = DM.groupby('Class').apply(lambda x: x.sample(frac=1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e80f57e-5a9d-4a57-bb55-befe23488bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d72e5bc-359f-4748-9ee8-8feb20ae68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels ke bentuk numerik jika diperlukan\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9672f567-73f9-4e26-9a88-fcab896c0f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3865, number of negative: 3151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 679\n",
      "[LightGBM] [Info] Number of data points in the train set: 7016, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550884 -> initscore=0.204242\n",
      "[LightGBM] [Info] Start training from score 0.204242\n",
      "0:\tlearn: 0.6225038\ttotal: 140ms\tremaining: 13.8s\n",
      "1:\tlearn: 0.5648435\ttotal: 141ms\tremaining: 6.93s\n",
      "2:\tlearn: 0.5146324\ttotal: 143ms\tremaining: 4.63s\n",
      "3:\tlearn: 0.4720224\ttotal: 145ms\tremaining: 3.47s\n",
      "4:\tlearn: 0.4350048\ttotal: 146ms\tremaining: 2.77s\n",
      "5:\tlearn: 0.4027545\ttotal: 148ms\tremaining: 2.31s\n",
      "6:\tlearn: 0.3755493\ttotal: 149ms\tremaining: 1.98s\n",
      "7:\tlearn: 0.3501847\ttotal: 151ms\tremaining: 1.73s\n",
      "8:\tlearn: 0.3271019\ttotal: 152ms\tremaining: 1.54s\n",
      "9:\tlearn: 0.3073735\ttotal: 154ms\tremaining: 1.39s\n",
      "10:\tlearn: 0.2902005\ttotal: 155ms\tremaining: 1.26s\n",
      "11:\tlearn: 0.2746216\ttotal: 157ms\tremaining: 1.15s\n",
      "12:\tlearn: 0.2600925\ttotal: 159ms\tremaining: 1.06s\n",
      "13:\tlearn: 0.2475987\ttotal: 160ms\tremaining: 985ms\n",
      "14:\tlearn: 0.2359112\ttotal: 162ms\tremaining: 917ms\n",
      "15:\tlearn: 0.2253975\ttotal: 163ms\tremaining: 858ms\n",
      "16:\tlearn: 0.2167833\ttotal: 165ms\tremaining: 806ms\n",
      "17:\tlearn: 0.2092614\ttotal: 167ms\tremaining: 759ms\n",
      "18:\tlearn: 0.2017174\ttotal: 168ms\tremaining: 718ms\n",
      "19:\tlearn: 0.1944779\ttotal: 170ms\tremaining: 680ms\n",
      "20:\tlearn: 0.1880450\ttotal: 171ms\tremaining: 645ms\n",
      "21:\tlearn: 0.1815289\ttotal: 173ms\tremaining: 613ms\n",
      "22:\tlearn: 0.1763367\ttotal: 174ms\tremaining: 584ms\n",
      "23:\tlearn: 0.1709611\ttotal: 176ms\tremaining: 557ms\n",
      "24:\tlearn: 0.1669190\ttotal: 177ms\tremaining: 532ms\n",
      "25:\tlearn: 0.1625019\ttotal: 179ms\tremaining: 510ms\n",
      "26:\tlearn: 0.1586400\ttotal: 181ms\tremaining: 489ms\n",
      "27:\tlearn: 0.1561253\ttotal: 182ms\tremaining: 469ms\n",
      "28:\tlearn: 0.1534304\ttotal: 184ms\tremaining: 450ms\n",
      "29:\tlearn: 0.1505491\ttotal: 185ms\tremaining: 433ms\n",
      "30:\tlearn: 0.1471110\ttotal: 187ms\tremaining: 416ms\n",
      "31:\tlearn: 0.1442390\ttotal: 189ms\tremaining: 401ms\n",
      "32:\tlearn: 0.1412542\ttotal: 190ms\tremaining: 386ms\n",
      "33:\tlearn: 0.1387046\ttotal: 192ms\tremaining: 372ms\n",
      "34:\tlearn: 0.1360860\ttotal: 193ms\tremaining: 359ms\n",
      "35:\tlearn: 0.1347027\ttotal: 195ms\tremaining: 347ms\n",
      "36:\tlearn: 0.1329165\ttotal: 197ms\tremaining: 335ms\n",
      "37:\tlearn: 0.1316439\ttotal: 199ms\tremaining: 324ms\n",
      "38:\tlearn: 0.1304193\ttotal: 200ms\tremaining: 313ms\n",
      "39:\tlearn: 0.1289349\ttotal: 202ms\tremaining: 303ms\n",
      "40:\tlearn: 0.1277465\ttotal: 204ms\tremaining: 293ms\n",
      "41:\tlearn: 0.1260828\ttotal: 205ms\tremaining: 283ms\n",
      "42:\tlearn: 0.1247887\ttotal: 207ms\tremaining: 274ms\n",
      "43:\tlearn: 0.1235842\ttotal: 208ms\tremaining: 265ms\n",
      "44:\tlearn: 0.1218344\ttotal: 210ms\tremaining: 257ms\n",
      "45:\tlearn: 0.1203481\ttotal: 212ms\tremaining: 249ms\n",
      "46:\tlearn: 0.1195323\ttotal: 214ms\tremaining: 241ms\n",
      "47:\tlearn: 0.1178549\ttotal: 216ms\tremaining: 234ms\n",
      "48:\tlearn: 0.1170335\ttotal: 217ms\tremaining: 226ms\n",
      "49:\tlearn: 0.1160720\ttotal: 219ms\tremaining: 219ms\n",
      "50:\tlearn: 0.1155176\ttotal: 220ms\tremaining: 212ms\n",
      "51:\tlearn: 0.1139071\ttotal: 222ms\tremaining: 205ms\n",
      "52:\tlearn: 0.1132429\ttotal: 224ms\tremaining: 198ms\n",
      "53:\tlearn: 0.1120933\ttotal: 225ms\tremaining: 192ms\n",
      "54:\tlearn: 0.1111356\ttotal: 232ms\tremaining: 190ms\n",
      "55:\tlearn: 0.1103830\ttotal: 234ms\tremaining: 184ms\n",
      "56:\tlearn: 0.1099219\ttotal: 235ms\tremaining: 177ms\n",
      "57:\tlearn: 0.1089765\ttotal: 237ms\tremaining: 171ms\n",
      "58:\tlearn: 0.1086635\ttotal: 238ms\tremaining: 166ms\n",
      "59:\tlearn: 0.1077198\ttotal: 240ms\tremaining: 160ms\n",
      "60:\tlearn: 0.1077156\ttotal: 241ms\tremaining: 154ms\n",
      "61:\tlearn: 0.1073729\ttotal: 242ms\tremaining: 148ms\n",
      "62:\tlearn: 0.1063665\ttotal: 244ms\tremaining: 143ms\n",
      "63:\tlearn: 0.1063622\ttotal: 244ms\tremaining: 137ms\n",
      "64:\tlearn: 0.1058240\ttotal: 246ms\tremaining: 132ms\n",
      "65:\tlearn: 0.1056750\ttotal: 247ms\tremaining: 127ms\n",
      "66:\tlearn: 0.1049726\ttotal: 249ms\tremaining: 123ms\n",
      "67:\tlearn: 0.1041842\ttotal: 250ms\tremaining: 118ms\n",
      "68:\tlearn: 0.1033431\ttotal: 252ms\tremaining: 113ms\n",
      "69:\tlearn: 0.1022336\ttotal: 254ms\tremaining: 109ms\n",
      "70:\tlearn: 0.1017337\ttotal: 255ms\tremaining: 104ms\n",
      "71:\tlearn: 0.1015070\ttotal: 257ms\tremaining: 100ms\n",
      "72:\tlearn: 0.1009685\ttotal: 259ms\tremaining: 95.7ms\n",
      "73:\tlearn: 0.1009643\ttotal: 260ms\tremaining: 91.2ms\n",
      "74:\tlearn: 0.1009566\ttotal: 261ms\tremaining: 86.9ms\n",
      "75:\tlearn: 0.1008286\ttotal: 262ms\tremaining: 82.7ms\n",
      "76:\tlearn: 0.1006039\ttotal: 263ms\tremaining: 78.7ms\n",
      "77:\tlearn: 0.1003365\ttotal: 265ms\tremaining: 74.7ms\n",
      "78:\tlearn: 0.1003323\ttotal: 266ms\tremaining: 70.6ms\n",
      "79:\tlearn: 0.0999905\ttotal: 267ms\tremaining: 66.8ms\n",
      "80:\tlearn: 0.0999842\ttotal: 268ms\tremaining: 62.9ms\n",
      "81:\tlearn: 0.0999799\ttotal: 269ms\tremaining: 59ms\n",
      "82:\tlearn: 0.0995468\ttotal: 271ms\tremaining: 55.4ms\n",
      "83:\tlearn: 0.0992222\ttotal: 272ms\tremaining: 51.9ms\n",
      "84:\tlearn: 0.0987468\ttotal: 274ms\tremaining: 48.3ms\n",
      "85:\tlearn: 0.0986756\ttotal: 275ms\tremaining: 44.8ms\n",
      "86:\tlearn: 0.0981420\ttotal: 277ms\tremaining: 41.4ms\n",
      "87:\tlearn: 0.0980842\ttotal: 279ms\tremaining: 38ms\n",
      "88:\tlearn: 0.0974691\ttotal: 280ms\tremaining: 34.6ms\n",
      "89:\tlearn: 0.0972219\ttotal: 282ms\tremaining: 31.3ms\n",
      "90:\tlearn: 0.0966257\ttotal: 284ms\tremaining: 28ms\n",
      "91:\tlearn: 0.0959407\ttotal: 285ms\tremaining: 24.8ms\n",
      "92:\tlearn: 0.0958526\ttotal: 287ms\tremaining: 21.6ms\n",
      "93:\tlearn: 0.0955513\ttotal: 288ms\tremaining: 18.4ms\n",
      "94:\tlearn: 0.0954358\ttotal: 290ms\tremaining: 15.3ms\n",
      "95:\tlearn: 0.0953970\ttotal: 291ms\tremaining: 12.1ms\n",
      "96:\tlearn: 0.0951661\ttotal: 293ms\tremaining: 9.06ms\n",
      "97:\tlearn: 0.0951625\ttotal: 294ms\tremaining: 6ms\n",
      "98:\tlearn: 0.0949176\ttotal: 296ms\tremaining: 2.99ms\n",
      "99:\tlearn: 0.0949141\ttotal: 296ms\tremaining: 0us\n",
      "94/94 [==============================] - 0s 657us/step\n",
      "94/94 [==============================] - 0s 701us/step\n",
      "94/94 [==============================] - 0s 987us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 3008it [00:38, 58.68it/s]                                                                    \n",
      "ExactExplainer explainer: 3008it [02:07, 21.82it/s]                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3865, number of negative: 3151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 679\n",
      "[LightGBM] [Info] Number of data points in the train set: 7016, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550884 -> initscore=0.204242\n",
      "[LightGBM] [Info] Start training from score 0.204242\n",
      "0:\tlearn: 0.6225038\ttotal: 1.79ms\tremaining: 178ms\n",
      "1:\tlearn: 0.5648435\ttotal: 3.32ms\tremaining: 163ms\n",
      "2:\tlearn: 0.5146324\ttotal: 4.85ms\tremaining: 157ms\n",
      "3:\tlearn: 0.4720224\ttotal: 6.29ms\tremaining: 151ms\n",
      "4:\tlearn: 0.4350048\ttotal: 7.85ms\tremaining: 149ms\n",
      "5:\tlearn: 0.4027545\ttotal: 9.48ms\tremaining: 149ms\n",
      "6:\tlearn: 0.3755493\ttotal: 11.1ms\tremaining: 148ms\n",
      "7:\tlearn: 0.3501847\ttotal: 12.8ms\tremaining: 147ms\n",
      "8:\tlearn: 0.3271019\ttotal: 14.5ms\tremaining: 146ms\n",
      "9:\tlearn: 0.3073735\ttotal: 15.9ms\tremaining: 143ms\n",
      "10:\tlearn: 0.2902005\ttotal: 17.5ms\tremaining: 141ms\n",
      "11:\tlearn: 0.2746216\ttotal: 19ms\tremaining: 139ms\n",
      "12:\tlearn: 0.2600925\ttotal: 26.5ms\tremaining: 177ms\n",
      "13:\tlearn: 0.2475987\ttotal: 28.1ms\tremaining: 173ms\n",
      "14:\tlearn: 0.2359112\ttotal: 29.7ms\tremaining: 168ms\n",
      "15:\tlearn: 0.2253975\ttotal: 31.2ms\tremaining: 164ms\n",
      "16:\tlearn: 0.2167833\ttotal: 32.8ms\tremaining: 160ms\n",
      "17:\tlearn: 0.2092614\ttotal: 34.4ms\tremaining: 157ms\n",
      "18:\tlearn: 0.2017174\ttotal: 35.9ms\tremaining: 153ms\n",
      "19:\tlearn: 0.1944779\ttotal: 37.5ms\tremaining: 150ms\n",
      "20:\tlearn: 0.1880450\ttotal: 39.1ms\tremaining: 147ms\n",
      "21:\tlearn: 0.1815289\ttotal: 40.7ms\tremaining: 144ms\n",
      "22:\tlearn: 0.1763367\ttotal: 42.4ms\tremaining: 142ms\n",
      "23:\tlearn: 0.1709611\ttotal: 44.2ms\tremaining: 140ms\n",
      "24:\tlearn: 0.1669190\ttotal: 45.8ms\tremaining: 137ms\n",
      "25:\tlearn: 0.1625019\ttotal: 47.5ms\tremaining: 135ms\n",
      "26:\tlearn: 0.1586400\ttotal: 49.2ms\tremaining: 133ms\n",
      "27:\tlearn: 0.1561253\ttotal: 51.1ms\tremaining: 131ms\n",
      "28:\tlearn: 0.1534304\ttotal: 52.8ms\tremaining: 129ms\n",
      "29:\tlearn: 0.1505491\ttotal: 54.8ms\tremaining: 128ms\n",
      "30:\tlearn: 0.1471110\ttotal: 56.7ms\tremaining: 126ms\n",
      "31:\tlearn: 0.1442390\ttotal: 58.3ms\tremaining: 124ms\n",
      "32:\tlearn: 0.1412542\ttotal: 60.1ms\tremaining: 122ms\n",
      "33:\tlearn: 0.1387046\ttotal: 61.8ms\tremaining: 120ms\n",
      "34:\tlearn: 0.1360860\ttotal: 63.4ms\tremaining: 118ms\n",
      "35:\tlearn: 0.1347027\ttotal: 65.1ms\tremaining: 116ms\n",
      "36:\tlearn: 0.1329165\ttotal: 66.7ms\tremaining: 114ms\n",
      "37:\tlearn: 0.1316439\ttotal: 68.3ms\tremaining: 111ms\n",
      "38:\tlearn: 0.1304193\ttotal: 69.8ms\tremaining: 109ms\n",
      "39:\tlearn: 0.1289349\ttotal: 71.3ms\tremaining: 107ms\n",
      "40:\tlearn: 0.1277465\ttotal: 73.2ms\tremaining: 105ms\n",
      "41:\tlearn: 0.1260828\ttotal: 74.9ms\tremaining: 103ms\n",
      "42:\tlearn: 0.1247887\ttotal: 76.6ms\tremaining: 101ms\n",
      "43:\tlearn: 0.1235842\ttotal: 78.3ms\tremaining: 99.7ms\n",
      "44:\tlearn: 0.1218344\ttotal: 79.9ms\tremaining: 97.7ms\n",
      "45:\tlearn: 0.1203481\ttotal: 81.7ms\tremaining: 95.9ms\n",
      "46:\tlearn: 0.1195323\ttotal: 83.3ms\tremaining: 93.9ms\n",
      "47:\tlearn: 0.1178549\ttotal: 84.9ms\tremaining: 91.9ms\n",
      "48:\tlearn: 0.1170335\ttotal: 86.5ms\tremaining: 90ms\n",
      "49:\tlearn: 0.1160720\ttotal: 88.1ms\tremaining: 88.1ms\n",
      "50:\tlearn: 0.1155176\ttotal: 89.8ms\tremaining: 86.3ms\n",
      "51:\tlearn: 0.1139071\ttotal: 91.4ms\tremaining: 84.4ms\n",
      "52:\tlearn: 0.1132429\ttotal: 93.1ms\tremaining: 82.6ms\n",
      "53:\tlearn: 0.1120933\ttotal: 94.7ms\tremaining: 80.7ms\n",
      "54:\tlearn: 0.1111356\ttotal: 96.2ms\tremaining: 78.7ms\n",
      "55:\tlearn: 0.1103830\ttotal: 97.9ms\tremaining: 76.9ms\n",
      "56:\tlearn: 0.1099219\ttotal: 99.5ms\tremaining: 75ms\n",
      "57:\tlearn: 0.1089765\ttotal: 101ms\tremaining: 73.2ms\n",
      "58:\tlearn: 0.1086635\ttotal: 103ms\tremaining: 71.3ms\n",
      "59:\tlearn: 0.1077198\ttotal: 104ms\tremaining: 69.5ms\n",
      "60:\tlearn: 0.1077156\ttotal: 105ms\tremaining: 67ms\n",
      "61:\tlearn: 0.1073729\ttotal: 106ms\tremaining: 65.3ms\n",
      "62:\tlearn: 0.1063665\ttotal: 108ms\tremaining: 63.5ms\n",
      "63:\tlearn: 0.1063622\ttotal: 109ms\tremaining: 61.2ms\n",
      "64:\tlearn: 0.1058240\ttotal: 110ms\tremaining: 59.4ms\n",
      "65:\tlearn: 0.1056750\ttotal: 112ms\tremaining: 57.7ms\n",
      "66:\tlearn: 0.1049726\ttotal: 114ms\tremaining: 56ms\n",
      "67:\tlearn: 0.1041842\ttotal: 115ms\tremaining: 54.2ms\n",
      "68:\tlearn: 0.1033431\ttotal: 117ms\tremaining: 52.5ms\n",
      "69:\tlearn: 0.1022336\ttotal: 118ms\tremaining: 50.8ms\n",
      "70:\tlearn: 0.1017337\ttotal: 120ms\tremaining: 49ms\n",
      "71:\tlearn: 0.1015070\ttotal: 122ms\tremaining: 47.3ms\n",
      "72:\tlearn: 0.1009685\ttotal: 123ms\tremaining: 45.5ms\n",
      "73:\tlearn: 0.1009643\ttotal: 124ms\tremaining: 43.6ms\n",
      "74:\tlearn: 0.1009566\ttotal: 125ms\tremaining: 41.7ms\n",
      "75:\tlearn: 0.1008286\ttotal: 126ms\tremaining: 39.8ms\n",
      "76:\tlearn: 0.1006039\ttotal: 128ms\tremaining: 38.1ms\n",
      "77:\tlearn: 0.1003365\ttotal: 129ms\tremaining: 36.4ms\n",
      "78:\tlearn: 0.1003323\ttotal: 130ms\tremaining: 34.5ms\n",
      "79:\tlearn: 0.0999905\ttotal: 132ms\tremaining: 32.9ms\n",
      "80:\tlearn: 0.0999842\ttotal: 132ms\tremaining: 31.1ms\n",
      "81:\tlearn: 0.0999799\ttotal: 133ms\tremaining: 29.2ms\n",
      "82:\tlearn: 0.0995468\ttotal: 135ms\tremaining: 27.6ms\n",
      "83:\tlearn: 0.0992222\ttotal: 136ms\tremaining: 26ms\n",
      "84:\tlearn: 0.0987468\ttotal: 138ms\tremaining: 24.3ms\n",
      "85:\tlearn: 0.0986756\ttotal: 139ms\tremaining: 22.7ms\n",
      "86:\tlearn: 0.0981420\ttotal: 141ms\tremaining: 21.1ms\n",
      "87:\tlearn: 0.0980842\ttotal: 143ms\tremaining: 19.4ms\n",
      "88:\tlearn: 0.0974691\ttotal: 144ms\tremaining: 17.8ms\n",
      "89:\tlearn: 0.0972219\ttotal: 146ms\tremaining: 16.2ms\n",
      "90:\tlearn: 0.0966257\ttotal: 147ms\tremaining: 14.6ms\n",
      "91:\tlearn: 0.0959407\ttotal: 149ms\tremaining: 12.9ms\n",
      "92:\tlearn: 0.0958526\ttotal: 150ms\tremaining: 11.3ms\n",
      "93:\tlearn: 0.0955513\ttotal: 152ms\tremaining: 9.7ms\n",
      "94:\tlearn: 0.0954358\ttotal: 154ms\tremaining: 8.09ms\n",
      "95:\tlearn: 0.0953970\ttotal: 155ms\tremaining: 6.47ms\n",
      "96:\tlearn: 0.0951661\ttotal: 157ms\tremaining: 4.85ms\n",
      "97:\tlearn: 0.0951625\ttotal: 158ms\tremaining: 3.23ms\n",
      "98:\tlearn: 0.0949176\ttotal: 160ms\tremaining: 1.61ms\n",
      "99:\tlearn: 0.0949141\ttotal: 160ms\tremaining: 0us\n",
      "94/94 [==============================] - 0s 582us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 623us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using SHAP with CNN: operands could not be broadcast together with shapes (7016,4,1) (7016,4) \n",
      "94/94 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using SHAP with RNN: in user code:\n",
      "\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 244, in grad_graph  *\n",
      "        out = self.model(shap_rAnD)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 371, in custom_grad\n",
      "        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefix before the lookup\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 663, in handler\n",
      "        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 670, in linearity_with_excluded_handler\n",
      "        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 222, in _variable_inputs\n",
      "        out[i] = t.name in self.between_tensors\n",
      "\n",
      "    AttributeError: Exception encountered when calling layer 'lstm' (type LSTM).\n",
      "    \n",
      "    'TFDeep' object has no attribute 'between_tensors'\n",
      "    \n",
      "    Call arguments received by layer 'lstm' (type LSTM):\n",
      "      • inputs=tf.Tensor(shape=(14032, 4, 1), dtype=float32)\n",
      "      • mask=None\n",
      "      • training=False\n",
      "      • initial_state=None\n",
      "\n",
      "\n",
      "Hasil Evaluasi ML/DL tanpa XAI:\n",
      "[['DecisionTree', 0.9666471620830895, 0.9775147928994082, 0.9720506031185642, 0.9684070502161622, 0.014509439468383789], ['RandomForest', 0.9759389671361502, 0.9840236686390532, 0.9799646434885091, 0.9773860991020951, 0.24090909957885742], ['Logistic Regression', 0.8135330578512396, 0.9319526627218935, 0.8687258687258687, 0.8417026937146658, 0.035555124282836914], ['Naive Bayes', 0.9592901878914405, 0.5437869822485207, 0.6941087613293051, 0.7306285334220153, 0.005001544952392578], ['MLP', 0.5624791736087971, 0.9988165680473373, 0.719675975271797, 0.562687063518457, 0.5913314819335938], ['Stochastic Gradient Descent', 0.8241758241758241, 0.7544378698224852, 0.7877664504170527, 0.7715330894579315, 0.012628316879272461], ['ADA Boost', 0.9560117302052786, 0.9644970414201184, 0.9602356406480118, 0.9551047555703359, 0.4430959224700928], ['Gradient Boosting', 0.9722222222222222, 0.9733727810650887, 0.9727971614429333, 0.9694047223145993, 0.47850704193115234], ['XGBoost', 0.9782224838140082, 0.9834319526627219, 0.9808203009737385, 0.9783837712005321, 1.3499305248260498], ['LightGBM', 0.9765944997074313, 0.9875739644970414, 0.9820535451603413, 0.9797140006651147, 0.15108489990234375], ['CatBoost', 0.9704142011834319, 0.9704142011834319, 0.9704142011834319, 0.966744263385434, 0.3641204833984375], ['DNN', 0.9014662756598241, 0.9094674556213018, 0.9054491899852726, 0.8932490854672431, 1.7544209957122803], ['CNN', 0.8904573687182383, 0.9331360946745562, 0.9112973129153423, 0.8979048885932823, 1.866936445236206], ['RNN', 0.9106611078022633, 0.9047337278106509, 0.9076877411694865, 0.8965746591286997, 5.046772718429565]]\n",
      "\n",
      "Hasil Evaluasi ML/DL dengan XAI:\n",
      "[['DecisionTree', 0.9683470105509965, 0.9775147928994082, 0.9729093050647821, 0.9694047223145993, 0.009515523910522461, {'SHAP': array([[-0.00699364,  0.00699364],\n",
      "       [-0.0002373 ,  0.0002373 ],\n",
      "       [-0.02125371,  0.02125371],\n",
      "       [-0.00206284,  0.00206284]])}], ['RandomForest', 0.9736225087924971, 0.9828402366863905, 0.9782096584216726, 0.9753907549052212, 0.29899168014526367, {'SHAP': array([[-0.01207137,  0.01207137],\n",
      "       [-0.00171428,  0.00171428],\n",
      "       [-0.01713257,  0.01713257],\n",
      "       [-0.00199002,  0.00199002]])}], ['Logistic Regression', 0.8135330578512396, 0.9319526627218935, 0.8687258687258687, 0.8417026937146658, 0.03179764747619629, {'SHAP': array([[-0.00099555,  0.00099555],\n",
      "       [ 0.00028692, -0.00028692],\n",
      "       [-0.03951409,  0.03951409],\n",
      "       [-0.00056555,  0.00056555]])}], ['Naive Bayes', 0.9592901878914405, 0.5437869822485207, 0.6941087613293051, 0.7306285334220153, 0.003000497817993164, {'SHAP': array([[-0.00717924,  0.00717924],\n",
      "       [ 0.02157755, -0.02157755],\n",
      "       [-0.02408096,  0.02408096],\n",
      "       [-0.00050675,  0.00050675]])}], ['MLP', 0.5624791736087971, 0.9988165680473373, 0.719675975271797, 0.562687063518457, 0.5345814228057861, {'SHAP': array([[ 0.00633835, -0.00633835],\n",
      "       [ 0.00692791, -0.00692791],\n",
      "       [ 0.00047095, -0.00047095],\n",
      "       [ 0.00013877, -0.00013877]])}], ['Stochastic Gradient Descent', 0.8241758241758241, 0.7544378698224852, 0.7877664504170527, 0.7715330894579315, 0.018660545349121094, {'SHAP': array([[ 1.07609269e-02, -1.07609269e-02],\n",
      "       [ 1.03084548e-03, -1.03084548e-03],\n",
      "       [-4.61004271e-02,  4.61004271e-02],\n",
      "       [-3.12370620e-05,  3.12370620e-05]])}], ['ADA Boost', 0.9560117302052786, 0.9644970414201184, 0.9602356406480118, 0.9551047555703359, 0.461564302444458, {'SHAP': array([[-0.00026356,  0.00026356],\n",
      "       [ 0.0011529 , -0.0011529 ],\n",
      "       [-0.00068292,  0.00068292],\n",
      "       [ 0.0003373 , -0.0003373 ]])}], ['Gradient Boosting', 0.9722222222222222, 0.9733727810650887, 0.9727971614429333, 0.9694047223145993, 0.504662275314331, {'SHAP': array([[-0.00801376,  0.00801376],\n",
      "       [ 0.00744866, -0.00744866],\n",
      "       [-0.0126078 ,  0.0126078 ],\n",
      "       [ 0.00052568, -0.00052568]])}], ['XGBoost', 0.9782224838140082, 0.9834319526627219, 0.9808203009737385, 0.9783837712005321, 0.056120872497558594, {'SHAP': array([[-0.01439793,  0.01439793],\n",
      "       [-0.005563  ,  0.005563  ],\n",
      "       [-0.01453844,  0.01453844],\n",
      "       [ 0.00093599, -0.00093599]])}], ['LightGBM', 0.9765944997074313, 0.9875739644970414, 0.9820535451603413, 0.9797140006651147, 0.055426836013793945, {'SHAP': array([[-0.01343446,  0.01343446],\n",
      "       [-0.00198579,  0.00198579],\n",
      "       [-0.01256635,  0.01256635],\n",
      "       [-0.00394397,  0.00394397]])}], ['CatBoost', 0.9704142011834319, 0.9704142011834319, 0.9704142011834319, 0.966744263385434, 0.21755552291870117, {'SHAP': array([[-0.00490788,  0.00490788],\n",
      "       [ 0.01194486, -0.01194486],\n",
      "       [-0.01886779,  0.01886779],\n",
      "       [ 0.00111475, -0.00111475]])}], ['DNN', 0.9739039665970772, 0.5520710059171597, 0.7046827794561934, 0.7399401396740938, 1.9768664836883545, {'SHAP': array([0.160035])}], ['CNN', 0.9158180583842498, 0.7982248520710059, 0.8529876699336073, 0.845360824742268, 1.7261998653411865, {'SHAP': None}], ['RNN', 0.9167148640832852, 0.9378698224852071, 0.9271716876279614, 0.9171932158297307, 5.161798715591431, {'SHAP': None}]]\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi variabel untuk menyimpan hasil evaluasi\n",
    "hasil_ml_dl = []\n",
    "hasil_ml_dl_xai = []\n",
    "\n",
    "# Encode labels ke bentuk numerik jika diperlukan\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Fungsi untuk mengevaluasi model ML/DL\n",
    "def EvaluateModel(model_name, model, X_train, y_train, X_test, y_test, use_xai=False, is_dl_model=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Melatih model\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0) if is_dl_model else model.fit(X_train, y_train)\n",
    "    \n",
    "    if is_dl_model:\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    elif hasattr(model, 'predict_proba'):\n",
    "        # Model dengan metode predict_proba\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        if y_pred_proba.shape[1] > 1:  # Model klasifikasi multi-kelas\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        else:  # Model klasifikasi biner\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    else:\n",
    "        # Model tanpa metode predict_proba\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "\n",
    "    # Menghitung confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Menghitung metrik\n",
    "    Precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    Recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    F1Score = 2 * ((Precision * Recall) / (Precision + Recall)) if (Precision + Recall) != 0 else 0\n",
    "    Accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) != 0 else 0\n",
    "\n",
    "    # Menghitung waktu running\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "    # Jika XAI diperlukan, tambahkan analisis dengan SHAP\n",
    "    if use_xai:\n",
    "        # Periksa apakah X_train adalah DataFrame\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            feature_names = X_train.columns\n",
    "        else:\n",
    "            feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "        \n",
    "        # Perbaiki format X_train untuk SHAP\n",
    "        if is_dl_model:\n",
    "            X_train_for_xai = X_train.reshape((X_train.shape[0], X_train.shape[1]))\n",
    "            X_test_for_xai = X_test.reshape((X_test.shape[0], X_test.shape[1]))\n",
    "        else:\n",
    "            X_train_for_xai = X_train\n",
    "            X_test_for_xai = X_test\n",
    "\n",
    "        # Gunakan SHAP\n",
    "        try:\n",
    "            if is_dl_model:\n",
    "                explainer = shap.DeepExplainer(model, X_train_for_xai)\n",
    "                shap_values = explainer.shap_values(X_test_for_xai)\n",
    "                shap_summary = np.mean(shap_values[0], axis=0)\n",
    "            else:\n",
    "                explainer = shap.Explainer(model.predict_proba, X_train_for_xai)\n",
    "                shap_values = explainer(X_test_for_xai)\n",
    "                shap_summary = shap_values.values.mean(axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error using SHAP with {model_name}: {e}\")\n",
    "            shap_summary = None\n",
    "\n",
    "        # Simpan hasil evaluasi dengan XAI\n",
    "        hasil_ml_dl_xai.append([model_name, Precision, Recall, F1Score, Accuracy, run_time, {'SHAP': shap_summary}])\n",
    "    else:\n",
    "        # Simpan hasil evaluasi tanpa XAI\n",
    "        hasil_ml_dl.append([model_name, Precision, Recall, F1Score, Accuracy, run_time])\n",
    "\n",
    "# Model ML dan DL yang akan dievaluasi\n",
    "model_ml_dl = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=10),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=50),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0, max_iter=10000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000),\n",
    "    \"Stochastic Gradient Descent\": SGDClassifier(loss='log_loss', random_state=42),\n",
    "    \"ADA Boost\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='Logloss')\n",
    "}\n",
    "\n",
    "model_dl = {\n",
    "    \"DNN\": Sequential([\n",
    "        Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"CNN\": Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"RNN\": Sequential([\n",
    "        LSTM(100, input_shape=(X_train.shape[1], 1)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Pastikan X_train dan X_test memiliki bentuk yang sesuai untuk DL\n",
    "X_train_dl = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_dl = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Mengevaluasi model ML tanpa XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=False)\n",
    "\n",
    "# Mengevaluasi model DL tanpa XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=False, is_dl_model=True)\n",
    "\n",
    "# Mengevaluasi model ML dengan XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=True)\n",
    "\n",
    "# Mengevaluasi model DL dengan XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=True, is_dl_model=True)\n",
    "\n",
    "# Print hasil evaluasi tanpa XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL tanpa XAI:\")\n",
    "print(hasil_ml_dl)\n",
    "\n",
    "# Print hasil evaluasi dengan XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL dengan XAI:\")\n",
    "print(hasil_ml_dl_xai)\n",
    "\n",
    "# Convert results to DataFrame and save to CSV\n",
    "df_ml_dl = pd.DataFrame(hasil_ml_dl, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\"])\n",
    "df_ml_dl_xai = pd.DataFrame(hasil_ml_dl_xai, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\", \"XAI\"])\n",
    "\n",
    "df_ml_dl.to_csv(\"hasil_evaluasi_ml_dl_ETFC.csv\", index=False)\n",
    "df_ml_dl_xai.to_csv(\"hasil_evaluasi_ml_dl_xai_ETFC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f093213-2c6f-464b-b29d-7ad52a0207d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
