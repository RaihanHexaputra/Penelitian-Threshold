{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed025ff4-309c-4926-b5c9-725682279014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396f8840-3416-48cb-8a12-68b2d5855736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dataset \n",
    "\n",
    "DM = pd.read_csv(\"C:\\\\Data Raihan\\\\Penelitian Threshold\\\\Dataset\\\\CIC-PDFMal2022\\\\PDFMalware2022.csv\") #DM--> Dataset Malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff30b1d6-f75b-4dc9-8f3c-a9544371a50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10026 entries, 0 to 10025\n",
      "Data columns (total 33 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Fine name         10026 non-null  object \n",
      " 1   pdfsize           10025 non-null  float64\n",
      " 2   metadata size     10025 non-null  float64\n",
      " 3   pages             10025 non-null  float64\n",
      " 4   xref Length       10025 non-null  float64\n",
      " 5   title characters  10025 non-null  float64\n",
      " 6   isEncrypted       10025 non-null  float64\n",
      " 7   embedded files    10025 non-null  float64\n",
      " 8   images            10025 non-null  object \n",
      " 9   text              10025 non-null  object \n",
      " 10  header            10025 non-null  object \n",
      " 11  obj               10023 non-null  object \n",
      " 12  endobj            10023 non-null  object \n",
      " 13  stream            10023 non-null  float64\n",
      " 14  endstream         10023 non-null  object \n",
      " 15  xref              10023 non-null  object \n",
      " 16  trailer           10023 non-null  float64\n",
      " 17  startxref         10023 non-null  object \n",
      " 18  pageno            10023 non-null  object \n",
      " 19  encrypt           10023 non-null  float64\n",
      " 20  ObjStm            10023 non-null  float64\n",
      " 21  JS                10023 non-null  object \n",
      " 22  Javascript        10023 non-null  object \n",
      " 23  AA                10023 non-null  object \n",
      " 24  OpenAction        10023 non-null  object \n",
      " 25  Acroform          10023 non-null  object \n",
      " 26  JBIG2Decode       10023 non-null  object \n",
      " 27  RichMedia         10023 non-null  object \n",
      " 28  launch            10023 non-null  object \n",
      " 29  EmbeddedFile      10023 non-null  object \n",
      " 30  XFA               10023 non-null  object \n",
      " 31  Colors            10023 non-null  float64\n",
      " 32  Class             10025 non-null  object \n",
      "dtypes: float64(12), object(21)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "DM.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a229129-c47a-40d1-a7e0-7a55bbecb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "features = DM.drop(['Fine name','images','text','header','obj','endobj','endstream','xref','startxref','pageno','JS','Javascript','AA','OpenAction','Acroform','JBIG2Decode','RichMedia','launch','EmbeddedFile','XFA','Class'],axis=1).columns.tolist()\n",
    "# Target variable\n",
    "y = DM['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5196a377-052f-4bea-8c43-2d6a7ba1a9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Temp\\ipykernel_22376\\1069642451.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_data = DM.groupby('Class').apply(lambda x: x.sample(frac=1)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Memilih 100% data secara acak dari setiap fitur/column\n",
    "sampled_data = DM.groupby('Class').apply(lambda x: x.sample(frac=1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77acb697-6d53-4375-a397-e4863feb4437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 pdfsize                                  10025           float64\n",
      "  2 metadata size                            10025           float64\n",
      "  3 pages                                    10025           float64\n",
      "  4 xref Length                              10025           float64\n",
      "  5 title characters                         10025           float64\n",
      "  6 isEncrypted                              10025           float64\n",
      "  7 embedded files                           10025           float64\n",
      "  8 stream                                   10023           float64\n",
      "  9 trailer                                  10023           float64\n",
      " 10 encrypt                                  10023           float64\n",
      " 11 ObjStm                                   10023           float64\n",
      " 12 Colors                                   10023           float64\n"
     ]
    }
   ],
   "source": [
    "for i, column_name in enumerate(features):\n",
    "    print(f\"{i+1:3} {column_name:40} {sampled_data[column_name].count():<15} {sampled_data[column_name].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4f40f0-48d9-4eb6-92b5-43fd4058ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan data menjadi fitur (X) dan target (y)\n",
    "X = sampled_data[features]\n",
    "y = sampled_data['Class']\n",
    "\n",
    "# Split data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd7f2e2b-af28-4d50-b164-6bd6d29cbbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat imputer untuk menggantikan NaN dengan rata-rata\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Menangani missing values pada X_train dan X_test\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f15a5dc-5a3e-4068-a8ce-e83e67236ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels in y_test are present in y_train.\n"
     ]
    }
   ],
   "source": [
    "# Gabungkan semua label\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Inisialisasi LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit encoder pada gabungan label\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Transform data\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Cek label yang ada di y_train dan y_test\n",
    "train_labels = set(label_encoder.classes_)\n",
    "test_labels = set(y_test)\n",
    "\n",
    "# Menampilkan label yang tidak ada di y_train\n",
    "missing_labels = test_labels - train_labels\n",
    "if missing_labels:\n",
    "    print(f\"Labels in y_test that are not in y_train: {missing_labels}\")\n",
    "else:\n",
    "    print(\"All labels in y_test are present in y_train.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c079f7e-171c-4523-ac80-73e13cd0d9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3917, number of negative: 3100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1171\n",
      "[LightGBM] [Info] Number of data points in the train set: 7017, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558216 -> initscore=0.233924\n",
      "[LightGBM] [Info] Start training from score 0.233924\n",
      "0:\tlearn: 0.6212770\ttotal: 136ms\tremaining: 13.4s\n",
      "1:\tlearn: 0.5612924\ttotal: 138ms\tremaining: 6.74s\n",
      "2:\tlearn: 0.5106660\ttotal: 139ms\tremaining: 4.5s\n",
      "3:\tlearn: 0.4645847\ttotal: 141ms\tremaining: 3.38s\n",
      "4:\tlearn: 0.4262830\ttotal: 143ms\tremaining: 2.71s\n",
      "5:\tlearn: 0.3935985\ttotal: 145ms\tremaining: 2.27s\n",
      "6:\tlearn: 0.3662782\ttotal: 147ms\tremaining: 1.95s\n",
      "7:\tlearn: 0.3411721\ttotal: 149ms\tremaining: 1.71s\n",
      "8:\tlearn: 0.3185328\ttotal: 150ms\tremaining: 1.52s\n",
      "9:\tlearn: 0.2988376\ttotal: 152ms\tremaining: 1.37s\n",
      "10:\tlearn: 0.2800841\ttotal: 154ms\tremaining: 1.24s\n",
      "11:\tlearn: 0.2644325\ttotal: 155ms\tremaining: 1.14s\n",
      "12:\tlearn: 0.2486767\ttotal: 157ms\tremaining: 1.05s\n",
      "13:\tlearn: 0.2349105\ttotal: 159ms\tremaining: 976ms\n",
      "14:\tlearn: 0.2233187\ttotal: 161ms\tremaining: 910ms\n",
      "15:\tlearn: 0.2124956\ttotal: 162ms\tremaining: 853ms\n",
      "16:\tlearn: 0.2024412\ttotal: 164ms\tremaining: 802ms\n",
      "17:\tlearn: 0.1936623\ttotal: 166ms\tremaining: 756ms\n",
      "18:\tlearn: 0.1852011\ttotal: 168ms\tremaining: 714ms\n",
      "19:\tlearn: 0.1783514\ttotal: 169ms\tremaining: 677ms\n",
      "20:\tlearn: 0.1713315\ttotal: 171ms\tremaining: 643ms\n",
      "21:\tlearn: 0.1655678\ttotal: 173ms\tremaining: 613ms\n",
      "22:\tlearn: 0.1600412\ttotal: 175ms\tremaining: 585ms\n",
      "23:\tlearn: 0.1542430\ttotal: 177ms\tremaining: 560ms\n",
      "24:\tlearn: 0.1497968\ttotal: 179ms\tremaining: 536ms\n",
      "25:\tlearn: 0.1460680\ttotal: 180ms\tremaining: 514ms\n",
      "26:\tlearn: 0.1421249\ttotal: 182ms\tremaining: 493ms\n",
      "27:\tlearn: 0.1390866\ttotal: 184ms\tremaining: 473ms\n",
      "28:\tlearn: 0.1357272\ttotal: 185ms\tremaining: 454ms\n",
      "29:\tlearn: 0.1323576\ttotal: 187ms\tremaining: 437ms\n",
      "30:\tlearn: 0.1288437\ttotal: 189ms\tremaining: 421ms\n",
      "31:\tlearn: 0.1255814\ttotal: 191ms\tremaining: 406ms\n",
      "32:\tlearn: 0.1232134\ttotal: 193ms\tremaining: 392ms\n",
      "33:\tlearn: 0.1208877\ttotal: 195ms\tremaining: 378ms\n",
      "34:\tlearn: 0.1187461\ttotal: 197ms\tremaining: 365ms\n",
      "35:\tlearn: 0.1169131\ttotal: 198ms\tremaining: 352ms\n",
      "36:\tlearn: 0.1142990\ttotal: 200ms\tremaining: 341ms\n",
      "37:\tlearn: 0.1125366\ttotal: 202ms\tremaining: 329ms\n",
      "38:\tlearn: 0.1109192\ttotal: 204ms\tremaining: 318ms\n",
      "39:\tlearn: 0.1095134\ttotal: 206ms\tremaining: 308ms\n",
      "40:\tlearn: 0.1074478\ttotal: 207ms\tremaining: 298ms\n",
      "41:\tlearn: 0.1058967\ttotal: 209ms\tremaining: 289ms\n",
      "42:\tlearn: 0.1043374\ttotal: 211ms\tremaining: 280ms\n",
      "43:\tlearn: 0.1030343\ttotal: 213ms\tremaining: 271ms\n",
      "44:\tlearn: 0.1017229\ttotal: 214ms\tremaining: 262ms\n",
      "45:\tlearn: 0.1003822\ttotal: 216ms\tremaining: 254ms\n",
      "46:\tlearn: 0.0989135\ttotal: 218ms\tremaining: 246ms\n",
      "47:\tlearn: 0.0980383\ttotal: 220ms\tremaining: 238ms\n",
      "48:\tlearn: 0.0972800\ttotal: 221ms\tremaining: 230ms\n",
      "49:\tlearn: 0.0961545\ttotal: 223ms\tremaining: 223ms\n",
      "50:\tlearn: 0.0956390\ttotal: 225ms\tremaining: 216ms\n",
      "51:\tlearn: 0.0945261\ttotal: 227ms\tremaining: 209ms\n",
      "52:\tlearn: 0.0936429\ttotal: 228ms\tremaining: 202ms\n",
      "53:\tlearn: 0.0924067\ttotal: 230ms\tremaining: 196ms\n",
      "54:\tlearn: 0.0913361\ttotal: 232ms\tremaining: 190ms\n",
      "55:\tlearn: 0.0899976\ttotal: 234ms\tremaining: 183ms\n",
      "56:\tlearn: 0.0889269\ttotal: 236ms\tremaining: 178ms\n",
      "57:\tlearn: 0.0886185\ttotal: 238ms\tremaining: 172ms\n",
      "58:\tlearn: 0.0878752\ttotal: 239ms\tremaining: 166ms\n",
      "59:\tlearn: 0.0871726\ttotal: 241ms\tremaining: 161ms\n",
      "60:\tlearn: 0.0869043\ttotal: 243ms\tremaining: 155ms\n",
      "61:\tlearn: 0.0862259\ttotal: 245ms\tremaining: 150ms\n",
      "62:\tlearn: 0.0853260\ttotal: 246ms\tremaining: 145ms\n",
      "63:\tlearn: 0.0842809\ttotal: 248ms\tremaining: 139ms\n",
      "64:\tlearn: 0.0840312\ttotal: 250ms\tremaining: 134ms\n",
      "65:\tlearn: 0.0833822\ttotal: 251ms\tremaining: 130ms\n",
      "66:\tlearn: 0.0830208\ttotal: 253ms\tremaining: 125ms\n",
      "67:\tlearn: 0.0821821\ttotal: 255ms\tremaining: 120ms\n",
      "68:\tlearn: 0.0811557\ttotal: 257ms\tremaining: 115ms\n",
      "69:\tlearn: 0.0803812\ttotal: 258ms\tremaining: 111ms\n",
      "70:\tlearn: 0.0798942\ttotal: 260ms\tremaining: 106ms\n",
      "71:\tlearn: 0.0796303\ttotal: 262ms\tremaining: 102ms\n",
      "72:\tlearn: 0.0790100\ttotal: 264ms\tremaining: 97.6ms\n",
      "73:\tlearn: 0.0784120\ttotal: 266ms\tremaining: 93.4ms\n",
      "74:\tlearn: 0.0778773\ttotal: 268ms\tremaining: 89.2ms\n",
      "75:\tlearn: 0.0777436\ttotal: 269ms\tremaining: 85ms\n",
      "76:\tlearn: 0.0775585\ttotal: 271ms\tremaining: 81ms\n",
      "77:\tlearn: 0.0774322\ttotal: 273ms\tremaining: 76.9ms\n",
      "78:\tlearn: 0.0768357\ttotal: 274ms\tremaining: 72.9ms\n",
      "79:\tlearn: 0.0763762\ttotal: 276ms\tremaining: 69ms\n",
      "80:\tlearn: 0.0762525\ttotal: 278ms\tremaining: 65.1ms\n",
      "81:\tlearn: 0.0757898\ttotal: 279ms\tremaining: 61.3ms\n",
      "82:\tlearn: 0.0754846\ttotal: 281ms\tremaining: 57.6ms\n",
      "83:\tlearn: 0.0753047\ttotal: 283ms\tremaining: 53.9ms\n",
      "84:\tlearn: 0.0748942\ttotal: 285ms\tremaining: 50.2ms\n",
      "85:\tlearn: 0.0745671\ttotal: 286ms\tremaining: 46.6ms\n",
      "86:\tlearn: 0.0738802\ttotal: 288ms\tremaining: 43ms\n",
      "87:\tlearn: 0.0731618\ttotal: 290ms\tremaining: 39.5ms\n",
      "88:\tlearn: 0.0729748\ttotal: 292ms\tremaining: 36ms\n",
      "89:\tlearn: 0.0728700\ttotal: 294ms\tremaining: 32.6ms\n",
      "90:\tlearn: 0.0724108\ttotal: 295ms\tremaining: 29.2ms\n",
      "91:\tlearn: 0.0718406\ttotal: 297ms\tremaining: 25.8ms\n",
      "92:\tlearn: 0.0714921\ttotal: 299ms\tremaining: 22.5ms\n",
      "93:\tlearn: 0.0706544\ttotal: 301ms\tremaining: 19.2ms\n",
      "94:\tlearn: 0.0703370\ttotal: 302ms\tremaining: 15.9ms\n",
      "95:\tlearn: 0.0702094\ttotal: 304ms\tremaining: 12.7ms\n",
      "96:\tlearn: 0.0700404\ttotal: 306ms\tremaining: 9.46ms\n",
      "97:\tlearn: 0.0697738\ttotal: 308ms\tremaining: 6.28ms\n",
      "98:\tlearn: 0.0694345\ttotal: 309ms\tremaining: 3.13ms\n",
      "99:\tlearn: 0.0693438\ttotal: 311ms\tremaining: 0us\n",
      "94/94 [==============================] - 0s 643us/step\n",
      "94/94 [==============================] - 0s 684us/step\n",
      "94/94 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 3009it [00:36, 70.45it/s]                                                              \n",
      "PermutationExplainer explainer: 3009it [09:06,  5.39it/s]                                                              \n",
      "PermutationExplainer explainer: 3009it [00:35, 61.94it/s]                                                              \n",
      "PermutationExplainer explainer: 3009it [00:43, 53.50it/s]                                                              \n",
      "PermutationExplainer explainer: 3009it [00:33, 62.58it/s]                                                              \n",
      "PermutationExplainer explainer: 3009it [00:32, 63.75it/s]                                                              \n",
      "PermutationExplainer explainer: 3009it [45:23,  1.10it/s]                                                              \n",
      "PermutationExplainer explainer: 3009it [07:38,  6.43it/s]                                                              \n",
      "PermutationExplainer explainer: 3009it [1:01:27,  1.23s/it]                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3917, number of negative: 3100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.508404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1171\n",
      "[LightGBM] [Info] Number of data points in the train set: 7017, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558216 -> initscore=0.233924\n",
      "[LightGBM] [Info] Start training from score 0.233924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 3009it [15:24,  3.24it/s]                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6212770\ttotal: 5.63ms\tremaining: 558ms\n",
      "1:\tlearn: 0.5612924\ttotal: 9.57ms\tremaining: 469ms\n",
      "2:\tlearn: 0.5106660\ttotal: 13.6ms\tremaining: 440ms\n",
      "3:\tlearn: 0.4645847\ttotal: 21.7ms\tremaining: 520ms\n",
      "4:\tlearn: 0.4262830\ttotal: 23.7ms\tremaining: 451ms\n",
      "5:\tlearn: 0.3935985\ttotal: 27.9ms\tremaining: 437ms\n",
      "6:\tlearn: 0.3662782\ttotal: 31.9ms\tremaining: 424ms\n",
      "7:\tlearn: 0.3411721\ttotal: 37ms\tremaining: 425ms\n",
      "8:\tlearn: 0.3185328\ttotal: 39ms\tremaining: 394ms\n",
      "9:\tlearn: 0.2988376\ttotal: 42.9ms\tremaining: 386ms\n",
      "10:\tlearn: 0.2800841\ttotal: 49.6ms\tremaining: 401ms\n",
      "11:\tlearn: 0.2644325\ttotal: 64ms\tremaining: 469ms\n",
      "12:\tlearn: 0.2486767\ttotal: 74.9ms\tremaining: 501ms\n",
      "13:\tlearn: 0.2349105\ttotal: 79.2ms\tremaining: 487ms\n",
      "14:\tlearn: 0.2233187\ttotal: 81.4ms\tremaining: 461ms\n",
      "15:\tlearn: 0.2124956\ttotal: 84.8ms\tremaining: 445ms\n",
      "16:\tlearn: 0.2024412\ttotal: 88ms\tremaining: 429ms\n",
      "17:\tlearn: 0.1936623\ttotal: 90ms\tremaining: 410ms\n",
      "18:\tlearn: 0.1852011\ttotal: 92.4ms\tremaining: 394ms\n",
      "19:\tlearn: 0.1783514\ttotal: 95.4ms\tremaining: 382ms\n",
      "20:\tlearn: 0.1713315\ttotal: 97.4ms\tremaining: 367ms\n",
      "21:\tlearn: 0.1655678\ttotal: 100ms\tremaining: 356ms\n",
      "22:\tlearn: 0.1600412\ttotal: 102ms\tremaining: 343ms\n",
      "23:\tlearn: 0.1542430\ttotal: 105ms\tremaining: 333ms\n",
      "24:\tlearn: 0.1497968\ttotal: 107ms\tremaining: 322ms\n",
      "25:\tlearn: 0.1460680\ttotal: 110ms\tremaining: 312ms\n",
      "26:\tlearn: 0.1421249\ttotal: 113ms\tremaining: 305ms\n",
      "27:\tlearn: 0.1390866\ttotal: 115ms\tremaining: 295ms\n",
      "28:\tlearn: 0.1357272\ttotal: 118ms\tremaining: 288ms\n",
      "29:\tlearn: 0.1323576\ttotal: 120ms\tremaining: 280ms\n",
      "30:\tlearn: 0.1288437\ttotal: 122ms\tremaining: 273ms\n",
      "31:\tlearn: 0.1255814\ttotal: 125ms\tremaining: 266ms\n",
      "32:\tlearn: 0.1232134\ttotal: 129ms\tremaining: 261ms\n",
      "33:\tlearn: 0.1208877\ttotal: 132ms\tremaining: 256ms\n",
      "34:\tlearn: 0.1187461\ttotal: 134ms\tremaining: 249ms\n",
      "35:\tlearn: 0.1169131\ttotal: 137ms\tremaining: 244ms\n",
      "36:\tlearn: 0.1142990\ttotal: 139ms\tremaining: 237ms\n",
      "37:\tlearn: 0.1125366\ttotal: 141ms\tremaining: 231ms\n",
      "38:\tlearn: 0.1109192\ttotal: 144ms\tremaining: 225ms\n",
      "39:\tlearn: 0.1095134\ttotal: 146ms\tremaining: 219ms\n",
      "40:\tlearn: 0.1074478\ttotal: 149ms\tremaining: 214ms\n",
      "41:\tlearn: 0.1058967\ttotal: 152ms\tremaining: 210ms\n",
      "42:\tlearn: 0.1043374\ttotal: 154ms\tremaining: 204ms\n",
      "43:\tlearn: 0.1030343\ttotal: 157ms\tremaining: 200ms\n",
      "44:\tlearn: 0.1017229\ttotal: 160ms\tremaining: 195ms\n",
      "45:\tlearn: 0.1003822\ttotal: 163ms\tremaining: 191ms\n",
      "46:\tlearn: 0.0989135\ttotal: 166ms\tremaining: 187ms\n",
      "47:\tlearn: 0.0980383\ttotal: 168ms\tremaining: 182ms\n",
      "48:\tlearn: 0.0972800\ttotal: 171ms\tremaining: 178ms\n",
      "49:\tlearn: 0.0961545\ttotal: 174ms\tremaining: 174ms\n",
      "50:\tlearn: 0.0956390\ttotal: 176ms\tremaining: 170ms\n",
      "51:\tlearn: 0.0945261\ttotal: 179ms\tremaining: 166ms\n",
      "52:\tlearn: 0.0936429\ttotal: 182ms\tremaining: 161ms\n",
      "53:\tlearn: 0.0924067\ttotal: 185ms\tremaining: 157ms\n",
      "54:\tlearn: 0.0913361\ttotal: 187ms\tremaining: 153ms\n",
      "55:\tlearn: 0.0899976\ttotal: 190ms\tremaining: 149ms\n",
      "56:\tlearn: 0.0889269\ttotal: 196ms\tremaining: 148ms\n",
      "57:\tlearn: 0.0886185\ttotal: 200ms\tremaining: 145ms\n",
      "58:\tlearn: 0.0878752\ttotal: 212ms\tremaining: 147ms\n",
      "59:\tlearn: 0.0871726\ttotal: 225ms\tremaining: 150ms\n",
      "60:\tlearn: 0.0869043\ttotal: 254ms\tremaining: 162ms\n",
      "61:\tlearn: 0.0862259\ttotal: 276ms\tremaining: 169ms\n",
      "62:\tlearn: 0.0853260\ttotal: 288ms\tremaining: 169ms\n",
      "63:\tlearn: 0.0842809\ttotal: 293ms\tremaining: 165ms\n",
      "64:\tlearn: 0.0840312\ttotal: 295ms\tremaining: 159ms\n",
      "65:\tlearn: 0.0833822\ttotal: 298ms\tremaining: 154ms\n",
      "66:\tlearn: 0.0830208\ttotal: 304ms\tremaining: 150ms\n",
      "67:\tlearn: 0.0821821\ttotal: 307ms\tremaining: 144ms\n",
      "68:\tlearn: 0.0811557\ttotal: 311ms\tremaining: 140ms\n",
      "69:\tlearn: 0.0803812\ttotal: 315ms\tremaining: 135ms\n",
      "70:\tlearn: 0.0798942\ttotal: 319ms\tremaining: 130ms\n",
      "71:\tlearn: 0.0796303\ttotal: 323ms\tremaining: 126ms\n",
      "72:\tlearn: 0.0790100\ttotal: 327ms\tremaining: 121ms\n",
      "73:\tlearn: 0.0784120\ttotal: 332ms\tremaining: 117ms\n",
      "74:\tlearn: 0.0778773\ttotal: 335ms\tremaining: 112ms\n",
      "75:\tlearn: 0.0777436\ttotal: 338ms\tremaining: 107ms\n",
      "76:\tlearn: 0.0775585\ttotal: 341ms\tremaining: 102ms\n",
      "77:\tlearn: 0.0774322\ttotal: 344ms\tremaining: 97.1ms\n",
      "78:\tlearn: 0.0768357\ttotal: 348ms\tremaining: 92.6ms\n",
      "79:\tlearn: 0.0763762\ttotal: 352ms\tremaining: 88.1ms\n",
      "80:\tlearn: 0.0762525\ttotal: 355ms\tremaining: 83.3ms\n",
      "81:\tlearn: 0.0757898\ttotal: 359ms\tremaining: 78.8ms\n",
      "82:\tlearn: 0.0754846\ttotal: 364ms\tremaining: 74.6ms\n",
      "83:\tlearn: 0.0753047\ttotal: 372ms\tremaining: 70.8ms\n",
      "84:\tlearn: 0.0748942\ttotal: 378ms\tremaining: 66.6ms\n",
      "85:\tlearn: 0.0745671\ttotal: 381ms\tremaining: 62ms\n",
      "86:\tlearn: 0.0738802\ttotal: 385ms\tremaining: 57.5ms\n",
      "87:\tlearn: 0.0731618\ttotal: 392ms\tremaining: 53.4ms\n",
      "88:\tlearn: 0.0729748\ttotal: 396ms\tremaining: 49ms\n",
      "89:\tlearn: 0.0728700\ttotal: 401ms\tremaining: 44.5ms\n",
      "90:\tlearn: 0.0724108\ttotal: 405ms\tremaining: 40.1ms\n",
      "91:\tlearn: 0.0718406\ttotal: 410ms\tremaining: 35.6ms\n",
      "92:\tlearn: 0.0714921\ttotal: 413ms\tremaining: 31.1ms\n",
      "93:\tlearn: 0.0706544\ttotal: 415ms\tremaining: 26.5ms\n",
      "94:\tlearn: 0.0703370\ttotal: 417ms\tremaining: 22ms\n",
      "95:\tlearn: 0.0702094\ttotal: 420ms\tremaining: 17.5ms\n",
      "96:\tlearn: 0.0700404\ttotal: 422ms\tremaining: 13ms\n",
      "97:\tlearn: 0.0697738\ttotal: 425ms\tremaining: 8.67ms\n",
      "98:\tlearn: 0.0694345\ttotal: 430ms\tremaining: 4.34ms\n",
      "99:\tlearn: 0.0693438\ttotal: 439ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 3009it [07:11,  6.84it/s]                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 726us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 797us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using SHAP with CNN: operands could not be broadcast together with shapes (7017,12,1) (7017,12) \n",
      "94/94 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using SHAP with RNN: in user code:\n",
      "\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 244, in grad_graph  *\n",
      "        out = self.model(shap_rAnD)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 371, in custom_grad\n",
      "        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefix before the lookup\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 663, in handler\n",
      "        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 670, in linearity_with_excluded_handler\n",
      "        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 222, in _variable_inputs\n",
      "        out[i] = t.name in self.between_tensors\n",
      "\n",
      "    AttributeError: Exception encountered when calling layer 'lstm' (type LSTM).\n",
      "    \n",
      "    'TFDeep' object has no attribute 'between_tensors'\n",
      "    \n",
      "    Call arguments received by layer 'lstm' (type LSTM):\n",
      "      • inputs=tf.Tensor(shape=(14034, 12, 1), dtype=float32)\n",
      "      • mask=None\n",
      "      • training=False\n",
      "      • initial_state=None\n",
      "\n",
      "\n",
      "Hasil Evaluasi ML/DL tanpa XAI:\n",
      "[['DecisionTree', 0.9761175750153093, 0.9719512195121951, 0.9740299419492819, 0.9717420212765957, 0.026174068450927734], ['RandomForest', 0.9800362976406534, 0.9878048780487805, 0.9839052535681749, 0.9823803191489362, 0.33972692489624023], ['Logistic Regression', 0.79833246482543, 0.9341463414634147, 0.8609159876369769, 0.835438829787234, 1.0150575637817383], ['Naive Bayes', 0.861271676300578, 0.09085365853658536, 0.1643684500827358, 0.496343085106383, 0.0030066967010498047], ['MLP', 0.5452127659574468, 1.0, 0.7056798623063684, 0.5452127659574468, 0.7719042301177979], ['Stochastic Gradient Descent', 0.5826914363389216, 0.7841463414634147, 0.6685729139589291, 0.5761303191489362, 0.020679712295532227], ['ADA Boost', 0.9629404617253949, 0.9664634146341463, 0.9646987218502739, 0.961436170212766, 0.5951333045959473], ['Gradient Boosting', 0.9726775956284153, 0.9768292682926829, 0.9747490112564648, 0.972406914893617, 0.790236234664917], ['XGBoost', 0.9836759371221282, 0.9920731707317073, 0.9878567091681845, 0.9867021276595744, 1.3904623985290527], ['LightGBM', 0.9860267314702309, 0.9896341463414634, 0.9878271454656117, 0.9867021276595744, 0.2321169376373291], ['CatBoost', 0.9686369119420989, 0.9792682926829268, 0.9739235900545785, 0.9714095744680851, 0.368175745010376], ['DNN', 0.7915376676986584, 0.9353658536585366, 0.8574622694242594, 0.8304521276595744, 1.8032691478729248], ['CNN', 0.820230607966457, 0.9542682926829268, 0.8821871476888388, 0.8610372340425532, 1.9193365573883057], ['RNN', 0.9300947867298578, 0.9573170731707317, 0.9435096153846153, 0.9375, 8.671617031097412]]\n",
      "\n",
      "Hasil Evaluasi ML/DL dengan XAI:\n",
      "[['DecisionTree', 0.9743276283618582, 0.9719512195121951, 0.9731379731379731, 0.9707446808510638, 0.02047586441040039, {'SHAP': array([[-0.00651147,  0.00651147],\n",
      "       [-0.00281567,  0.00281567],\n",
      "       [-0.00343859,  0.00343859],\n",
      "       [ 0.00252186, -0.00252186],\n",
      "       [-0.0010059 ,  0.0010059 ],\n",
      "       [ 0.00026001, -0.00026001],\n",
      "       [ 0.00341217, -0.00341217],\n",
      "       [ 0.00451009, -0.00451009],\n",
      "       [ 0.0039057 , -0.0039057 ],\n",
      "       [ 0.        ,  0.        ],\n",
      "       [ 0.0004227 , -0.0004227 ],\n",
      "       [-0.00299923,  0.00299923]])}], ['RandomForest', 0.9764776839565742, 0.9871951219512195, 0.9818071558520315, 0.9800531914893617, 0.3370511531829834, {'SHAP': array([[ 0.00233318, -0.00233318],\n",
      "       [-0.00753   ,  0.00753   ],\n",
      "       [-0.00506785,  0.00506785],\n",
      "       [ 0.01162171, -0.01162171],\n",
      "       [ 0.00158114, -0.00158114],\n",
      "       [ 0.00020833, -0.00020833],\n",
      "       [ 0.00133779, -0.00133779],\n",
      "       [-0.00217426,  0.00217426],\n",
      "       [ 0.00463404, -0.00463404],\n",
      "       [-0.00020881,  0.00020881],\n",
      "       [ 0.0003692 , -0.0003692 ],\n",
      "       [-0.0017909 ,  0.0017909 ]])}], ['Logistic Regression', 0.79833246482543, 0.9341463414634147, 0.8609159876369769, 0.835438829787234, 1.0500428676605225, {'SHAP': array([[ 2.25567944e-04, -2.25567944e-04],\n",
      "       [ 2.03031081e-04, -2.03031081e-04],\n",
      "       [ 4.18535316e-04, -4.18535316e-04],\n",
      "       [-1.30962380e-03,  1.30962380e-03],\n",
      "       [-1.90041689e-04,  1.90041689e-04],\n",
      "       [-1.18509850e-02,  1.18509850e-02],\n",
      "       [ 1.82371035e-03, -1.82371035e-03],\n",
      "       [ 3.74226869e-02, -3.74226869e-02],\n",
      "       [-8.03642280e-03,  8.03642280e-03],\n",
      "       [ 4.31331573e-04, -4.31331573e-04],\n",
      "       [-3.50882292e-06,  3.50882292e-06],\n",
      "       [-3.22674430e-04,  3.22674430e-04]])}], ['Naive Bayes', 0.861271676300578, 0.09085365853658536, 0.1643684500827358, 0.496343085106383, 0.005118370056152344, {'SHAP': array([[ 4.62755676e-03, -4.62755676e-03],\n",
      "       [-5.19299361e-03,  5.19299361e-03],\n",
      "       [ 2.21098966e-03, -2.21098966e-03],\n",
      "       [-4.37524599e-03,  4.37524599e-03],\n",
      "       [-6.33630348e-03,  6.33630348e-03],\n",
      "       [ 9.94858481e-04, -9.94858481e-04],\n",
      "       [ 8.95593308e-03, -8.95593308e-03],\n",
      "       [-4.77827496e-05,  4.77827496e-05],\n",
      "       [-1.33404265e-03,  1.33404265e-03],\n",
      "       [-1.15522660e-04,  1.15522660e-04],\n",
      "       [ 2.78737949e-03, -2.78737949e-03],\n",
      "       [-4.53487727e-04,  4.53487727e-04]])}], ['MLP', 0.5452127659574468, 1.0, 0.7056798623063684, 0.5452127659574468, 0.8216907978057861, {'SHAP': array([[-8.27706058e-04,  8.27706058e-04],\n",
      "       [-1.99027346e-03,  1.99027346e-03],\n",
      "       [-1.83640548e-04,  1.83640548e-04],\n",
      "       [-1.30318115e-03,  1.30318115e-03],\n",
      "       [-8.95647483e-06,  8.95647483e-06],\n",
      "       [-8.60323706e-05,  8.60323706e-05],\n",
      "       [-4.41444854e-05,  4.41444854e-05],\n",
      "       [-2.33508197e-05,  2.33508197e-05],\n",
      "       [-6.89711196e-05,  6.89711196e-05],\n",
      "       [ 1.21636008e-05, -1.21636008e-05],\n",
      "       [-2.96996804e-05,  2.96996804e-05],\n",
      "       [-1.57899542e-04,  1.57899542e-04]])}], ['Stochastic Gradient Descent', 0.5826914363389216, 0.7841463414634147, 0.6685729139589291, 0.5761303191489362, 0.02213311195373535, {'SHAP': array([[-4.33352051e-03,  4.33352051e-03],\n",
      "       [ 1.70795194e-03, -1.70795194e-03],\n",
      "       [-1.73448819e-03,  1.73448819e-03],\n",
      "       [-2.44370641e-02,  2.44370641e-02],\n",
      "       [-6.45841413e-04,  6.45841413e-04],\n",
      "       [-1.95447428e-05,  1.95447428e-05],\n",
      "       [-1.89293478e-05,  1.89293478e-05],\n",
      "       [ 2.43492379e-02, -2.43492379e-02],\n",
      "       [ 3.22525625e-05, -3.22525625e-05],\n",
      "       [ 3.19967169e-06, -3.19967169e-06],\n",
      "       [ 1.20610100e-04, -1.20610100e-04],\n",
      "       [ 1.25462981e-03, -1.25462981e-03]])}], ['ADA Boost', 0.9629404617253949, 0.9664634146341463, 0.9646987218502739, 0.961436170212766, 0.642409086227417, {'SHAP': array([[ 4.20380409e-05, -4.20380409e-05],\n",
      "       [-4.79610303e-04,  4.79610303e-04],\n",
      "       [-1.89405424e-04,  1.89405424e-04],\n",
      "       [ 5.68538166e-04, -5.68538166e-04],\n",
      "       [-4.04826999e-04,  4.04826999e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 2.23139049e-05, -2.23139049e-05],\n",
      "       [ 8.95258103e-05, -8.95258103e-05],\n",
      "       [-9.39952519e-05,  9.39952519e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.25204352e-04, -1.25204352e-04],\n",
      "       [-1.16552631e-04,  1.16552631e-04]])}], ['Gradient Boosting', 0.9726775956284153, 0.9768292682926829, 0.9747490112564648, 0.972406914893617, 2.7091434001922607, {'SHAP': array([[ 9.38520168e-05, -9.38520168e-05],\n",
      "       [-9.78625417e-03,  9.78625417e-03],\n",
      "       [-4.31266905e-03,  4.31266905e-03],\n",
      "       [ 1.32210026e-02, -1.32210026e-02],\n",
      "       [-1.01344569e-03,  1.01344569e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.64721138e-03, -1.64721138e-03],\n",
      "       [-2.25112136e-03,  2.25112136e-03],\n",
      "       [ 5.09417874e-03, -5.09417874e-03],\n",
      "       [ 1.59333957e-05, -1.59333957e-05],\n",
      "       [ 8.38972445e-05, -8.38972445e-05],\n",
      "       [-2.17092568e-03,  2.17092568e-03]])}], ['XGBoost', 0.9836759371221282, 0.9920731707317073, 0.9878567091681845, 0.9867021276595744, 0.6915788650512695, {'SHAP': array([[ 0.00060565, -0.00060565],\n",
      "       [-0.00394284,  0.00394285],\n",
      "       [-0.00599852,  0.00599852],\n",
      "       [ 0.02046408, -0.02046408],\n",
      "       [ 0.00090735, -0.00090735],\n",
      "       [ 0.        ,  0.        ],\n",
      "       [ 0.00122486, -0.00122486],\n",
      "       [-0.00529672,  0.00529672],\n",
      "       [ 0.00306022, -0.00306022],\n",
      "       [ 0.        ,  0.        ],\n",
      "       [-0.00065127,  0.00065127],\n",
      "       [-0.00219742,  0.00219742]])}], ['LightGBM', 0.9860267314702309, 0.9896341463414634, 0.9878271454656117, 0.9867021276595744, 473.36230993270874, {'SHAP': array([[ 0.00288403, -0.00288403],\n",
      "       [-0.00920804,  0.00920804],\n",
      "       [-0.00533497,  0.00533497],\n",
      "       [ 0.02186693, -0.02186693],\n",
      "       [-0.0003845 ,  0.0003845 ],\n",
      "       [ 0.        ,  0.        ],\n",
      "       [ 0.00150926, -0.00150926],\n",
      "       [-0.00760709,  0.00760709],\n",
      "       [ 0.00771949, -0.00771949],\n",
      "       [ 0.        ,  0.        ],\n",
      "       [ 0.0007697 , -0.0007697 ],\n",
      "       [-0.00267405,  0.00267405]])}], ['CatBoost', 0.9686369119420989, 0.9792682926829268, 0.9739235900545785, 0.9714095744680851, 0.5011711120605469, {'SHAP': array([[-9.42242502e-05,  9.42242502e-05],\n",
      "       [-6.97830063e-03,  6.97830063e-03],\n",
      "       [-3.14262674e-03,  3.14262674e-03],\n",
      "       [ 1.11561090e-02, -1.11561090e-02],\n",
      "       [-4.44344292e-04,  4.44344292e-04],\n",
      "       [ 7.73039047e-05, -7.73039047e-05],\n",
      "       [ 1.74813007e-03, -1.74813007e-03],\n",
      "       [ 1.76695287e-03, -1.76695287e-03],\n",
      "       [ 1.91435632e-03, -1.91435632e-03],\n",
      "       [-6.43966632e-04,  6.43966632e-04],\n",
      "       [ 1.35778192e-04, -1.35778192e-04],\n",
      "       [-1.60295315e-03,  1.60295315e-03]])}], ['DNN', 0.7498822421102214, 0.9707317073170731, 0.8461334041987775, 0.8075132978723404, 1.8848655223846436, {'SHAP': array([-0.00677528])}], ['CNN', 0.8614357262103506, 0.9439024390243902, 0.9007855688100087, 0.8866356382978723, 2.260239601135254, {'SHAP': None}], ['RNN', 0.9415971394517283, 0.9634146341463414, 0.9523809523809524, 0.9474734042553191, 8.467994689941406, {'SHAP': None}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi variabel untuk menyimpan hasil evaluasi\n",
    "hasil_ml_dl = []\n",
    "hasil_ml_dl_xai = []\n",
    "\n",
    "# Encode labels ke bentuk numerik jika diperlukan\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Fungsi untuk mengevaluasi model ML/DL\n",
    "def EvaluateModel(model_name, model, X_train, y_train, X_test, y_test, use_xai=False, is_dl_model=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Melatih model\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0) if is_dl_model else model.fit(X_train, y_train)\n",
    "    \n",
    "    if is_dl_model:\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    elif hasattr(model, 'predict_proba'):\n",
    "        # Model dengan metode predict_proba\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        if y_pred_proba.shape[1] > 1:  # Model klasifikasi multi-kelas\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        else:  # Model klasifikasi biner\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    else:\n",
    "        # Model tanpa metode predict_proba\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "\n",
    "    # Menghitung confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Menghitung metrik\n",
    "    Precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    Recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    F1Score = 2 * ((Precision * Recall) / (Precision + Recall)) if (Precision + Recall) != 0 else 0\n",
    "    Accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) != 0 else 0\n",
    "\n",
    "    # Menghitung waktu running\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "    # Jika XAI diperlukan, tambahkan analisis dengan SHAP\n",
    "    if use_xai:\n",
    "        # Periksa apakah X_train adalah DataFrame\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            feature_names = X_train.columns\n",
    "        else:\n",
    "            feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "        \n",
    "        # Perbaiki format X_train untuk SHAP\n",
    "        if is_dl_model:\n",
    "            X_train_for_xai = X_train.reshape((X_train.shape[0], X_train.shape[1]))\n",
    "            X_test_for_xai = X_test.reshape((X_test.shape[0], X_test.shape[1]))\n",
    "        else:\n",
    "            X_train_for_xai = X_train\n",
    "            X_test_for_xai = X_test\n",
    "\n",
    "        # Gunakan SHAP\n",
    "        try:\n",
    "            if is_dl_model:\n",
    "                explainer = shap.DeepExplainer(model, X_train_for_xai)\n",
    "                shap_values = explainer.shap_values(X_test_for_xai)\n",
    "                shap_summary = np.mean(shap_values[0], axis=0)\n",
    "            else:\n",
    "                explainer = shap.Explainer(model.predict_proba, X_train_for_xai)\n",
    "                shap_values = explainer(X_test_for_xai)\n",
    "                shap_summary = shap_values.values.mean(axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error using SHAP with {model_name}: {e}\")\n",
    "            shap_summary = None\n",
    "\n",
    "        # Simpan hasil evaluasi dengan XAI\n",
    "        hasil_ml_dl_xai.append([model_name, Precision, Recall, F1Score, Accuracy, run_time, {'SHAP': shap_summary}])\n",
    "    else:\n",
    "        # Simpan hasil evaluasi tanpa XAI\n",
    "        hasil_ml_dl.append([model_name, Precision, Recall, F1Score, Accuracy, run_time])\n",
    "\n",
    "# Model ML dan DL yang akan dievaluasi\n",
    "model_ml_dl = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=10),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=50),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0, max_iter=10000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000),\n",
    "    \"Stochastic Gradient Descent\": SGDClassifier(loss='log_loss', random_state=42),\n",
    "    \"ADA Boost\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='Logloss')\n",
    "}\n",
    "\n",
    "model_dl = {\n",
    "    \"DNN\": Sequential([\n",
    "        Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"CNN\": Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"RNN\": Sequential([\n",
    "        LSTM(100, input_shape=(X_train.shape[1], 1)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Pastikan X_train dan X_test memiliki bentuk yang sesuai untuk DL\n",
    "X_train_dl = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_dl = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Mengevaluasi model ML tanpa XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=False)\n",
    "\n",
    "# Mengevaluasi model DL tanpa XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=False, is_dl_model=True)\n",
    "\n",
    "# Mengevaluasi model ML dengan XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=True)\n",
    "\n",
    "# Mengevaluasi model DL dengan XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=True, is_dl_model=True)\n",
    "\n",
    "# Print hasil evaluasi tanpa XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL tanpa XAI:\")\n",
    "print(hasil_ml_dl)\n",
    "\n",
    "# Print hasil evaluasi dengan XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL dengan XAI:\")\n",
    "print(hasil_ml_dl_xai)\n",
    "\n",
    "# Convert results to DataFrame and save to CSV\n",
    "df_ml_dl = pd.DataFrame(hasil_ml_dl, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\"])\n",
    "df_ml_dl_xai = pd.DataFrame(hasil_ml_dl_xai, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\", \"XAI\"])\n",
    "\n",
    "df_ml_dl.to_csv(\"hasil_evaluasi_ml_dl_BF.csv\", index=False)\n",
    "df_ml_dl_xai.to_csv(\"hasil_evaluasi_ml_dl_xai_BF.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
