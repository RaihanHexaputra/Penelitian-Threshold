{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674d68be-dee1-4910-a28e-f08a102316c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk pengolahan data dan visualisasi\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Library untuk evaluasi dan model machine learning\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import sklearn.ensemble as ek\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Library untuk Explainable AI (XAI)\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import shap\n",
    "\n",
    "# Library untuk Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103abc4c-1b2e-4ca0-82e5-0b66b34b6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dataset \n",
    "\n",
    "DM = pd.read_csv(\"C:\\\\Data Raihan\\\\Penelitian Threshold\\\\Dataset\\\\CIC-PDFMal2022\\\\PDFMalware2022.csv\") #DM--> Dataset Malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b14026-c76d-4c99-8f2a-723225d2df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10026 entries, 0 to 10025\n",
      "Data columns (total 33 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Fine name         10026 non-null  object \n",
      " 1   pdfsize           10025 non-null  float64\n",
      " 2   metadata size     10025 non-null  float64\n",
      " 3   pages             10025 non-null  float64\n",
      " 4   xref Length       10025 non-null  float64\n",
      " 5   title characters  10025 non-null  float64\n",
      " 6   isEncrypted       10025 non-null  float64\n",
      " 7   embedded files    10025 non-null  float64\n",
      " 8   images            10025 non-null  object \n",
      " 9   text              10025 non-null  object \n",
      " 10  header            10025 non-null  object \n",
      " 11  obj               10023 non-null  object \n",
      " 12  endobj            10023 non-null  object \n",
      " 13  stream            10023 non-null  float64\n",
      " 14  endstream         10023 non-null  object \n",
      " 15  xref              10023 non-null  object \n",
      " 16  trailer           10023 non-null  float64\n",
      " 17  startxref         10023 non-null  object \n",
      " 18  pageno            10023 non-null  object \n",
      " 19  encrypt           10023 non-null  float64\n",
      " 20  ObjStm            10023 non-null  float64\n",
      " 21  JS                10023 non-null  object \n",
      " 22  Javascript        10023 non-null  object \n",
      " 23  AA                10023 non-null  object \n",
      " 24  OpenAction        10023 non-null  object \n",
      " 25  Acroform          10023 non-null  object \n",
      " 26  JBIG2Decode       10023 non-null  object \n",
      " 27  RichMedia         10023 non-null  object \n",
      " 28  launch            10023 non-null  object \n",
      " 29  EmbeddedFile      10023 non-null  object \n",
      " 30  XFA               10023 non-null  object \n",
      " 31  Colors            10023 non-null  float64\n",
      " 32  Class             10025 non-null  object \n",
      "dtypes: float64(12), object(21)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "DM.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dcbc54b-758f-4b1f-999c-71e61b807d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "features_to_drop = ['Fine name', 'images', 'text', 'header', 'obj', 'endobj', 'endstream', \n",
    "                    'xref', 'startxref', 'pageno', 'JS', 'Javascript', 'AA', 'OpenAction', \n",
    "                    'Acroform', 'JBIG2Decode', 'RichMedia', 'launch', 'EmbeddedFile', 'XFA', 'Class']\n",
    "\n",
    "# Droping specified columns and target variable\n",
    "X = DM.drop(features_to_drop, axis=1).values    \n",
    "y = DM['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41bd6d6c-c0ef-470b-9c61-cf4044411438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Nan\n",
    "X = pd.DataFrame(X).dropna()\n",
    "y = y[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8f7589-ddf7-41a4-aaa7-436e367e5f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menerapkan Min-Max scaling untuk membuat X tidak negatif\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba75d9b8-e9cf-428b-bee5-0f0eb118955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Threshold (Filter)\n",
    "vt_selector = VarianceThreshold(threshold=0.001)  # Anda bisa menyesuaikan ambang batas\n",
    "X_vt = vt_selector.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa8ad04-c8ca-43d2-95fc-f272b05e0a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature xref Length terpilih dengan varians di atas threshold\n",
      "Feature isEncrypted terpilih dengan varians di atas threshold\n",
      "Feature embedded files terpilih dengan varians di atas threshold\n",
      "Feature stream terpilih dengan varians di atas threshold\n",
      "Feature encrypt terpilih dengan varians di atas threshold\n"
     ]
    }
   ],
   "source": [
    "# Mendapatkan indeks fitur yang terpilih\n",
    "vt_top_features = np.where(vt_selector.get_support())[0]\n",
    "\n",
    "# Mengambil nama kolom dari X yang sudah difilter\n",
    "filtered_columns = DM.drop(features_to_drop, axis=1).columns\n",
    "\n",
    "# Mengambil nama fitur terpilih\n",
    "features = []\n",
    "for idx in vt_top_features:\n",
    "    print(f\"Feature {filtered_columns[idx]} terpilih dengan varians di atas threshold\")\n",
    "    features.append(filtered_columns[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbdd0877-c2ba-4c27-a531-0e69ba6823e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Temp\\ipykernel_12756\\1069642451.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_data = DM.groupby('Class').apply(lambda x: x.sample(frac=1)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Memilih 100% data secara acak dari setiap fitur/column\n",
    "sampled_data = DM.groupby('Class').apply(lambda x: x.sample(frac=1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c19c643a-4213-435e-ab40-0d4f86031267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vt, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8b0fbaf-2f18-4e1b-a113-19d20e88df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels ke bentuk numerik jika diperlukan\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc61cbda-5dc7-409a-bc00-3a5341cd2dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3865, number of negative: 3151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 422\n",
      "[LightGBM] [Info] Number of data points in the train set: 7016, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550884 -> initscore=0.204242\n",
      "[LightGBM] [Info] Start training from score 0.204242\n",
      "0:\tlearn: 0.6353943\ttotal: 148ms\tremaining: 14.6s\n",
      "1:\tlearn: 0.5901188\ttotal: 149ms\tremaining: 7.32s\n",
      "2:\tlearn: 0.5478482\ttotal: 153ms\tremaining: 4.93s\n",
      "3:\tlearn: 0.5136306\ttotal: 155ms\tremaining: 3.73s\n",
      "4:\tlearn: 0.4860331\ttotal: 158ms\tremaining: 2.99s\n",
      "5:\tlearn: 0.4603531\ttotal: 160ms\tremaining: 2.5s\n",
      "6:\tlearn: 0.4392672\ttotal: 162ms\tremaining: 2.15s\n",
      "7:\tlearn: 0.4196621\ttotal: 164ms\tremaining: 1.88s\n",
      "8:\tlearn: 0.4008000\ttotal: 166ms\tremaining: 1.67s\n",
      "9:\tlearn: 0.3851888\ttotal: 167ms\tremaining: 1.51s\n",
      "10:\tlearn: 0.3724749\ttotal: 169ms\tremaining: 1.37s\n",
      "11:\tlearn: 0.3568197\ttotal: 172ms\tremaining: 1.26s\n",
      "12:\tlearn: 0.3417550\ttotal: 174ms\tremaining: 1.16s\n",
      "13:\tlearn: 0.3315141\ttotal: 176ms\tremaining: 1.08s\n",
      "14:\tlearn: 0.3186721\ttotal: 178ms\tremaining: 1.01s\n",
      "15:\tlearn: 0.3114373\ttotal: 180ms\tremaining: 944ms\n",
      "16:\tlearn: 0.3041058\ttotal: 182ms\tremaining: 888ms\n",
      "17:\tlearn: 0.2980165\ttotal: 184ms\tremaining: 838ms\n",
      "18:\tlearn: 0.2890200\ttotal: 186ms\tremaining: 793ms\n",
      "19:\tlearn: 0.2840458\ttotal: 188ms\tremaining: 753ms\n",
      "20:\tlearn: 0.2797251\ttotal: 190ms\tremaining: 715ms\n",
      "21:\tlearn: 0.2735361\ttotal: 192ms\tremaining: 681ms\n",
      "22:\tlearn: 0.2691002\ttotal: 194ms\tremaining: 649ms\n",
      "23:\tlearn: 0.2644316\ttotal: 196ms\tremaining: 621ms\n",
      "24:\tlearn: 0.2619269\ttotal: 198ms\tremaining: 594ms\n",
      "25:\tlearn: 0.2586062\ttotal: 200ms\tremaining: 569ms\n",
      "26:\tlearn: 0.2566122\ttotal: 202ms\tremaining: 546ms\n",
      "27:\tlearn: 0.2529136\ttotal: 204ms\tremaining: 524ms\n",
      "28:\tlearn: 0.2497365\ttotal: 206ms\tremaining: 504ms\n",
      "29:\tlearn: 0.2467193\ttotal: 208ms\tremaining: 485ms\n",
      "30:\tlearn: 0.2442787\ttotal: 210ms\tremaining: 468ms\n",
      "31:\tlearn: 0.2424973\ttotal: 213ms\tremaining: 453ms\n",
      "32:\tlearn: 0.2401940\ttotal: 216ms\tremaining: 438ms\n",
      "33:\tlearn: 0.2383951\ttotal: 218ms\tremaining: 423ms\n",
      "34:\tlearn: 0.2370410\ttotal: 220ms\tremaining: 409ms\n",
      "35:\tlearn: 0.2360192\ttotal: 222ms\tremaining: 395ms\n",
      "36:\tlearn: 0.2337688\ttotal: 224ms\tremaining: 381ms\n",
      "37:\tlearn: 0.2324773\ttotal: 226ms\tremaining: 368ms\n",
      "38:\tlearn: 0.2317474\ttotal: 228ms\tremaining: 357ms\n",
      "39:\tlearn: 0.2300905\ttotal: 230ms\tremaining: 346ms\n",
      "40:\tlearn: 0.2284777\ttotal: 233ms\tremaining: 335ms\n",
      "41:\tlearn: 0.2278026\ttotal: 236ms\tremaining: 326ms\n",
      "42:\tlearn: 0.2267316\ttotal: 238ms\tremaining: 316ms\n",
      "43:\tlearn: 0.2259917\ttotal: 241ms\tremaining: 306ms\n",
      "44:\tlearn: 0.2252336\ttotal: 243ms\tremaining: 297ms\n",
      "45:\tlearn: 0.2239174\ttotal: 246ms\tremaining: 289ms\n",
      "46:\tlearn: 0.2236347\ttotal: 249ms\tremaining: 280ms\n",
      "47:\tlearn: 0.2231099\ttotal: 252ms\tremaining: 273ms\n",
      "48:\tlearn: 0.2226520\ttotal: 255ms\tremaining: 265ms\n",
      "49:\tlearn: 0.2224887\ttotal: 256ms\tremaining: 256ms\n",
      "50:\tlearn: 0.2213479\ttotal: 259ms\tremaining: 249ms\n",
      "51:\tlearn: 0.2204791\ttotal: 261ms\tremaining: 241ms\n",
      "52:\tlearn: 0.2196832\ttotal: 263ms\tremaining: 234ms\n",
      "53:\tlearn: 0.2193089\ttotal: 266ms\tremaining: 226ms\n",
      "54:\tlearn: 0.2191588\ttotal: 268ms\tremaining: 219ms\n",
      "55:\tlearn: 0.2188146\ttotal: 270ms\tremaining: 212ms\n",
      "56:\tlearn: 0.2184435\ttotal: 273ms\tremaining: 206ms\n",
      "57:\tlearn: 0.2177817\ttotal: 275ms\tremaining: 199ms\n",
      "58:\tlearn: 0.2175176\ttotal: 277ms\tremaining: 192ms\n",
      "59:\tlearn: 0.2173402\ttotal: 279ms\tremaining: 186ms\n",
      "60:\tlearn: 0.2164811\ttotal: 282ms\tremaining: 180ms\n",
      "61:\tlearn: 0.2159342\ttotal: 284ms\tremaining: 174ms\n",
      "62:\tlearn: 0.2154854\ttotal: 287ms\tremaining: 168ms\n",
      "63:\tlearn: 0.2150157\ttotal: 289ms\tremaining: 163ms\n",
      "64:\tlearn: 0.2145972\ttotal: 291ms\tremaining: 157ms\n",
      "65:\tlearn: 0.2145149\ttotal: 293ms\tremaining: 151ms\n",
      "66:\tlearn: 0.2141162\ttotal: 296ms\tremaining: 146ms\n",
      "67:\tlearn: 0.2139198\ttotal: 299ms\tremaining: 141ms\n",
      "68:\tlearn: 0.2130691\ttotal: 302ms\tremaining: 135ms\n",
      "69:\tlearn: 0.2128962\ttotal: 304ms\tremaining: 130ms\n",
      "70:\tlearn: 0.2123232\ttotal: 306ms\tremaining: 125ms\n",
      "71:\tlearn: 0.2120403\ttotal: 308ms\tremaining: 120ms\n",
      "72:\tlearn: 0.2117036\ttotal: 310ms\tremaining: 115ms\n",
      "73:\tlearn: 0.2109447\ttotal: 313ms\tremaining: 110ms\n",
      "74:\tlearn: 0.2106756\ttotal: 315ms\tremaining: 105ms\n",
      "75:\tlearn: 0.2096294\ttotal: 318ms\tremaining: 100ms\n",
      "76:\tlearn: 0.2090333\ttotal: 320ms\tremaining: 95.6ms\n",
      "77:\tlearn: 0.2087178\ttotal: 322ms\tremaining: 90.9ms\n",
      "78:\tlearn: 0.2084647\ttotal: 324ms\tremaining: 86.1ms\n",
      "79:\tlearn: 0.2080589\ttotal: 326ms\tremaining: 81.6ms\n",
      "80:\tlearn: 0.2079186\ttotal: 329ms\tremaining: 77.2ms\n",
      "81:\tlearn: 0.2074210\ttotal: 332ms\tremaining: 73ms\n",
      "82:\tlearn: 0.2069465\ttotal: 336ms\tremaining: 68.8ms\n",
      "83:\tlearn: 0.2065308\ttotal: 338ms\tremaining: 64.4ms\n",
      "84:\tlearn: 0.2057001\ttotal: 341ms\tremaining: 60.1ms\n",
      "85:\tlearn: 0.2053623\ttotal: 344ms\tremaining: 56ms\n",
      "86:\tlearn: 0.2051467\ttotal: 346ms\tremaining: 51.7ms\n",
      "87:\tlearn: 0.2049545\ttotal: 349ms\tremaining: 47.6ms\n",
      "88:\tlearn: 0.2042306\ttotal: 352ms\tremaining: 43.5ms\n",
      "89:\tlearn: 0.2038911\ttotal: 355ms\tremaining: 39.4ms\n",
      "90:\tlearn: 0.2035694\ttotal: 356ms\tremaining: 35.3ms\n",
      "91:\tlearn: 0.2034918\ttotal: 358ms\tremaining: 31.1ms\n",
      "92:\tlearn: 0.2028345\ttotal: 361ms\tremaining: 27.2ms\n",
      "93:\tlearn: 0.2026659\ttotal: 363ms\tremaining: 23.2ms\n",
      "94:\tlearn: 0.2023846\ttotal: 365ms\tremaining: 19.2ms\n",
      "95:\tlearn: 0.2021355\ttotal: 368ms\tremaining: 15.3ms\n",
      "96:\tlearn: 0.2018238\ttotal: 370ms\tremaining: 11.5ms\n",
      "97:\tlearn: 0.2014325\ttotal: 372ms\tremaining: 7.6ms\n",
      "98:\tlearn: 0.2009687\ttotal: 375ms\tremaining: 3.79ms\n",
      "99:\tlearn: 0.2007213\ttotal: 378ms\tremaining: 0us\n",
      "94/94 [==============================] - 0s 867us/step\n",
      "94/94 [==============================] - 0s 850us/step\n",
      "94/94 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 3008it [00:11, 104.68it/s]                                                                   \n",
      "ExactExplainer explainer: 3008it [00:48, 49.46it/s]                                                                    \n",
      "ExactExplainer explainer: 3008it [02:29, 18.78it/s]                                                                    \n",
      "ExactExplainer explainer: 3008it [03:24, 13.08it/s]                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3865, number of negative: 3151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 422\n",
      "[LightGBM] [Info] Number of data points in the train set: 7016, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550884 -> initscore=0.204242\n",
      "[LightGBM] [Info] Start training from score 0.204242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 3008it [00:23, 63.09it/s]                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6353943\ttotal: 1.9ms\tremaining: 188ms\n",
      "1:\tlearn: 0.5901188\ttotal: 4.22ms\tremaining: 207ms\n",
      "2:\tlearn: 0.5478482\ttotal: 6ms\tremaining: 194ms\n",
      "3:\tlearn: 0.5136306\ttotal: 8.26ms\tremaining: 198ms\n",
      "4:\tlearn: 0.4860331\ttotal: 10.2ms\tremaining: 194ms\n",
      "5:\tlearn: 0.4603531\ttotal: 12.3ms\tremaining: 192ms\n",
      "6:\tlearn: 0.4392672\ttotal: 14.5ms\tremaining: 193ms\n",
      "7:\tlearn: 0.4196621\ttotal: 16.5ms\tremaining: 190ms\n",
      "8:\tlearn: 0.4008000\ttotal: 18.9ms\tremaining: 192ms\n",
      "9:\tlearn: 0.3851888\ttotal: 20.9ms\tremaining: 188ms\n",
      "10:\tlearn: 0.3724749\ttotal: 22.7ms\tremaining: 184ms\n",
      "11:\tlearn: 0.3568197\ttotal: 24.8ms\tremaining: 182ms\n",
      "12:\tlearn: 0.3417550\ttotal: 26.8ms\tremaining: 179ms\n",
      "13:\tlearn: 0.3315141\ttotal: 29.1ms\tremaining: 178ms\n",
      "14:\tlearn: 0.3186721\ttotal: 31.1ms\tremaining: 176ms\n",
      "15:\tlearn: 0.3114373\ttotal: 33.3ms\tremaining: 175ms\n",
      "16:\tlearn: 0.3041058\ttotal: 35.4ms\tremaining: 173ms\n",
      "17:\tlearn: 0.2980165\ttotal: 37.5ms\tremaining: 171ms\n",
      "18:\tlearn: 0.2890200\ttotal: 39.8ms\tremaining: 170ms\n",
      "19:\tlearn: 0.2840458\ttotal: 41.7ms\tremaining: 167ms\n",
      "20:\tlearn: 0.2797251\ttotal: 43.5ms\tremaining: 163ms\n",
      "21:\tlearn: 0.2735361\ttotal: 45.9ms\tremaining: 163ms\n",
      "22:\tlearn: 0.2691002\ttotal: 47.9ms\tremaining: 160ms\n",
      "23:\tlearn: 0.2644316\ttotal: 49.9ms\tremaining: 158ms\n",
      "24:\tlearn: 0.2619269\ttotal: 51.9ms\tremaining: 156ms\n",
      "25:\tlearn: 0.2586062\ttotal: 53.9ms\tremaining: 153ms\n",
      "26:\tlearn: 0.2566122\ttotal: 56.1ms\tremaining: 152ms\n",
      "27:\tlearn: 0.2529136\ttotal: 58.2ms\tremaining: 150ms\n",
      "28:\tlearn: 0.2497365\ttotal: 60.7ms\tremaining: 149ms\n",
      "29:\tlearn: 0.2467193\ttotal: 62.5ms\tremaining: 146ms\n",
      "30:\tlearn: 0.2442787\ttotal: 64.5ms\tremaining: 144ms\n",
      "31:\tlearn: 0.2424973\ttotal: 66.8ms\tremaining: 142ms\n",
      "32:\tlearn: 0.2401940\ttotal: 68.9ms\tremaining: 140ms\n",
      "33:\tlearn: 0.2383951\ttotal: 71.1ms\tremaining: 138ms\n",
      "34:\tlearn: 0.2370410\ttotal: 72.8ms\tremaining: 135ms\n",
      "35:\tlearn: 0.2360192\ttotal: 74.8ms\tremaining: 133ms\n",
      "36:\tlearn: 0.2337688\ttotal: 77.5ms\tremaining: 132ms\n",
      "37:\tlearn: 0.2324773\ttotal: 79.5ms\tremaining: 130ms\n",
      "38:\tlearn: 0.2317474\ttotal: 81.7ms\tremaining: 128ms\n",
      "39:\tlearn: 0.2300905\ttotal: 84.1ms\tremaining: 126ms\n",
      "40:\tlearn: 0.2284777\ttotal: 86.2ms\tremaining: 124ms\n",
      "41:\tlearn: 0.2278026\ttotal: 88ms\tremaining: 122ms\n",
      "42:\tlearn: 0.2267316\ttotal: 90ms\tremaining: 119ms\n",
      "43:\tlearn: 0.2259917\ttotal: 92.3ms\tremaining: 117ms\n",
      "44:\tlearn: 0.2252336\ttotal: 94.9ms\tremaining: 116ms\n",
      "45:\tlearn: 0.2239174\ttotal: 96.8ms\tremaining: 114ms\n",
      "46:\tlearn: 0.2236347\ttotal: 98.7ms\tremaining: 111ms\n",
      "47:\tlearn: 0.2231099\ttotal: 102ms\tremaining: 111ms\n",
      "48:\tlearn: 0.2226520\ttotal: 104ms\tremaining: 109ms\n",
      "49:\tlearn: 0.2224887\ttotal: 105ms\tremaining: 105ms\n",
      "50:\tlearn: 0.2213479\ttotal: 108ms\tremaining: 103ms\n",
      "51:\tlearn: 0.2204791\ttotal: 110ms\tremaining: 101ms\n",
      "52:\tlearn: 0.2196832\ttotal: 111ms\tremaining: 98.8ms\n",
      "53:\tlearn: 0.2193089\ttotal: 113ms\tremaining: 96.4ms\n",
      "54:\tlearn: 0.2191588\ttotal: 115ms\tremaining: 94.1ms\n",
      "55:\tlearn: 0.2188146\ttotal: 117ms\tremaining: 91.8ms\n",
      "56:\tlearn: 0.2184435\ttotal: 119ms\tremaining: 89.7ms\n",
      "57:\tlearn: 0.2177817\ttotal: 121ms\tremaining: 87.5ms\n",
      "58:\tlearn: 0.2175176\ttotal: 123ms\tremaining: 85.5ms\n",
      "59:\tlearn: 0.2173402\ttotal: 126ms\tremaining: 83.7ms\n",
      "60:\tlearn: 0.2164811\ttotal: 128ms\tremaining: 81.5ms\n",
      "61:\tlearn: 0.2159342\ttotal: 130ms\tremaining: 79.4ms\n",
      "62:\tlearn: 0.2154854\ttotal: 132ms\tremaining: 77.6ms\n",
      "63:\tlearn: 0.2150157\ttotal: 134ms\tremaining: 75.4ms\n",
      "64:\tlearn: 0.2145972\ttotal: 136ms\tremaining: 73.3ms\n",
      "65:\tlearn: 0.2145149\ttotal: 137ms\tremaining: 70.8ms\n",
      "66:\tlearn: 0.2141162\ttotal: 140ms\tremaining: 68.8ms\n",
      "67:\tlearn: 0.2139198\ttotal: 142ms\tremaining: 66.6ms\n",
      "68:\tlearn: 0.2130691\ttotal: 144ms\tremaining: 64.5ms\n",
      "69:\tlearn: 0.2128962\ttotal: 146ms\tremaining: 62.5ms\n",
      "70:\tlearn: 0.2123232\ttotal: 148ms\tremaining: 60.4ms\n",
      "71:\tlearn: 0.2120403\ttotal: 150ms\tremaining: 58.5ms\n",
      "72:\tlearn: 0.2117036\ttotal: 152ms\tremaining: 56.4ms\n",
      "73:\tlearn: 0.2109447\ttotal: 154ms\tremaining: 54.2ms\n",
      "74:\tlearn: 0.2106756\ttotal: 156ms\tremaining: 52.1ms\n",
      "75:\tlearn: 0.2096294\ttotal: 158ms\tremaining: 50ms\n",
      "76:\tlearn: 0.2090333\ttotal: 160ms\tremaining: 47.8ms\n",
      "77:\tlearn: 0.2087178\ttotal: 162ms\tremaining: 45.7ms\n",
      "78:\tlearn: 0.2084647\ttotal: 164ms\tremaining: 43.5ms\n",
      "79:\tlearn: 0.2080589\ttotal: 166ms\tremaining: 41.5ms\n",
      "80:\tlearn: 0.2079186\ttotal: 168ms\tremaining: 39.4ms\n",
      "81:\tlearn: 0.2074210\ttotal: 170ms\tremaining: 37.3ms\n",
      "82:\tlearn: 0.2069465\ttotal: 172ms\tremaining: 35.2ms\n",
      "83:\tlearn: 0.2065308\ttotal: 174ms\tremaining: 33.1ms\n",
      "84:\tlearn: 0.2057001\ttotal: 176ms\tremaining: 31ms\n",
      "85:\tlearn: 0.2053623\ttotal: 178ms\tremaining: 28.9ms\n",
      "86:\tlearn: 0.2051467\ttotal: 180ms\tremaining: 26.8ms\n",
      "87:\tlearn: 0.2049545\ttotal: 182ms\tremaining: 24.8ms\n",
      "88:\tlearn: 0.2042306\ttotal: 184ms\tremaining: 22.7ms\n",
      "89:\tlearn: 0.2038911\ttotal: 186ms\tremaining: 20.6ms\n",
      "90:\tlearn: 0.2035694\ttotal: 188ms\tremaining: 18.6ms\n",
      "91:\tlearn: 0.2034918\ttotal: 190ms\tremaining: 16.5ms\n",
      "92:\tlearn: 0.2028345\ttotal: 192ms\tremaining: 14.4ms\n",
      "93:\tlearn: 0.2026659\ttotal: 194ms\tremaining: 12.4ms\n",
      "94:\tlearn: 0.2023846\ttotal: 197ms\tremaining: 10.3ms\n",
      "95:\tlearn: 0.2021355\ttotal: 199ms\tremaining: 8.28ms\n",
      "96:\tlearn: 0.2018238\ttotal: 201ms\tremaining: 6.21ms\n",
      "97:\tlearn: 0.2014325\ttotal: 203ms\tremaining: 4.15ms\n",
      "98:\tlearn: 0.2009687\ttotal: 206ms\tremaining: 2.08ms\n",
      "99:\tlearn: 0.2007213\ttotal: 208ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 3008it [00:16, 70.77it/s]                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 883us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 832us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using SHAP with CNN: operands could not be broadcast together with shapes (7016,5,1) (7016,5) \n",
      "94/94 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using SHAP with RNN: in user code:\n",
      "\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 244, in grad_graph  *\n",
      "        out = self.model(shap_rAnD)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 371, in custom_grad\n",
      "        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefix before the lookup\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 663, in handler\n",
      "        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 670, in linearity_with_excluded_handler\n",
      "        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\n",
      "    File \"C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 222, in _variable_inputs\n",
      "        out[i] = t.name in self.between_tensors\n",
      "\n",
      "    AttributeError: Exception encountered when calling layer 'lstm' (type LSTM).\n",
      "    \n",
      "    'TFDeep' object has no attribute 'between_tensors'\n",
      "    \n",
      "    Call arguments received by layer 'lstm' (type LSTM):\n",
      "      • inputs=tf.Tensor(shape=(14032, 5, 1), dtype=float32)\n",
      "      • mask=None\n",
      "      • training=False\n",
      "      • initial_state=None\n",
      "\n",
      "\n",
      "Hasil Evaluasi ML/DL tanpa XAI:\n",
      "[['DecisionTree', 0.9146974063400576, 0.9390532544378698, 0.9267153284671532, 0.9165281010974393, 0.012289047241210938], ['RandomForest', 0.9232142857142858, 0.9177514792899408, 0.9204747774480713, 0.9108746258729631, 0.3529360294342041], ['Logistic Regression', 0.7139718804920914, 0.9615384615384616, 0.8194654563792234, 0.7618889258397074, 0.017370223999023438], ['Naive Bayes', 0.9136125654450262, 0.20650887573964496, 0.33687258687258687, 0.543066178915863, 0.004433631896972656], ['MLP', 0.8089764641488779, 0.8745562130177514, 0.8404890531703155, 0.8134353175922847, 3.1871626377105713], ['Stochastic Gradient Descent', 0.815655133295519, 0.850887573964497, 0.8328989284679987, 0.8081143997339542, 0.015979528427124023], ['ADA Boost', 0.9027856736782263, 0.9396449704142011, 0.920846622209336, 0.9092118390422348, 0.5322613716125488], ['Gradient Boosting', 0.9237875288683602, 0.9467455621301775, 0.9351256575102279, 0.9261722647156635, 0.4594995975494385], ['XGBoost', 0.9320732427643237, 0.9337278106508876, 0.9328997930830625, 0.9245094778849352, 1.775609016418457], ['LightGBM', 0.9275618374558304, 0.9319526627218935, 0.9297520661157025, 0.9208513468573329, 0.2935519218444824], ['CatBoost', 0.9146620847651775, 0.9449704142011834, 0.929569266589057, 0.9195211173927502, 0.4920077323913574], ['DNN', 0.8274440518256773, 0.8313609467455622, 0.8293978748524203, 0.8077818423678085, 2.359313726425171], ['CNN', 0.7904015670910872, 0.9550295857988166, 0.864951768488746, 0.8323910874625873, 2.3872361183166504], ['RNN', 0.7024828767123288, 0.9710059171597634, 0.8152011922503726, 0.7525773195876289, 7.050199031829834]]\n",
      "\n",
      "Hasil Evaluasi ML/DL dengan XAI:\n",
      "[['DecisionTree', 0.9146974063400576, 0.9390532544378698, 0.9267153284671532, 0.9165281010974393, 0.011989355087280273, {'SHAP': array([[-0.01448616,  0.01448616],\n",
      "       [-0.00344944,  0.00344944],\n",
      "       [ 0.01048154, -0.01048154],\n",
      "       [-0.00136821,  0.00136821],\n",
      "       [ 0.00063582, -0.00063582]])}], ['RandomForest', 0.922209026128266, 0.9189349112426035, 0.920569057498518, 0.9108746258729631, 0.36347293853759766, {'SHAP': array([[-0.01892822,  0.01892822],\n",
      "       [-0.00213301,  0.00213301],\n",
      "       [ 0.00865056, -0.00865056],\n",
      "       [-0.00078198,  0.00078198],\n",
      "       [-0.00184476,  0.00184476]])}], ['Logistic Regression', 0.7139718804920914, 0.9615384615384616, 0.8194654563792234, 0.7618889258397074, 0.017132043838500977, {'SHAP': array([[-0.00043685,  0.00043685],\n",
      "       [ 0.00102775, -0.00102775],\n",
      "       [-0.00054384,  0.00054384],\n",
      "       [-0.01838575,  0.01838575],\n",
      "       [-0.00885379,  0.00885379]])}], ['Naive Bayes', 0.9136125654450262, 0.20650887573964496, 0.33687258687258687, 0.543066178915863, 0.0040361881256103516, {'SHAP': array([[-0.00158761,  0.00158761],\n",
      "       [ 0.01916463, -0.01916463],\n",
      "       [ 0.01464193, -0.01464193],\n",
      "       [-0.00049882,  0.00049882],\n",
      "       [ 0.00097185, -0.00097185]])}], ['MLP', 0.8089764641488779, 0.8745562130177514, 0.8404890531703155, 0.8134353175922847, 2.993086814880371, {'SHAP': array([[-0.00251403,  0.00251403],\n",
      "       [-0.00051505,  0.00051505],\n",
      "       [ 0.00504193, -0.00504193],\n",
      "       [-0.049729  ,  0.049729  ],\n",
      "       [-0.00125065,  0.00125065]])}], ['Stochastic Gradient Descent', 0.815655133295519, 0.850887573964497, 0.8328989284679987, 0.8081143997339542, 0.015003204345703125, {'SHAP': array([[-0.00042852,  0.00042852],\n",
      "       [ 0.00129148, -0.00129148],\n",
      "       [-0.00080185,  0.00080185],\n",
      "       [-0.01934745,  0.01934745],\n",
      "       [-0.00834451,  0.00834451]])}], ['ADA Boost', 0.9027856736782263, 0.9396449704142011, 0.920846622209336, 0.9092118390422348, 0.4855175018310547, {'SHAP': array([[-2.74049564e-04,  2.74049564e-04],\n",
      "       [-7.77685734e-05,  7.77685734e-05],\n",
      "       [ 7.65253224e-05, -7.65253224e-05],\n",
      "       [-2.68561477e-04,  2.68561477e-04],\n",
      "       [-7.05620891e-04,  7.05620891e-04]])}], ['Gradient Boosting', 0.9237875288683602, 0.9467455621301775, 0.9351256575102279, 0.9261722647156635, 0.47249865531921387, {'SHAP': array([[-0.01009769,  0.01009769],\n",
      "       [-0.00297723,  0.00297723],\n",
      "       [ 0.00792493, -0.00792493],\n",
      "       [-0.00789379,  0.00789379],\n",
      "       [ 0.00056608, -0.00056608]])}], ['XGBoost', 0.9320732427643237, 0.9337278106508876, 0.9328997930830625, 0.9245094778849352, 0.11553215980529785, {'SHAP': array([[-0.0178705 ,  0.0178705 ],\n",
      "       [-0.0024032 ,  0.0024032 ],\n",
      "       [ 0.00717673, -0.00717673],\n",
      "       [-0.00243842,  0.00243842],\n",
      "       [ 0.00239365, -0.00239365]])}], ['LightGBM', 0.9275618374558304, 0.9319526627218935, 0.9297520661157025, 0.9208513468573329, 98.53627276420593, {'SHAP': array([[-0.02173608,  0.02173608],\n",
      "       [-0.00253034,  0.00253034],\n",
      "       [ 0.00546633, -0.00546633],\n",
      "       [-0.00162014,  0.00162014],\n",
      "       [ 0.00431674, -0.00431674]])}], ['CatBoost', 0.9146620847651775, 0.9449704142011834, 0.929569266589057, 0.9195211173927502, 0.2857372760772705, {'SHAP': array([[-0.00311796,  0.00311796],\n",
      "       [-0.0023302 ,  0.0023302 ],\n",
      "       [ 0.00637302, -0.00637302],\n",
      "       [-0.0134433 ,  0.0134433 ],\n",
      "       [ 0.00029175, -0.00029175]])}], ['DNN', 0.8074195308237861, 0.8757396449704142, 0.8401930173147886, 0.8127702028599934, 2.0983705520629883, {'SHAP': array([0.0530575])}], ['CNN', 0.8165548098434005, 0.863905325443787, 0.8395629672225418, 0.8144329896907216, 8.371269941329956, {'SHAP': None}], ['RNN', 0.8075040783034257, 0.878698224852071, 0.8415981864550863, 0.814100432324576, 7.0632452964782715, {'SHAP': None}]]\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi variabel untuk menyimpan hasil evaluasi\n",
    "hasil_ml_dl = []\n",
    "hasil_ml_dl_xai = []\n",
    "\n",
    "# Encode labels ke bentuk numerik jika diperlukan\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Fungsi untuk mengevaluasi model ML/DL\n",
    "def EvaluateModel(model_name, model, X_train, y_train, X_test, y_test, use_xai=False, is_dl_model=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Melatih model\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0) if is_dl_model else model.fit(X_train, y_train)\n",
    "    \n",
    "    if is_dl_model:\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    elif hasattr(model, 'predict_proba'):\n",
    "        # Model dengan metode predict_proba\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        if y_pred_proba.shape[1] > 1:  # Model klasifikasi multi-kelas\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        else:  # Model klasifikasi biner\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "    else:\n",
    "        # Model tanpa metode predict_proba\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "\n",
    "    # Menghitung confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Menghitung metrik\n",
    "    Precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    Recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    F1Score = 2 * ((Precision * Recall) / (Precision + Recall)) if (Precision + Recall) != 0 else 0\n",
    "    Accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) != 0 else 0\n",
    "\n",
    "    # Menghitung waktu running\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "    # Jika XAI diperlukan, tambahkan analisis dengan SHAP\n",
    "    if use_xai:\n",
    "        # Periksa apakah X_train adalah DataFrame\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            feature_names = X_train.columns\n",
    "        else:\n",
    "            feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "        \n",
    "        # Perbaiki format X_train untuk SHAP\n",
    "        if is_dl_model:\n",
    "            X_train_for_xai = X_train.reshape((X_train.shape[0], X_train.shape[1]))\n",
    "            X_test_for_xai = X_test.reshape((X_test.shape[0], X_test.shape[1]))\n",
    "        else:\n",
    "            X_train_for_xai = X_train\n",
    "            X_test_for_xai = X_test\n",
    "\n",
    "        # Gunakan SHAP\n",
    "        try:\n",
    "            if is_dl_model:\n",
    "                explainer = shap.DeepExplainer(model, X_train_for_xai)\n",
    "                shap_values = explainer.shap_values(X_test_for_xai)\n",
    "                shap_summary = np.mean(shap_values[0], axis=0)\n",
    "            else:\n",
    "                explainer = shap.Explainer(model.predict_proba, X_train_for_xai)\n",
    "                shap_values = explainer(X_test_for_xai)\n",
    "                shap_summary = shap_values.values.mean(axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error using SHAP with {model_name}: {e}\")\n",
    "            shap_summary = None\n",
    "\n",
    "        # Simpan hasil evaluasi dengan XAI\n",
    "        hasil_ml_dl_xai.append([model_name, Precision, Recall, F1Score, Accuracy, run_time, {'SHAP': shap_summary}])\n",
    "    else:\n",
    "        # Simpan hasil evaluasi tanpa XAI\n",
    "        hasil_ml_dl.append([model_name, Precision, Recall, F1Score, Accuracy, run_time])\n",
    "\n",
    "# Model ML dan DL yang akan dievaluasi\n",
    "model_ml_dl = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=10),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=50),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0, max_iter=10000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000),\n",
    "    \"Stochastic Gradient Descent\": SGDClassifier(loss='log_loss', random_state=42),\n",
    "    \"ADA Boost\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='Logloss')\n",
    "}\n",
    "\n",
    "model_dl = {\n",
    "    \"DNN\": Sequential([\n",
    "        Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"CNN\": Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"RNN\": Sequential([\n",
    "        LSTM(100, input_shape=(X_train.shape[1], 1)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Pastikan X_train dan X_test memiliki bentuk yang sesuai untuk DL\n",
    "X_train_dl = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_dl = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Mengevaluasi model ML tanpa XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=False)\n",
    "\n",
    "# Mengevaluasi model DL tanpa XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=False, is_dl_model=True)\n",
    "\n",
    "# Mengevaluasi model ML dengan XAI\n",
    "for model_name, model in model_ml_dl.items():\n",
    "    EvaluateModel(model_name, model, X_train, y_train_encoded, X_test, y_test_encoded, use_xai=True)\n",
    "\n",
    "# Mengevaluasi model DL dengan XAI\n",
    "for model_name, model in model_dl.items():\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    EvaluateModel(model_name, model, X_train_dl, y_train_encoded, X_test_dl, y_test_encoded, use_xai=True, is_dl_model=True)\n",
    "\n",
    "# Print hasil evaluasi tanpa XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL tanpa XAI:\")\n",
    "print(hasil_ml_dl)\n",
    "\n",
    "# Print hasil evaluasi dengan XAI\n",
    "print(\"\\nHasil Evaluasi ML/DL dengan XAI:\")\n",
    "print(hasil_ml_dl_xai)\n",
    "\n",
    "# Convert results to DataFrame and save to CSV\n",
    "df_ml_dl = pd.DataFrame(hasil_ml_dl, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\"])\n",
    "df_ml_dl_xai = pd.DataFrame(hasil_ml_dl_xai, columns=[\"Model\", \"Precision\", \"Recall\", \"F1Score\", \"Accuracy\", \"RunTime\", \"XAI\"])\n",
    "\n",
    "df_ml_dl.to_csv(\"hasil_evaluasi_ml_dl_VTFC.csv\", index=False)\n",
    "df_ml_dl_xai.to_csv(\"hasil_evaluasi_ml_dl_xai_VTFC.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
